[{"title":"java day01 Typora","url":"/2021/07/06/java%20day01%20Typora/","content":"Typora的使用熟练使用Markdown语法\n标题的使用一级标题为**#**\n二级标题为**##**\n三级标题为**###**\n字体的使用粗体 hello-&gt;左右两个*\n斜体hello-&gt;左右一个*\n斜体加粗hello-&gt;左右三个*\n删除线hello-&gt;左右两个~\n引用的使用\n引用别人文章时使用，左侧一个&gt;\n\n分割线\n\n左侧三个-\n左侧三个*\n\n\n图片\n本地图片\n\n\n\n网络图片\n\n\n通用方法：**!+[名字]+()**\n超链接CSDN\n方法：**[名称]+(链接)**\n列表\n前面使用的都是有序列表\n方法：数字+.+空格\n\n无须列表方法：**-+空格**\n\nA\nB\n\n\n\n表格\n\n\n名字\n性别\n年龄\n\n\n\n小昊\n女\n20\n\n\n格式如下所示：\n名字|性别|年龄\n–|–|–\n小昊|女|20\n代码public\n\n方法如下：\n英文下的&#96;&#96;&#96;(tab上面的按键)+想要写的语言\n被忽略的windows快捷键\nalt+F4：关闭所在页面\nshift+delete：永久删除\nwindows+tab：切换程序\n\n","tags":["java基础"]},{"title":"java day01 基础","url":"/2021/07/07/java%20day01%20%E5%9F%BA%E7%A1%80/","content":"01 注释单行注释：\n// 单行注释可以注释一行文字\n\n多行注释：\n/*多行注释可以注释一段文字*/\n\n文档注释：\n/***配合JavaDoc使用*/\n\n02 标识符与关键字关键字：class,public等Java硬性要求的代码。\n标识符：类名，变量名，方法名都是标识符。\n标识符的注意事项：\n\n所有标识符都应该以字母，$，或者下划线(_)开始\nString name = &quot;xiaofang&quot;;String $name = &quot;xiaofang&quot;;String _name = &quot;xiaofang&quot;;\n\n首字母之后可以是字母，$，或者下划线(_)或者数字\nString A$ = &quot;xiaofang&quot;;String A_ = &quot;xiaofang&quot;;String A1 = &quot;xiaofang&quot;;\n\n\n\n不能使用关键字作为变量名或方法名\n\n标识符不建议使用中文\n\n标识符是大小写敏感的\n\n\n03 数据类型Java是强类型语言，要求所有变量都必须定义后才能使用。\n\n基本数据类型如下表所示：\n\n\n\n整数类型\n浮点类型\n字符类型\n布尔类型\n\n\n\nbyte占1字节\nfloat占4字节\nchar占2字节\ntrue占1位\n\n\nshort占2字节\ndouble占8字节\n\nfalse占1位\n\n\nint占4字节\n\n\n\n\n\nlong占8字节\n\n\n\n\n\n//整数byte num = 10;short num1 = 15;int num2 = 20;long num3 = 30L;//long类型要在数字后加上L//浮点数float num5 = 10.1f;//float类型要在数字后加上fdouble num6 = 10.33333;//字符char name = &#x27;f&#x27;;//注意String不是关键字//布尔boolean flag = true;boolean flag1 = false;\n\n字节与位的关系：1 Byte&#x3D;8 bit\n\n数据类型面试拓展\n\n整型拓展：\n\nint i = 10;//输出10int i2 = 010;//八进制0开头 输出8int i3 = 0x10;//十六进制0x开头（范围：0~9 A~F） 输出16\n\n\n浮点数拓展：\n由于浮点数有舍入误差，接近但不等于的特点，最好不适用浮点数进行比较，可以使用BigDecimal提供的方法进行比较。\n\n字符拓展：\n所有字符的本质还是数字\nchar s1 = &#x27;a&#x27;;char s2 = &#x27;小&#x27;;System.out.println(s1);//输出 aSystem.out.println((int)s1);//强制转换 输出 97System.out.println(s2);//输出 小System.out.println((int)s2);//强制转换 输出 23567\n\n布尔拓展：\nboolean flag =true;if(flag)&#123;&#125; == if(flag==true)&#123;&#125;//二者是等价的\n\n04 类型转换\n强制类型转换：一般是高容量转换到低容量的转换。格式：**(类型)变量名**\n\nint i = 12;byte b = (byte)i;System.out.println(i);//输出12System.out.println(b);//输出12\n\n\n自动类型转化：低容量到高容量直接转换。\n低 -------------------------------------&gt;高 byte,short,char-&gt;int-&gt;long-&gt;float-&gt;double\n\nint i = 12;double b = i;System.out.println(i);//输出12System.out.println(b);//输出12.0\n\n注意点\n\n布尔类型不能进行转换\n转换的时候可能出现内存溢出，或者精度问题\n\n\n\n//溢出问题int money = 10_0000_0000;//数字之间可以用下划线分割int year = 20;int total = money*year;//计算时溢出 输出为-1474836480long total1 = money*year;//默认为int类型，转换之前就出了问题。所以输出依旧是-1474836480long total2 = money*((long)year);//输出20000000000\n\n//精度问题System.out.println((int)23.7);//输出23System.out.println((int)-20.4f);//输出-20\n\n","tags":["java基础"]},{"title":"java day02 基础","url":"/2021/07/08/java%20day02%20%E5%9F%BA%E7%A1%80/","content":"01 变量、作用域、常量1.1 变量\n变量的格式： 数据类型  变量名 &#x3D; 值\n注意事项：\n数据类型可以是基本类型，还可以是引用类型\n变量名必须是合法的标识符\n变量声明必须以;结尾\n\n\n\nchar x = &#x27;A&#x27;;//基本数据类型int a = 1;//基本数据类型String name = &quot;xiaofang&quot;;//引用类型\n\n1.2 变量作用域public class Hello &#123;    static double salary = 1000;//类变量在类中不在方法中，由static修饰符修饰    String name;//实例变量从属于对象，整型变量默认值为0；布尔变量默认值为false;基本数据类型外默认值都为null。    public static void main(String[] args) &#123;        //定义在方法中为局部变量        int i =10;        System.out.println(i);//输出10        //使用实例变量如下所示：        Hello hello = new Hello();//变量类型 变量名 = new 变量类型        System.out.println(hello.name);//输出null        //类变量        System.out.println(salary);//输出1000.0    &#125;&#125;\n\n1.3 常量\n常量初始化后，值不能再改变\n初始化格式：final 常量名 &#x3D; 值；\n常量名都用大写字母\n\n\n命名规则\n类成员变量：首字母小写+驼峰原则：除了第一个单词外，后面单词首字母大写。xiaoFang\n局部变量：首字母小写+驼峰原则\n常量：大写字母+下划线：XIAO_FANG\n类名：首字母大写+驼峰原则\n方法名：小写+驼峰原则\n\n02 运算符2.1 二元运算符int a = 10;int b = 20;int c = 21;System.out.println(a+b);//输出30System.out.println(a-b);//输出-10System.out.println(a*b);//输出200System.out.println(a/b);//由于int类型，需要舍弃小数点，所以输出0System.out.println(a/(double)b);//输出0.5System.out.println(c%a);//输出1(取余)\n\n2.2 类型转换long a = 101010120121L;int b = 20;short c = 10;byte d = 8;//如果有一个数是long类型，那么最后输出也是long类型System.out.println(a+b+c+d);//输出101010120159//下面自动转为int类型System.out.println(b+c+d);//输出38System.out.println(c+d);//输出18\n\n2.3 关系运算符//关系运算符输出结果是布尔类型int a = 2;int b = 3;System.out.println(a&gt;b);//输出falseSystem.out.println(a&lt;b);//输出trueSystem.out.println(a==b);//输出falseSystem.out.println(a!=b);//输出true\n\n2.4 一元运算符int a = 10;int b = a++;//先赋值再自增int c = ++a;//先自增再赋值System.out.println(a);//输出12System.out.println(b);//输出10System.out.println(c);//输出12\n\n2.5 Math类double pow =Math.pow(3,2);//幂运算System.out.println(pow);//输出9.0\n\n2.6 逻辑运算符boolean a = true;boolean b = false;//逻辑与，两个变量都为真，结果才为真，否则为假System.out.println(&quot;a &amp;&amp; b:&quot;+(a &amp;&amp; b));//输出a &amp;&amp; b:false//逻辑或，两个变量只要有一个为真，结果就为真System.out.println(&quot;a || b:&quot;+(a || b));//输出a || b:true//逻辑否，真变假，假变真System.out.println(&quot;!(a &amp;&amp; b):&quot;+!(a &amp;&amp; b));//输出!(a &amp;&amp; b):true//短路原则int c = 5;boolean d = (c&lt;4)&amp;&amp;(c++&lt;4);//与运算，当第一个为假时，结果就以确定，不再进行下面操作。System.out.println(d);//输出falseSystem.out.println(c);//输出5\n\n2.7 位运算符A = 0011 1100;B = 0000 1101;A&amp;B = 0000 1100;//位与运算，同1才为1，否则为0A|B = 0011 1101;//位或运算，有一就为1，否则为0A^B = 0011 0001;//位异或运算，相同为0，不同为1~A = 1100 0011;//0变1，1变02&gt;&gt;1// 右移/2输出12&lt;&lt;1//左移*2输出4\n\n2.8 字符串连接符a = 10;int b = 20;System.out.println(&quot;&quot;+a+b);//输出1020，String类型在前面+用于连接System.out.println(a+b+&quot;&quot;);//输出30，String类型在后面正常输出\n\n2.9 三元运算符//x ? y : z//如果x==true,则结果为y，否则为zint x =62;String type = x&gt;60 ? &quot;及格&quot; : &quot;不及格&quot;;System.out.println(type);//输出及格\n\n","tags":["java基础"]},{"title":"java day03 基础","url":"/2021/07/09/java%20day03%20%E5%9F%BA%E7%A1%80/","content":"01 包机制\n包就是相当于一个文件夹\n包语句的语法格式：\n\n//package pkg1.pkg2；package com.fang;\n\n\n一般利用公司域名倒置作为包名\n使用某一个包的成员，需要用”import”导入，格式：\n\n//import package1.package1.classname；import com.fang.demo；\n\n02 JavaDoc生成文档/** * @author Fang //@author 用于标记作者 * @version 1.0 //@version 用于标记当前版本，默认为1.0 * @since 1.8 //@since 一般用于标记文件创建时项目当时对应的版本，跟版本号，也可以跟是一个时间，表示文件当前创建的时间 */public class Hello &#123;    String name;    /**     * @param name //@param用于标记参数     * @return //@return 用于返回值     * @throws Exception //@throws 用于抛出异常     */    public String test(String name)throws Exception&#123;        return name;    &#125;&#125;\n\n\n使用cmd生成文档\n\njavadoc -encoding UTF-8 -charset UTF-8 Hello.java\n\n\n使用IDEA生成文档\n\n在IDEA找到工具里的生成JavaDoc文档，配置其他命令行参数-encoding UTF-8 -charset UTF-8防止乱码。\n","tags":["java基础"]},{"title":"java day03 流程控制","url":"/2021/07/09/java%20day03%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","content":"01 Scanner对象\n基本语法：\n\nScanner s = new Scanner(System.in);\n\n\n通过Scanner类的next()和nextLine()方法获取输入字符串，在读取之前一般采用hasNext()与hasNextLine()判断是否还有输入数据。\n\n//创建一个扫描对象，用于接收数据Scanner scanner = new Scanner(System.in);System.out.println(&quot;请输入数据&quot;);//判断用户有没有输入字符if(scanner.hasNext())&#123;//使用next接收String str = scanner.next();//输入xiao fangSystem.out.println(&quot;输出内容为&quot;+str);//输出 输出内容为xiao&#125;scanner.close();//使用完一定要给关闭掉，节省资源\n\n//创建一个扫描对象，用于接收数据Scanner scanner = new Scanner(System.in);System.out.println(&quot;请输入数据&quot;);//判断用户有没有输入字符if(scanner.hasNextLine())&#123;//使用nextLine接收String str = scanner.nextLine();//输入xiao fangSystem.out.println(&quot;输出内容为&quot;+str);//输出 输出内容为xiao fang&#125;scanner.close();//使用完一定要给关闭掉，节省资源\n\n\nnext()与nextLine()的区别\nnext()以有效字符之后的空格作为分隔符胡总和结束符，对于之前遇到的空格，next()会将其去掉；nextLine()以Enter作为结束符。\nnext()不能获得带有空格的字符；nextLine()能获得带有空格的字符。\n\n\n\n02 Scanner进阶使用我们可以输入多个数字，并求其总数及平均值，每输入一个数字用回车确认，通过输入非数字结束输入并输出结果。\npublic class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        double sum = 0;        int count = 0;        while(scanner.hasNextDouble())&#123;            double x = scanner.nextDouble();            count++;            sum +=x;            System.out.println(&quot;输入第&quot;+count+&quot;个数据,总和为&quot;+sum);        &#125;        System.out.println(&quot;总和为&quot;+sum);        System.out.println(&quot;平均数为&quot;+sum/count);        scanner.close();    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day04 流程控制","url":"/2021/07/10/java%20day04%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","content":"01 顺序结构\nJava的最基本的结构就是顺序结构\n它是任何一个算法都离不开的一种基本算法结构\n\n02 if选择结构2.1 if单选择结构public class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(&quot;请输入&quot;);        String str = scanner.nextLine();        //判断字符串是否相等        if(str.equals(&quot;hello&quot;))&#123;            System.out.println(str);        &#125;        System.out.println(&quot;end&quot;);        scanner.close();    &#125;&#125;\n\n2.2 if双选择结构//考试分数大于60就是及格，小于60就是不及格public class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(&quot;请输入&quot;);        int num = scanner.nextInt();        if(num&gt;60)&#123;            System.out.println(&quot;及格&quot;);        &#125;else &#123;            System.out.println(&quot;不及格&quot;);        &#125;        scanner.close();    &#125;&#125;\n\n2.3 多选择结构public class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(&quot;请输入&quot;);        int num = scanner.nextInt();        if(num&lt;=100 &amp;&amp; num&gt;=90)&#123;            System.out.println(&quot;A&quot;);        &#125;else if(num&lt;90 &amp;&amp; num&gt;=80)&#123;            System.out.println(&quot;B&quot;);        &#125;else if(num&lt;80 &amp;&amp; num&gt;=70)&#123;            System.out.println(&quot;C&quot;);        &#125;else if(num&lt;70 &amp;&amp; num&gt;=60)&#123;            System.out.println(&quot;D&quot;);        &#125;else&#123;            System.out.println(&quot;成绩不对&quot;);        &#125;        scanner.close();    &#125;&#125;\n\n03 switch多选择结构public class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(&quot;请输入&quot;);        String str = scanner.nextLine();        switch (str)&#123;//JDK7之后就可以用字符串            case &quot;fang&quot;:                System.out.println(&quot;fang&quot;);                break;            case &quot;xiao&quot;:                System.out.println(&quot;xiao&quot;);                break;            default:                System.out.println(&quot;wu&quot;);        &#125;        scanner.close();    &#125;&#125;\n\n\ncase穿透：如果没有break，则会按顺序执行，直到遇到break或者程序结束\n\n","tags":["java基础"]},{"title":"java day05 流程控制","url":"/2021/07/11/java%20day05%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","content":"01 while循环\n只要布尔表达式为true，循环就会一直执行下去。\n我们大多数的情况需要让循环停止下来，需要一个让表达式失效的方式来结束循环。\n先判断在执行\n正常业务应该尽量避免死循环。\n如果不满足条件，则不能进入循环。\n\n//1+2.....+100int i = 0;int sum = 0;while(i&lt;100)&#123;    i++;    sum+=i;&#125;\n\n02 do…..while循环\ndo…..while循环至少执行一次\n先执行后判断\n\n//1+2.....+100int i = 0;int sum = 0;do&#123;    i++;    sum+=i;&#125;while (i&lt;100);\n\n\nwhile与do while区别\n\nint i = 0;while (i&lt;0)&#123;    System.out.println(i);//不输出&#125;System.out.println(&quot;..........................&quot;);do&#123;    System.out.println(i);//输出0&#125;while (i&lt;0);\n\n03 For循环\nfor循环语句时支持迭代的一种通用结构，最有效、最灵活的循环结构。\nfor循环执行的次数是在执行前就确定的。\nfor循环也有死循环，格式如下：\n\nfor ( ; ; )&#123; &#125;\n\n\n计算0到100之间的奇数和偶数的和\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        int oddSum = 0;        int evenSum = 0;        for (int i = 0; i &lt;= 100; i++) &#123;            if(i%2==0)&#123;                evenSum+=i;            &#125;else&#123;                oddSum+=i;            &#125;        &#125;        System.out.println(&quot;偶数和&quot;+evenSum);        System.out.println(&quot;奇数和&quot;+oddSum);    &#125;&#125;\n\n\n循环输出1-1000之间能被5整除的数，并且每行输出3个\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        for (int i = 0; i &lt;= 1000; i++) &#123;            if(i%5==0)&#123;                System.out.print(i+&quot;\\t&quot;);//\\t加空格            &#125;            if(i%(5*3)==0)&#123;                System.out.println();//输出完自动换行                //System.out.print(&quot;\\n&quot;);输出完不会换行            &#125;        &#125;    &#125;&#125;\n\n\n打印九九乘法表\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        for (int i = 1; i &lt;= 9; i++) &#123;            for(int j = 1; j&lt;=i;j++)&#123;                System.out.print(i+&quot;*&quot;+j+&quot;=&quot;+(i*j)+&quot;\\t&quot;);            &#125;            System.out.println();        &#125;    &#125;&#125;\n\n04 增强for循环\n主要用来遍历数组与集合\n格式：for(声明语句 ：表达式){ }\n声明语句：是声明局部变量，该变量类型必须和数组元素的类型匹配。\n表达式：是要访问的数组名，或者是返回值是数组的方法。\n\n\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        int[] number = &#123;10, 20, 30, 40&#125;;        for (int x : number)&#123;            System.out.println(x);        &#125;    &#125;&#125;\n\n05 break与continue\nbreak用于强制退出循环，不再执行循环中剩余语句。\ncontinue用于终止某次循环结构，进行下次循环\n\npublic class Hello &#123;    public static void main(String[] args) &#123;       int i = 1;       while (i&lt;100)&#123;           i++;           if(i%10==0)&#123;               System.out.println();               continue;//1               //break;2           &#125;           System.out.print(i+&quot; &quot;);       &#125;    &#125;&#125;1./*1 2 3 4 5 6 7 8 9               2.   1 2 3 4 5 6 7 8 9 11 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 41 42 43 44 45 46 47 48 49 51 52 53 54 55 56 57 58 59 61 62 63 64 65 66 67 68 69 71 72 73 74 75 76 77 78 79 81 82 83 84 85 86 87 88 89 91 92 93 94 95 96 97 98 99 */\n\n\n打印三角形\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        for (int i = 1; i &lt;= 5; i++) &#123;            for (int j = 5; j &gt;= i; j--) &#123;                System.out.print(&quot; &quot;);            &#125;            for (int j = 1; j &lt;= i; j++)&#123;                System.out.print(&quot;*&quot;);            &#125;            for (int j = 1; j &lt; i; j++)&#123;                System.out.print(&quot;*&quot;);            &#125;            System.out.println();        &#125;    &#125;&#125;","tags":["java基础"]},{"title":"java day06 方法","url":"/2021/07/12/java%20day06%20%E6%96%B9%E6%B3%95/","content":"01 方法定义和调用1.1 方法定义//类.对象.方法System.out.println();\n\n\nJava一定是值传递\nJava方法是语句的集合，他们在一起执行一个功能。\n方法包括在类或对象中。\n方法在程序中被创建，在其他地方被引用。\n一个方法只完成一个功能。\n\n//修饰符+返回值类型+方法名（参数类型+参数名）public static int max(int num1,int num2)&#123;    return 0;&#125;\n\n//比较大小public class Hello &#123;    public static void main(String[] args) &#123;        int max =max(3,2);        System.out.println(max);    &#125;    public static int max(int num1,int num2)&#123;        int result = 0;        if(num1 == num2)&#123;            System.out.println(&quot;等价&quot;);        &#125;else if(num1&gt;num2)&#123;            result = num1;        &#125;else&#123;            result = num2;        &#125;        return result;    &#125;&#125;\n\n1.2 方法调用\n调用方法：对象名.方法名（实参列表）\n当方法返回一个值时，方法调用通常被当作一个值。例如\n\nint max =max(3,2);\n\n\n当方法返回值是void，方法调用一定是一条语句。\n\nSystem.out.println(&quot;hello&quot;);\n\n02 方法的重载\n重载就是在一个类中，有相同的函数名称，但形式参数不同的函数。\n方法重载的规则：\n方法名称必须相同。\n参数列表必须不同（个数不同、类型不同、参数排列顺序不同）。\n返回类型可以相同也可以不同。\n仅仅返回类型不同，不是方法的重载。\n\n\n\npublic static int max(int num1,int num2)public static int max(double num1,double num2)","tags":["java基础"]},{"title":"java day07 数组","url":"/2021/07/13/java%20day07%20%E6%95%B0%E7%BB%84/","content":"01 数组的定义\n数组是相同数据类型的有序集合\n按照一定的先后次序排列组合而成\n每一个数据称作一个数组元素，每个数组元素都可以通过一个下标来进行访问\n\n02 数组的声明及创建\n数组的元素是通过索引访问的，数组索引从0开始\n获得数组的长度：arrays.length\n声明数组：\n\nint[] arrays;//首选int arrays[];//不是首选\n\n\n创建一个数组：\n\narrays = new int[10];\n\n\n声明+创建数组：\n\nint[] arrays = new int[10];","tags":["java基础"]},{"title":"java day07 方法","url":"/2021/07/13/java%20day07%20%E6%96%B9%E6%B3%95/","content":"01 可变参数\n在方法声明时，在（ ）中指定参数类型后加…\n一个方法中只能指定一个可变参数，它必须是方法的最后一个参数。\n\npublic class Hello &#123;    public static void main(String[] args) &#123;       max(1, 2, 3, 4, 5);       max(0.45, 0.55, 0.12);    &#125;    public static void max(double ...i)&#123;//i为可变参数        if(i.length == 0)&#123;            System.out.println(&quot;No Print&quot;);        &#125;        double result = i[0];        for(int number = 0;number&lt;i.length;number++)&#123;            if(result&lt;i[number])&#123;                result = i[number];            &#125;        &#125;        System.out.println(&quot;The Max is&quot;+result);    &#125;&#125;\n\n02 递归\n递归就是：自己调用自己\n递归结构包括：\n递归头：什么时候不调用自身方法。\n递归体：什么时候需要调用自身方法。\n\n\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        System.out.println(f(4));    &#125;    public static int f(int i)&#123;      if(i == 1)&#123;          return 1;      &#125;else&#123;          return i*f(i-1);      &#125;    &#125;&#125;\n\n\n递归的形式：\n\n\n","tags":["java基础"]},{"title":"java day08 数组","url":"/2021/07/15/java%20day08%20%E6%95%B0%E7%BB%84/","content":"01 三种初始化及内存分析\n内存分析\n堆是用来存放new的对象和数组；可以被所有线程共享，不会存放别的对象引用\n栈是用来存放基本变量类型（包含具体数值）；或者存放引用对象变量\n方法区包括了所有的class和static变量\n\n\n\n\n\n三种初始化\n\n静态初始化\n\nint[] arrays = &#123;1,2,3,4,5,6,7&#125;;Man[] man = &#123;new Man(),new Man()&#125;;//在此之前先创建个Man类，进行引用\n\n\n动态初始化\n\nint[] a = new int[2];a[0] = 1;a[1] = 2;\n\n\n默认初始化：数组分配空间后，int类型默认为0\n\n\n\n02 下标越界\n数组的四个基本特点\n\n其长度是确定的，数组一旦被创建，它的大小就是不可以改变的。\n其元素必须是相同类型的。\n数组中的元素可以是任何数据类型，包括基本类型和引用类型。\n数组对象本身是在堆中的,数组元素相当于对象的成员变量。\n\n\n下标的合法区间：[0,length-1]\n\n\n","tags":["java基础"]},{"title":"java day09 数组","url":"/2021/07/16/java%20day09%20%E6%95%B0%E7%BB%84/","content":"01 数组的使用\n配合for循环使用\n\npublic class Hello &#123;    public static void main(String[] args) &#123;      int[] a = &#123;1,2,3,4,5&#125;;      //打印全部的数组元素        for(int i = 0;i&lt;a.length;i++)&#123;            System.out.println(a[i]);        &#125;        System.out.println(&quot;============&quot;);        //计算所有数组的和        int sum = 0;        for(int i = 0;i&lt;a.length;i++)&#123;            sum+=a[i];        &#125;        System.out.println(&quot;总和&quot;+sum);        System.out.println(&quot;============&quot;);        //查找最大的数        int max = a[0];        for(int i = 0;i&lt;a.length;i++)&#123;           if(a[i]&gt;max)&#123;               max = a[i];           &#125;        &#125;        System.out.println(&quot;最大数&quot;+max);    &#125;&#125;\n\n\nFor-Each循环\n\npublic class Hello &#123;    public static void main(String[] args) &#123;      int[] a = &#123;1,2,3,4,5&#125;;        for (int i : a) &#123;//i就是数组元素，a就代表数组            System.out.println(i);        &#125;    &#125;&#125;\n\n\n数组作方法入参\n\n////打印全部的数组元素public class Hello &#123;    public static void main(String[] args) &#123;      int[] a = &#123;1,2,3,4,5&#125;;      printArray(a);    &#125;    public static  void printArray(int[] a)&#123;        for (int i = 0;i&lt;a.length;i++)&#123;            System.out.println(a[i]);        &#125;    &#125;&#125;\n\n\n数组作返回值\n\n//反转数组public class Hello &#123;    public static void main(String[] args) &#123;      int[] a = &#123;1,2,3,4,5&#125;;      int[] reverse = reverse(a);      printArray(reverse);    &#125;    public  static int[] reverse(int[] a)&#123;        int[] b = new int[a.length];        for(int i = 0,j = b.length-1;i&lt;b.length;i++,j--)&#123;            b[j] = a[i];        &#125;        return b;    &#125;    public static  void printArray(int[] a)&#123;        for (int i = 0;i&lt;a.length;i++)&#123;            System.out.println(a[i]);        &#125;    &#125;&#125;\n\n02 二维数组int a[][] = new int[2][5];int[][] b = &#123;&#123;1,2&#125;,&#123;3,4&#125;,&#123;5,6&#125;&#125;;\n\n03 Arrays类\n数组的工具类java.util.Arrays\nArrays类中的方法都是static修饰的静态方法，在使用的时候可以直接使用类名进行调用，而不用适用对象来调用。\n\nint[] a =&#123;1,2,3,55645,121,11&#125;;//数组进行排序   Arrays.sort(a);//数组进行填充   Arrays.fill(a,2,4,0);//从2到4之间进行填充//打印数组元素   System.out.println(Arrays.toString(a));","tags":["java基础"]},{"title":"java day11 稀疏数组","url":"/2021/07/18/java%20day11%20%E6%95%B0%E7%BB%84/","content":"稀疏数组public class Hello &#123;    public static void main(String[] args) &#123;        //1.创建一个二维数组11*11        int[][] array1 = new int[11][11];        array1[1][2] = 1;        array1[2][3] = 2;        //2.输出原始数组        System.out.println(&quot;输出原始数组&quot;);        for (int[] ints : array1) &#123;//ints 相当于array1的每一行            for (int anInt : ints) &#123;//anInt相当于每一个元素                System.out.print(anInt+&quot;\\t&quot;);            &#125;            System.out.println();        &#125;        //3.获取有效数值        int sum = 0;        for (int i = 0; i &lt; 11; i++) &#123;            for (int j = 0; j &lt; 11; j++) &#123;                if(array1[i][j]!=0)&#123;                    sum++;                &#125;            &#125;        &#125;        System.out.println(&quot;有效个数&quot;+sum);        //4.创建一个稀疏矩阵数组        int[][] array2 = new int[sum+1][3];        array2[0][0] = 11;        array2[0][1] = 11;        array2[0][2] = 2;        //5.遍历二位数组，有非零值，存放在稀疏矩阵中        int cout = 0;        for(int i =0;i&lt;array1.length;i++)&#123;            for(int j =0;j&lt;array1[i].length;j++)&#123;                if(array1[i][j]!=0)&#123;                    cout++;                    array2[cout][0] = i;                    array2[cout][1] = j;                    array2[cout][2] = array1[i][j];                &#125;            &#125;        &#125;        //6.输出稀疏数组        System.out.println(&quot;稀疏数组：&quot;);        for (int i = 0;i&lt; array2.length;i++)&#123;            System.out.println(array2[i][0]+&quot;\\t&quot;                    +array2[i][1]+&quot;\\t&quot;                    +array2[i][2]+&quot;\\t&quot; );        &#125;        //7.读取稀疏矩阵        int[][] array3 = new int[array2[0][0]][array2[0][1]];        //8.给其他元素还原        for(int i = 1;i&lt; array2.length;i++)&#123;            array3[array2[i][0]][array2[i][1]] = array2[i][2];        &#125;        //9.打印        System.out.println(&quot;还原数组：&quot;);        for (int[] ints : array3) &#123;//ints 相当于array1的每一行            for (int anInt : ints) &#123;//anInt相当于每一个元素                System.out.print(anInt+&quot;\\t&quot;);            &#125;            System.out.println();        &#125;&#125;    &#125;\n\n输出原始数组0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t有效个数2稀疏数组：11\t11\t2\t1\t2\t1\t2\t3\t2\t还原数组：0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n\n","tags":["java基础"]},{"title":"java day12 面向对象","url":"/2021/07/20/java%20day12%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":"01 什么是面向对象\n属性+方法&#x3D;类 \n面向过程思想\n步骤清晰简单，第一步做什么，第二部做什么….\n面向过程适合处理一些较为简单的问题\n\n\n面向对象思想\n物以类聚，分类的思维模式\n面向对象适合处理复杂的问题\n\n\n对于描述复杂的事务，为了从宏观上把握，从整体上合理分析，我们需要使用面向对象的思想来分析整个系统。但是，具体到微观操作，仍然需要面向过程的思想。\n面向对象编程的本质：以类的方式组织代码，以对象的组织（封装）数据。\n三大特性：封装、继承、多态\n\n02 回顾方法\n当一个类调用静态方法时，调用形式：类名+方法名\n\npublic class Student &#123;    public static void say() &#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;public class Hello &#123;    public static void main(String[] args) &#123;        Student.say();&#125;    &#125;\n\n\n当调用非静态方法时，调用形式：将这个类实例化\n\npublic class Student &#123;    public  void say() &#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;public class Hello &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.say();&#125;    &#125;\n\n\nstatic是和类一起加载的，而不含static的是在类实例化之后才存在，所以下面代码是错误的\n\npublic  static void a()&#123;        b();&#125;public void b()&#123;&#125;\n\n\n一个类中只有一个public class,但是有很多class。\n\n03 类和对象的关系\n使用new关键字创建对象，除了分配内存空间，还会初始化，以及对类中构造器的使用。\n一个项目应该只存在一个main方法\n\npublic class Student &#123;    //属性:字段    String name;    int age;    //方法    public  void study() &#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        //类：抽象的，实例化        //类实例化后会返回一个自己的对象        //student对象就是一个Student类的具体实例。        Student xm = new Student();        Student xh = new Student();        xm.name = &quot;xiaoming&quot;;        xm.age = 3;        System.out.println(xm.name);//xiaoming        System.out.println(xm.age);//3        System.out.println(xh.name);//默认值null        System.out.println(xh.age);//默认值0        xh.study();//hello    &#125;&#125;\n\n04 构造器详解\n一个类即使什么都不写，也会构造一个方法。\n\n构造器：\n\n特点：必须和类的名字相同；必须没有返回类型，也不能写void。\n作用：new本质就是调用构造方法；初始化对象的值。\n注意点：定义有参构造之后，如果想使用无参构造，必须显示的定义一个无参构造。\n\n\n调用无参构造函数\n\n\n\npublic class Student &#123;    String name;    public Student()&#123;        this.name = &quot;xiaofang&quot;;    &#125;    public Student(String name)&#123;        this.name = name;//this.name代表对象本身的name,name是传递下来的name。    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;     Student student = new Student();        System.out.println(student.name);//xiaofang    &#125;&#125;\n\n\n调用有参构造函数\n\npublic class Student &#123;    String name;    public Student()&#123;        this.name = &quot;xiaofang&quot;;    &#125;    public Student(String name)&#123;        this.name = name;//this.name代表对象本身的name,name是传递下来的name。    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;     Student student = new Student(&quot;xiaoxu&quot;);        System.out.println(student.name);//xiaoxu    &#125;&#125;","tags":["java基础"]},{"title":"java day10 冒泡排序","url":"/2021/07/17/java%20day10%20%E6%95%B0%E7%BB%84/","content":"01 冒泡排序冒泡排序：两层循环，外层冒泡轮数，里层依次比较。\npublic class Hello &#123;    public static void main(String[] args) &#123;        int[] a = &#123;1, 2, 3, 8, 11, 1, 55, 12&#125;;        int[] array = sort(a);        System.out.println(Arrays.toString(array));    &#125;    public static int[] sort(int[] array) &#123;        int temp = 0;        for (int i = 0; i &lt; array.length - 1; i++) &#123;            boolean flag = false;            for (int j = 0; j &lt; array.length - 1; j++) &#123;                if (array[j + 1] &lt; array[j]) &#123;                    temp = array[j + 1];                    array[j + 1] = array[j];                    array[j] = temp;                    flag = true;                &#125;            &#125;                if (flag == false) &#123;                    break;                &#125;        &#125;        return array;    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day13 面向对象三大特征1","url":"/2021/07/21/java%20day13%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A71/","content":"01 封装\n我们程序设计追求高内聚低耦合。\n高内聚：类的内部数据操作细节自己完成，不允许外部干涉。\n低耦合：仅暴露少量的方法给外部使用。\n\n\n封装的意义：\n提高程序的安全性，保护数据\n隐藏代码的实现细节\n统一接口\n系统可维护增加了\n\n\n属性私有，get&#x2F;set\n信息隐藏：禁止直接访问一个对象中数据的实际表示，而应通过操作接口来访问。\n\npublic class Student &#123;    //属性私有    private String name;//姓名    private int id;//学号    private char sex;//性别    //get 获得这个数据    public String getName()&#123;        return this.name;    &#125;    //set 给这个数据设置值    public void setName(String name)&#123;        this.name = name;    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.setName(&quot;小方&quot;);        System.out.println(student.getName());    &#125;&#125;\n\n02 继承\n继承的本质是对某一批类的抽象，从而实现对现实世界更好的建模。\nextends的意思是”扩展”。子类是父类的扩展。\nJAVA只有单继承，没有多继承。一个爸爸可以有多个儿子，一个儿子只能有一个爸爸。\n继承是类与类之间的一种关系\n\npublic class Person &#123;    public void say()&#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;public class Student extends Person &#123;&#125;public class Application &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.say();//hello    &#125;&#125;\n\n\n私有的东西无法被继承。\n在Java中，所有的类，都默认直接或者间接继承object\n\n03 Super\nsuper注意点：\n\nsuper调用父类的构造方法，必须在构造方法的第一个\nsuper必须只能出现在子类的方法或者构造方法中。\nsuper和this不能同时调用构造方法。\n\n\nsuper VS this\n\n代表的对象不同：this（本身调用这个对象），super（代表父类对象的引用）。\n前提：this（没有继承也可以使用），super（只有在继承条件下才可以使用）。\n构造方法：this():本类的构造，super():父类的构造\n\npublic class Person &#123;    public Person()&#123;        System.out.println(&quot;Person无参&quot;);    &#125;    protected String name = &quot;xiaofang&quot;;    public void print()&#123;        System.out.println(&quot;Person&quot;);    &#125;&#125;public class Student extends Person &#123;    //隐藏代码：调用父类的无参构造    public Student()&#123;        super();        System.out.println(&quot;Student无参&quot;);    &#125;    private String name = &quot;xiaoxu&quot;;    public void print()&#123;        System.out.println(&quot;student&quot;);    &#125;    public  void test(String name)&#123;        System.out.println(name);//方        System.out.println(this.name);//xiaoxu        System.out.println(super.name);//xiaofang    &#125;    public  void test1()&#123;        print();//student        this.print();//student        super.print();//Person    &#125;&#125;public class Application &#123;    public Application() &#123;    &#125;    public static void main(String[] args) &#123;        Student student = new Student();//先调用父类Person无参，在调用子类Student无参        student.test(&quot;方&quot;);        student.test1();    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day13 面向对象三大特征2","url":"/2021/07/28/java%20day13%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A72/","content":"01 方法重写\n重写：需要有继承关系，子类重写父类的方法！\n\n方法名必须相同\n参数列表必须相同\n修饰符：范围可以扩大但是不能缩小（public&gt;Protected&gt;Default&gt;private）\n抛出的异常：范围可以缩小但是不能扩大\n快捷键：Alt+Insert(override)\n\n\n为什么需要重写：因为父类的功能，子类不一定需要，或者不一定满足\n\n静态的方法和非静态方法差别很大：\n\n静态方法：方法的调用只和左边定义的数据类型有关\n\npublic class Person &#123;    public static void print()&#123;        System.out.println(&quot;Person&quot;);    &#125;&#125;public class Student extends Person &#123;    public static void print()&#123;        System.out.println(&quot;Student&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.print();//Student        //父类的引用指向了子类        Person person = new Student();        person.print();//Person    &#125;&#125;\n\n\n非静态方法：重写\n\n\n\npublic class Person &#123;    public void print()&#123;        System.out.println(&quot;Person&quot;);    &#125;&#125;public class Student extends Person &#123;    public void print()&#123;        System.out.println(&quot;Student&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.print();//Student        //父类的引用指向了子类        Person person = new Student();        person.print();//Student    &#125;&#125;\n\n02 多态多态就是同一方法可以根据发送对象的不同而采用多种不同的行为方式。\n\n\n多态注意事项：\n\n多态时方法的多态，属性没有多态\n存在条件：继承关系，方法需要重写，父亲引用指向子类对象\n\n\n不能重写的方法：\n\nstatic方法属于类不属于实例\nfinal常量\nprivate方法\n\n\n\npublic class Person &#123;    public void print()&#123;        System.out.println(&quot;Person&quot;);    &#125;&#125;public class Student extends Person &#123;    public void print()&#123;        System.out.println(&quot;Student&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        //一个对象的实际类型是确定的--&gt;new Student(); new Person()        //可以指向的引用类型就不确定了：父类的引用指向子类        //Student能调用的方法都是自己的或者继承父类的        Student student = new Student();        student.print();//Student        //Person父类型可以指向子类，但是不能调用子类独有的方法        Person person = new Student();        person.print();//Student    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day14 面向对象","url":"/2021/07/29/java%20day14%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":"01 instanceof和类型转换\ninstanceof的格式是System.out.println(x instanceof y);如果x和y是同一类型或者能类型转换（兄弟之间不能类型转换，父子之间可以类型转换）则编译通过，否则不通过。编译通过后会把x和y比较，如果x是y本类或者子类的对象，结果就是true，反之就是flase。\n\npublic class Application &#123;    public static void main(String[] args) &#123;        //Object &gt; String        //Object &gt; Person &gt; Teacher        //Object &gt; Person &gt; Student        Object object = new Student();        System.out.println(object instanceof Object);//true        System.out.println(object instanceof Person);//true        System.out.println(object instanceof Teacher);//false        System.out.println(object instanceof Student);//true        System.out.println(object instanceof String);//false        System.out.println(&quot;=========================&quot;);        Person person = new Student();        System.out.println(person instanceof Object);//true        System.out.println(person instanceof Person);//true        System.out.println(person instanceof Teacher);//false        System.out.println(person instanceof Student);//true        //System.out.println(person instanceof String);编译不通过        System.out.println(&quot;=========================&quot;);        Student student = new Student();        System.out.println(student instanceof Object);//true        System.out.println(student instanceof Person);//true        //System.out.println(student instanceof Teacher);编译不通过        System.out.println(student instanceof Student);//true        //System.out.println(student instanceof String);编译不通过        System.out.println(&quot;=========================&quot;);    &#125;&#125;\n\n\n类型转换：\n把子类转换成父类，向上转型\n把父类转换成子类，向下转型：强制转换\n\n\n\npublic class Student extends Person &#123;    public void go()&#123;        System.out.println(&quot;Student&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        //高转低        Person obj = new Student();        //方法一        Student student = (Student) obj;        student.go();//Student        //方法二        ((Student) obj).go();//Student        //低转高可能丢失一些自己本来的方法        Student student = new Student();        Person person = student;       //person.go();报错！    &#125;&#125;\n\n02 static关键字详解\n对于代码块来说：\n\npublic class Person &#123;    &#123;        System.out.println(&quot;匿名代码块&quot;);    &#125;    static &#123;        System.out.println(&quot;静态代码块&quot;);//只执行一次    &#125;    public Person()&#123;        System.out.println(&quot;构造方法&quot;);    &#125;    public static void main(String[] args) &#123;        Person p1 = new Person();        System.out.println(&quot;==========&quot;);        Person p2 = new Person();    &#125;&#125;                                /*静态代码块                                匿名代码块                                构造方法                                ==========                                匿名代码块                                构造方法*/\n\n\n非静态方法和静态方法可以调用静态方法，而静态方法不能调用非静态方法。\n静态导入包：\n\n//静态导入包import static java.lang.Math.random;public class Person &#123;    public static void main(String[] args) &#123;        System.out.println(random());//这就可以直接使用random()，而不用Math.random()    &#125;&#125;\n\n\n调用非静态方法必须new一个对象进行调用，而调用静态方法可以直接用类调用，比如Student.run()。\n在方法中调用变量：调用非静态变量不能直接用类调用，要创建一个对象进行调用，而调用静态变量既可以用类进行调用，也可以用对象进行调用。\n\n03 抽象类\nabstract修饰符，如果修饰方法就是抽象方法，如果修饰类就是抽象类。\n抽象类中可以没有抽象方法，但是只要有抽象方法，必须声明抽象类。\n抽象类不能用new实例化。\n抽象方法只有方法的声明而没有具体实现，实现是让子类来完成的。\n子类继承抽象类，就必须实现抽象类中没有实现的抽象方法，否则子类也要声明为抽象类。\n\npublic abstract class Application &#123;   public abstract void run();   public void go()&#123;       System.out.println(&quot;有普通方法也是可以的&quot;);   &#125;&#125;\n\n04 接口\n接口的本质是契约，是对对象的抽象\n用interface定义接口\n接口的作用：\n约束\n定义一些方法，让不同的人实现（10个人可以实现一个接口）\n接口中的所有定义的方法其实都是抽象的 public abstract\n接口中的所有定义的变量其实都是静态常量 public static final\n接口也不能被实例化（没有构造方法）\nimplements可以实现多个接口，就是相当于多继承\n实现接口，必须要做重写接口中方法\n\n\n\npublic interface Person &#123;    void add(String name);    void delete(String name);    void update(String name);    void query(String name);&#125;public interface Teacher  &#123;    void run();&#125;//Ait+insert直接生成的重写方法public class Student implements Person,Teacher &#123;    @Override    public void add(String name) &#123;    &#125;    @Override    public void delete(String name) &#123;    &#125;    @Override    public void update(String name) &#123;    &#125;    @Override    public void query(String name) &#123;    &#125;    @Override    public void run() &#123;    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day15 异常","url":"/2021/07/30/java%20day15%E5%BC%82%E5%B8%B8/","content":"01 Error和Exception\n异常是指程序运行时出现的不期而至的各种状况，如：文件找不到、网络连接失败、非法参数。\n三种类型的异常：\n检查性异常：是用户错误或问题引起的异常，这时程序员无法遇见的。比如打开一个不存在的文件。\n运行时异常：是可能被程序员避免的异常。\n错误：错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如堆栈溢出，在编译时也检测不到。\n\n\nJava把异常当作对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。\n这些异常通常分为两大类：错误Error和异常Exception\n在Exception分支中有一个重要的子类RuntimeException（运行时异常）：\nArrayIndexOutOfBoundsException（数组下标越界）\nNullPointerException（空指针异常）\nArithmeticException（算数异常）\nMissingResourceException（丢失资源）\nClassNotFoundException（找不到类）\n\n\n\n02 捕获和抛出异常\n异常处理五个关键字：try、catch、finally、throw、throws\n\n//方法一public abstract class Application &#123;    public static void main(String[] args) &#123;        int a = 1;        int b = 0;        //假设要捕获多个异常：从小到大        try&#123;//try监控区域            System.out.println(a/b);        &#125;catch(Error e)&#123;            System.out.println(&quot;Error&quot;);        &#125;catch(Exception e)&#123;            System.out.println(&quot;Exception&quot;);        &#125;catch (Throwable t)&#123;            System.out.println(&quot;Throwable&quot;);        &#125;finally &#123;//处理善后工作            System.out.println(&quot;finally&quot;);        &#125;    &#125;&#125;//打印出Exception和finally//方法二public abstract class Application &#123;    public static void main(String[] args) &#123;        int a = 1;        int b = 0;        //通过Ctrl+Alt+t快捷键来完成        try &#123;            System.out.println(a/b);        &#125; catch (Exception e) &#123;            e.printStackTrace();//打印错误的栈信息        &#125; finally &#123;        &#125;    &#125;&#125;//打印出ava.lang.ArithmeticException: / by zero//方法三public  class Application &#123;    public static void main(String[] args) &#123;        new Application().test(1,0);    &#125;    public void test(int a, int b)&#123;        if(b==0)&#123;            throw new ArithmeticException();//主动抛出异常        &#125;    &#125;&#125;//打印出Exception in thread &quot;main&quot; java.lang.ArithmeticException//方法四public  class Application &#123;    public static void main(String[] args) &#123;        try &#123;            new Application().test(1,0);        &#125; catch (ArithmeticException e) &#123;            e.printStackTrace();        &#125;    &#125;    //假设方法处理不了这个异常。那么就将其向上抛出，在方法上抛出。    public void test(int a, int b)throws ArithmeticException&#123;        if(b==0)&#123;            throw new ArithmeticException();//主动抛出异常        &#125;    &#125;&#125;//输出java.lang.ArithmeticException\n\n03 自定义异常\n自定义异常类，大体可以分为以下几个步骤：\n创建自定义异常类\n在方法中通过throw关键字抛出异常对象\n如果在当前抛出异常的方法中处理异常，可以使用try-catch语句捕获并处理；否则在方法的声明处通过throws关键字指明要抛出给方法调用者的异常，继续进行下一步操作\n在出现异常方法的调用者中捕获并处理异常\n\n\n\npublic class MyException extends Exception&#123;    //传递数字&gt;10    private  int detail;    public MyException(int a) &#123;        this.detail = a;    &#125;    //toString:异常的打印信息    @Override    public String toString() &#123;        return &quot;MyException&#123;&quot; + &quot;detail=&quot; + detail + &#x27;&#125;&#x27;;    &#125;&#125;public  class Application &#123;    public static void main(String[] args) &#123;        try &#123;            new Application().test(11);        &#125; catch (MyException e) &#123;            System.out.println(&quot;MyException=&gt;&quot;+e);        &#125;    &#125;    //假设方法处理不了这个异常。那么就将其向上抛出，在方法上抛出。    public void test(int a)throws MyException&#123;        System.out.println(&quot;传递的参数为：&quot;+a);        if(a&gt;10)&#123;            throw new MyException(a);//主动抛出异常        &#125;        System.out.println(&quot;OK&quot;);    &#125;&#125;\n\n\n在实际应用中的经验：\n处理运行时异常时，采用逻辑去合理规避同时辅助try-catch处理\n在多重catch块后面，可以加一个catch(Exception)来处理可能会被遗漏的异常\n对于不确定的代码，也可以加上try-catch，处理潜在的异常（当在IDEA中出现红色波浪线可以Alt+Enter）\n尽量去处理异常，不要只是简单的调用printStackTrace()去打印输出\n尽量添加finally语句块去释放占用资源\n\n\n\n","tags":["java基础"]},{"title":"1编程作业：线性回归","url":"/2021/08/06/1%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","content":"原任务是在Octave&#x2F;MATLAB实现，本次编程作业全部以python完成。\n\n01 简单的练习总结下题目：输出一个5*5的单位矩阵\n\n\n在此我们用np.eye(N,M&#x3D;None, k&#x3D;0, dtype&#x3D;&lt;type ‘float’&gt;)，首先N代表的是输出方阵的维度，第二个参数不用设置默认M&#x3D;N，主要看第三个参数，默认是对角线为1，其余全为0；如果k为正数，则对角线往上第k个全为1，其余全为0；如果k为负数，则对角线往下第k个全为1，其余全为0。\n\nimport numpy as npA = np.eye(5)print(A)&quot;&quot;&quot;[[1. 0. 0. 0. 0.] [0. 1. 0. 0. 0.] [0. 0. 1. 0. 0.] [0. 0. 0. 1. 0.] [0. 0. 0. 0. 1.]]&quot;&quot;&quot;\n\n02 单变量线性回归根据这座城市的人口数量及该城市小吃店的利润，来预测开小吃店的利润。\n\n2.1 绘制数据\n读入数据：在此我们引入pandas库，该库可以帮助我们从诸如 csv 类型的文件导入数据，并且可以用它快速的对数据进行转换和过滤的操作。\n\nimport pandas as pdpath = &quot;machine-learning-ex1\\machine-learning-ex1\\ex1\\ex1data1.txt&quot;data = pd.read_csv(path,header=None,names=[&#x27;Population&#x27;,&#x27;Profit&#x27;])#header决定要不要原始的表头，name给出自定义的表头。print(data.head())#从头查询数据&quot;&quot;&quot;   population   profit0      6.1101  17.59201      5.5277   9.13022      8.5186  13.66203      7.0032  11.85404      5.8598   6.8233&quot;&quot;&quot;\n\n\n数据可视化：在此我们引入matplotlib.pyplot库，使用plot函数画图。\n\nimport matplotlib.pyplot as pltdata.plot(kind=&#x27;scatter&#x27;, x=&#x27;Population&#x27;, y=&#x27;Profit&#x27;, figsize=(12,8))#生成图形，kind‘指定所画图的类型，figsize 指定图片大小。plt.show()#显示图形\n\n\n2.2 梯度下降这部分需要使用梯度下降将线性回归参数 θ 拟合到数据集上。\n2.21 公式\n代价函数\n\n\n\n假设函数\n\n\n\n参数更新\n\n\n\n随着梯度下降不断地更新参数，参数也就越接近使代价函数最小的最优值\n\n2.22 实现\n我们要为我们之前读取的数据添加一列x，用来更新θ_0。\n\ndata.insert(0, &#x27;Ones&#x27;, 1) #相当于在第0列，添加一个表头名为Ones，并且该列均为1print(data.head())&quot;&quot;&quot;   Ones  Population   Profit0     1      6.1101  17.59201     1      5.5277   9.13022     1      8.5186  13.66203     1      7.0032  11.85404     1      5.8598   6.8233&quot;&quot;&quot;\n\n\n分割X和y。使用pandas的iloc来进行选择训练集X和目标y\n\n# 分割X和ylists = data.shape[1]#输出列数X = data.iloc[:,:-1]#X是第一列到最后一列，但不包括最后一列，因为 python的范围/切片不包括终点y = data.iloc[:,lists-1:lists]#最后一列#y = data.iloc[:,-1]#也是最后一列print(X.head())&quot;&quot;&quot;   Ones  Population0     1      6.11011     1      5.52772     1      8.51863     1      7.00324     1      5.8598&quot;&quot;&quot;print(y.head())&quot;&quot;&quot;    Profit0  17.59201   9.13022  13.66203  11.85404   6.8233&quot;&quot;&quot;\n\n\n我们还要将θ初始化为0，并将θ、X、y全部转化为矩阵\n\nX = np.matrix(X.values)y = np.matrix(y.values)theta = np.matrix(np.array([0,0]))print(X.shape)#(97, 2)print(y.shape)#(97, 1)print(theta.shape)#(1, 2)\n\n2.23 计算J(θ)\n计算代价函数来检测代价函数的收敛性。根据上面的公式我们写出代价函数。\n\ndef computeCost(X, y, theta):    inner = np.power((X * theta.T)-y,2)#数组元素求n次方    return np.sum(inner) / (2 * len(X))print(computeCost(X, y, theta)) #32.072733877455676\n\n2.24 梯度下降代价函数J(θ)的参数是由向量θ表示，假设你已经实现了梯度下降，如果计算正确，J(θ)的值不应该增加，而应该减小然后在算法结束时收敛到一个稳定值。\ndef gradientDescent(X, y, theta, alpha, iters):    temp = np.matrix(np.zeros(theta.shape))#创建0矩阵[[0. 0.]]    parameters = int(theta.ravel().shape[1]) #ravel()将多维数组转换为一维数组,.shape[1]是看列数为多少-2    cost = np.zeros(iters)#初始化代价函数数组    for i in range(iters):        error = (X * theta.T) - y        for j in range(parameters):            term = np.multiply(error, X[:, j])            temp[0, j] = theta[0, j] - ((alpha / len(X)) * np.sum(term))#更新参数        theta = temp        cost[i] = computeCost(X, y, theta)    return theta, costalpha = 0.01iters = 1500g, cost = gradientDescent(X, y, theta, alpha, iters)print(g)#[[-3.63029144  1.16636235]]predict1 = [1,3.5]*g.Tprint(predict1)#[[0.45197679]]predict2 = [1,7]*g.Tprint(predict2)#[[4.53424501]]\n\n2.3 调试\npython可视化：原始数据以及拟合的直线\n\n# 在指定的间隔内返回均匀间隔的数字：从data.Population的最小值到最大的范围内，等间距的返回100个样本x = np.linspace(data.Population.min(), data.Population.max(), 100)f = g[0, 0] + (g[0, 1] * x)#参数为最优值的直线fig, ax = plt.subplots(figsize=(12,8))#创建一个12*8的图即多维窗口ax.plot(x, f, &#x27;r&#x27;, label=&#x27;Prediction&#x27;) #定义x, y, 颜色，图例上显示的东西ax.scatter(data.Population, data.Profit, label=&#x27;Traning Data&#x27;)ax.legend(loc=2)#指定图例的位置ax.set_xlabel(&#x27;Population&#x27;)ax.set_ylabel(&#x27;Profit&#x27;)ax.set_title(&#x27;Predicted Profit vs. Population Size&#x27;)plt.show()\n\n\n03 多变量线性回归根据ex1data2.txt里的数据建立模型，预测房屋的价格，其中第一列是房屋大小，第二列是卧室数量，第三列是房屋售价\n\n\n第一步依旧是读入数据：\n\npath = &#x27;machine-learning-ex1\\machine-learning-ex1\\ex1\\ex1data2.txt&#x27;data2 = pd.read_csv(path,header = None,names=[&#x27;Size&#x27;, &#x27;Bedrooms&#x27;, &#x27;Price&#x27;])print(data2.head())&#x27;&#x27;&#x27; Size  Bedrooms   Price0  2104         3  3999001  1600         3  3299002  2400         3  3690003  1416         2  2320004  3000         4  539900&#x27;&#x27;&#x27;\n\n3.1 特征归一化特征缩放的目的只是为了运行更快。使特征值比较接近，使图像变得比较圆。以至于梯度下降的速度更快，收敛所需要的迭代次数更少，收敛更快。\n\n\nmean()函数功能：求取均值，std()函数是用来求标准差的（std &#x3D; sqrt(mean(abs(x - x.mean())**2))）。\n\ndata2 = (data2 - data2.mean()) / data2.std()print(data2.head())&#x27;&#x27;&#x27;      Size  Bedrooms     Price0  0.130010 -0.223675  0.4757471 -0.504190 -0.223675 -0.0840742  0.502476 -0.223675  0.2286263 -0.735723 -1.537767 -0.8670254  1.257476  1.090417  1.595389&#x27;&#x27;&#x27;\n\n3.2 梯度下降data2.insert(0, &#x27;Ones&#x27;, 1)cols = data2.shape[1]X2 = data2.iloc[:,0:cols-1]y2 = data2.iloc[:,cols-1:cols]X2 = np.matrix(X2.values)y2 = np.matrix(y2.values)theta2 = np.matrix(np.array([0,0,0]))g2, cost2 = gradientDescent(X2, y2, theta2, alpha, iters)print(g2)&#x27;&#x27;&#x27;[[-1.10898288e-16  8.84042349e-01 -5.24551809e-02]]&#x27;&#x27;&#x27;\n\n3.3 正规方程训练集特征矩阵为 X（包含了x_0&#x3D;1）训练集结果为向量 y，则利用正规方程解出向量:其中np.linalg.inv()：矩阵求逆。\n\ndef normalEqn(X, y):    theta = ((np.linalg.inv(X.T.dot(X))).dot(X.T)).dot(y)    # theta = np.linalg.inv(X.T@X)@X.T@y    return thetatheta2=normalEqn(X2, y2)print(theta2)&#x27;&#x27;&#x27;[[-7.11223170e-17] [ 8.84765988e-01] [-5.31788197e-02]] &#x27;&#x27;&#x27;\n\n04 代码总结import matplotlib.pyplot as pltimport numpy as npimport pandas as pdpath = &quot;machine-learning-ex1\\machine-learning-ex1\\ex1\\ex1data1.txt&quot;data = pd.read_csv(path,header=None,names=[&#x27;Population&#x27;,&#x27;Profit&#x27;])#header决定要不要原始的表头，name给出自定义的表头。#data.plot(kind=&#x27;scatter&#x27;, x=&#x27;Population&#x27;, y=&#x27;Profit&#x27;, figsize=(12,8))#生成图形，kind‘指定所画图的类型，figsize 指定图片大小。# plt.show()#显示图形#==============================================================================data.insert(0, &#x27;Ones&#x27;, 1) #相当于在第0列，添加一个表头名为Ones，并且该列均为1# 分割X和ylists = data.shape[1]#输出列数X = data.iloc[:,:-1]#X是第一列到最后一列，但不包括最后一列，因为 python的范围/切片不包括终点y = data.iloc[:,lists-1:lists]#最后一列#y = data.iloc[:,-1]#也是最后一列X = np.matrix(X.values)y = np.matrix(y.values)theta = np.matrix(np.array([0,0]))def computeCost(X, y, theta):    inner = np.power((X * theta.T)-y,2)#数组元素求n次方    return np.sum(inner) / (2 * len(X))# print(computeCost(X, y, theta)) #32.072733877455676#梯度下降算法如下：def gradientDescent(X, y, theta, alpha, iters):    temp = np.matrix(np.zeros(theta.shape))#创建0矩阵[[0. 0.]]    parameters = int(theta.ravel().shape[1]) #ravel()将多维数组转换为一维数组,.shape[1]是看列数为多少    cost = np.zeros(iters)    for i in range(iters):        error = (X * theta.T) - y        for j in range(parameters):            term = np.multiply(error, X[:, j])            temp[0, j] = theta[0, j] - ((alpha / len(X)) * np.sum(term))        theta = temp        cost[i] = computeCost(X, y, theta)    return theta, costalpha = 0.01iters = 1500g, cost = gradientDescent(X, y, theta, alpha, iters)#print(g)#[[-3.63029144  1.16636235]]predict1 = [1,3.5]*g.T#print(predict1)#[[0.45197679]]predict2 = [1,7]*g.T#print(predict2)#[[4.53424501]]# 在指定的间隔内返回均匀间隔的数字：从data.Population的最小值到最大的范围内，等间距的返回100个样本x = np.linspace(data.Population.min(), data.Population.max(), 100)f = g[0, 0] + (g[0, 1] * x)#参数为最优值的直线fig, ax = plt.subplots(figsize=(12,8))#创建一个12*8的图即多维窗口ax.plot(x, f, &#x27;r&#x27;, label=&#x27;Prediction&#x27;) #定义x, y, 颜色，图例上显示的东西ax.scatter(data.Population, data.Profit, label=&#x27;Traning Data&#x27;)ax.legend(loc=2)#指定图例的位置ax.set_xlabel(&#x27;Population&#x27;)ax.set_ylabel(&#x27;Profit&#x27;)ax.set_title(&#x27;Predicted Profit vs. Population Size&#x27;)#plt.show()#===========================================================================path = &#x27;machine-learning-ex1\\machine-learning-ex1\\ex1\\ex1data2.txt&#x27;data2 = pd.read_csv(path,header = None,names=[&#x27;Size&#x27;, &#x27;Bedrooms&#x27;, &#x27;Price&#x27;])data2 = (data2 - data2.mean()) / data2.std()data2.insert(0, &#x27;Ones&#x27;, 1)cols = data2.shape[1]X2 = data2.iloc[:,0:cols-1]y2 = data2.iloc[:,cols-1:cols]X2 = np.matrix(X2.values)y2 = np.matrix(y2.values)theta2 = np.matrix(np.array([0,0,0]))g2, cost2 = gradientDescent(X2, y2, theta2, alpha, iters)print(g2)def normalEqn(X, y):    theta = ((np.linalg.inv(X.T.dot(X))).dot(X.T)).dot(y)    # theta = np.linalg.inv(X.T@X)@X.T@y    return thetatheta2=normalEqn(X2, y2)print(theta2)\n","tags":["机器学习"]},{"title":"机器学习 day01初识机器学习","url":"/2021/07/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day01%E5%88%9D%E8%AF%86%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","content":"01 监督学习\n监督学习是指我们给算法一个数据集，其中包含了正确的答案。算法的目的就是给出更多的正确答案。\n回归是指我们设法预测连续值的属性，可以应用在预测房子价格等方面。\n分类是指我们设法预测离散值的输出(0或1)，可以应用在判断账户是否被入侵等方面。\n\n02 无监督学习\n无监督学习也会给一个数据集，但是数据集不包括正确答案(里面的数据要么都有相同的标签要么都没有标签)。无监督学习会将数据分为一个个不同的簇，这就是聚类算法。\n聚类算法可以应用在|搜集新闻并将相关新闻组合在一起|星系形成理论|市场销售等领域\n\n\n建议使用Octave免费开源的软件，许多学习算法都可以用几行代码将其实现。例如svd函数(奇异值分解)已经作为线性代数常规函数内置在Octave中了。\n","tags":["机器学习"]},{"title":"机器学习 day02单变量线性回归","url":"/2021/07/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day02%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","content":"01 模型描述为了更好的描述监督学习问题，需要给出训练集并以此构建一个模型。\n\n下面先学习几个符号：\n\nm:代表的是训练集有几个\nx:代表的是输入的特征\ny:代表的是输出，也就是预测的目标变量\nh:代表假设函数，引导从x得到y的函数\n\n02 代价函数（平方误差函数）\n可以通过代价函数来衡量假设函数的准确性。\n\n代价函数取值越小，假设函数就越准确。\n\n\n\n\n代价函数有助于我们弄清楚如何把最有可能的直线与我们的数据相拟合。\n\n在线性回归中，我们要解决的是最小化问题\n\n代价函数是解决回归问题最常用的手段\n\n\n\n03 梯度下降梯度下降法：可以将代价函数最小化\n\n一般将两个参数初始化为0，再不断的改变参数的值，使得代价函数取值达到最小。\n\n\na：代表学习率（永远为正），用来控制使用梯度下降时，迈出步子的大小。下面是a太小与太大的情况。\n\n\n\n导数的含义：针对于只有一个参数的，两种不同初始点的情况分析。\n\n\n\n事实上，当取值越接近最优解时，梯度下降的幅度也就越小，因为导数始终向0靠拢。\n\n\n04 线性回归的梯度下降\n将代价函数带入梯度下降算法，并求偏导数可得：\n\n\n\n将所求的偏导数带回梯度下降算法\n\n\n\n通过梯度下降算法，一步步的进行，最终可以得到与数据最拟合的直线\n\n\n","tags":["机器学习"]},{"title":"机器学习 day03线性代数基础","url":"/2021/07/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day03%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/","content":"01 矩阵与向量\n小写字母表示向量：a b c\n大写字母表示矩阵：A B C\n\n02 加法和标量乘法\n只有维度相同的矩阵才能相加\n一个数乘一个矩阵与一个矩阵乘一个数的结果相同\n\n\n03 矩阵向量乘法\n矩阵与向量相乘\n\n\n\n例子：\n\n\n\n将一个方程转化为矩阵向量相乘的形式\n\n\n04 矩阵相乘\n矩阵相乘计算原理：只需将第二个矩阵的每一列提取出来，计算矩阵与向量相乘，最终将其拼接成为最终答案。\n\n\n\n将三个方程转化为两个矩阵相乘的形式\n\n\n05 矩阵乘法特性\n不能使用乘法交换律（单位矩阵除外），会改变结果的维度及数值\n\n\n\n矩阵与实数一样，都符合乘法结合律\n\n\n06 逆和转置\n只有方阵才有逆矩阵\n\n\n\n矩阵的转置：将A的第一行变成A的转置的第一列，将A的第二行变成A的转置的第二列。。。。。。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day04多变量线性回归","url":"/2021/07/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day04%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","content":"01 多元线性回归–多特征向量情况下的假设形式\n一些符号表示：\n\n\n\n简化下面等式的表达方法：向量内积转化\n\n\n02 多元梯度下降算法\n多元线性回归方程+代价函数+梯度下降函数\n\n\n\n单元及多元线性回归的梯度下降法对比\n\n\n03 多元梯度下降法–特征缩放\n特征缩放的目的只是为了运行更快。使特征值比较接近，使图像变得比较圆。以至于梯度下降的速度更快，收敛所需要的迭代次数更少，收敛更快。缩放前后对比图如下：\n\n\n\n特征值的取值别太大也别太小，与下面这个范围足够接近最好。\n\n\n\n均值归一化的工作：X &#x3D;（当前值-平均值）&#x2F;【（最大值-最小值）只要是这个范围左右就可以】\n\n\n04 多元梯度下降法–学习率\n梯度算法正常工作图如下：代价函数随迭代次数的变化，最终收敛。\n\n\n\n如果所得图像不是一直减小的，那么需要减小学习率，当然学习率也不能过小，否则梯度下降将会十分缓慢，迭代次数无限增加。\n\n\n\n得到一个不错的学习率：按照三的倍数来取值，尝试一系列的学习率，找到个太小的值，再找到另一个太大的值，然后取太大的值，或者比太大的值略小的比较合理的值\n\n\n05 特征和多项式回归\n特征可以根据自己的需求选择合适的特征，例如将两个不同的特征相乘得到一个新的特征\n如果只用多次函数，适当使用特征缩放将起到很好的效果：\n\n\n\n可以有多种合理的选择，比如也可以是平方根。\n\n\n06 正规方程–区别于迭代方法的直接解法\n正规方程：对代价函数求偏导数，并将其置0，就可以得到使代价函数最小的值。\n\n\n\n方程的形式及例子：\n\n\n\n使用正规方程就不用对特征进行缩放了。\n\n选择合适的算法（梯度下降还是正规方程）一般特征&lt;10000时选用正规方程直接求解，他们二者的优缺点：\n\n\n\n07 正规方程在矩阵不可逆情况下的解决方法\n在Octave中pinv（伪逆）与inv（逆）是求逆矩阵的，就算矩阵没有逆，pinv也会求出它的逆。\n\n首先看是否有多余的特征（两个特征线性相关），选择进行删除，直到没有多余的为止；再观察是否特征过多，选择没有影响的特征进行删除。\n\n\n\n","tags":["机器学习"]},{"title":"机器学习 day05Octave教程","url":"/2021/07/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day05Octave%E6%95%99%E7%A8%8B/","content":"01 基本操作\n注释表达：%\n&gt;&gt; 1~= 2 %注释ans = 1\n\n\n\n不等号表达：~&#x3D;\n&gt;&gt; 1~= 2ans = 1\n\n\n\n隐藏提示命令：PS1(‘&gt;&gt; ‘);\noctave:6&gt; PS1(&#x27;&gt;&gt; &#x27;);&gt;&gt;\n\n\n\n想分配一个变量，但是不想在屏幕上显示结果：只需在结尾加分号（;）\n&gt;&gt; a = pi;&gt;&gt; a = pia = 3.1416\n\n\n\n显示命令：disp( );\n&gt;&gt; disp(a);3.1416\n\n用disp( );显示字符串\n&gt;&gt; disp(sprintf(&#x27;2 decimals:%0.2f&#x27;,a)) %0.2f:小数点后两位2 decimals:3.14\n\n显示更多的小数点后几位：format long\n&gt;&gt; format long&gt;&gt; aa = 3.141592653589793\n\n\n\n显示少量的小数点后几位：format short\n&gt;&gt; format short&gt;&gt; aa = 3.1416\n\n\n\n建立一个矩阵：\n\n\n&gt;&gt; A = [1 2;3 4;5 6]A =   1   2   3   4   5   6&gt;&gt; A = [1 2;&gt; 3 4;&gt; 5 6]A =   1   2   3   4   5   6\n\n\n\n\n建立向量：\n\n&gt;&gt; v = [1 2 3] %行向量v =   1   2   3&gt;&gt; v = [1; 2; 3] %列向量v =   1   2   3&gt;&gt; v = 1:0.1:2 %从1开始每次增加0.1到2的行向量v =    1.0000    1.1000    1.2000    1.3000    1.4000    1.5000    1.6000    1.7000    1.8000    1.9000    2.0000&gt;&gt; V = 1:6 %从1到6的整数V =   1   2   3   4   5   6\n\n\n生成单位矩阵\n\n&gt;&gt; ones(2,3) %2×3的ans =   1   1   1   1   1   1\n\n\n生成零矩阵\n\n&lt;&lt; zeros(2,3)ans =   0   0   0   0   0   0\n\n\n随机生成0到1的值\n\n&lt;&lt; rand(3,3)ans =   0.914686   0.131127   0.563647   0.296402   0.590713   0.134373   0.243013   0.477658   0.071331\n\n\n生成服从高斯分布的随机数：均值为0，标准差或者方差为1\n\n&lt;&lt;  w = randn(1,3)w =  -0.1177   2.0111   0.7261\n\n\n绘制直方图：hist( ):均值为-6，方差为10，标准差为根号10\n\n\n\n生成单位矩阵：eye( )\n\n&lt;&lt; eye(4)ans =Diagonal Matrix   1   0   0   0   0   1   0   0   0   0   1   0   0   0   0   1\n\n\n显示帮助：help eye;help help;按q退出\n\n显示矩阵大小:size( )\n\n\n&lt;&lt; A = [1 2; 3 4; 5 6]A =   1   2   3   4   5   6&lt;&lt; size(A)ans =   3   2&lt;&lt; size(A,1) %显示行数ans = 3&lt;&lt; size(A,2) %显示列数ans = 2\n\n\n返回最大维度大小：length( )|一般对向量使\n\n&lt;&lt; length(A)ans = 3 %3×2，最大维度为3&lt;&lt; length([1;2;3;4;5])ans = 5\n\n02 移动数据\n显示当前在内存中存储的所有变量：who\nwhos显示更加完善的信息\n\n&lt;&lt; whoVariables visible from the current scope:A    ans&lt;&lt; whosVariables visible from the current scope:variables in scope: top scope   Attr Name        Size                     Bytes  Class   ==== ====        ====                     =====  =====        A           3x2                         48  double        ans         1x10                        10  charTotal is 16 elements using 58 bytes\n\n\n载入文件格式：load+文件；load(‘文件’)\n删除某个变量：clear+变量\n存储数据到硬盘中：save+存储文件名+数据\n在找矩阵某一个元素时，：表示这一行或者这一列的元素\n\n&lt;&lt; A(2,1)ans = 3&lt;&lt; A(2,:)ans =   3   4&lt;&lt; A(:,2)ans =   2   4   6\n\n\n索引操作：同时取得1、3行所有元素\n\n&lt;&lt; A([1 3],:)ans =   1   2   5   6\n\n\n将第二列用其他元素代替\n\n&lt;&lt; A(:,2) = [10; 11; 12]A =    1   10    3   11    5   12    \n\n\n在A的右侧附加一列\n\n&lt;&lt; A = [A,[100; 200; 300]]A =     1    10   100     3    11   200     5    12   300\n\n\n把A所有元素放在单独的一列\n\n&lt;&lt; A(:)ans =     1     3     5    10    11    12   100   200   300\n\n\n将两个矩阵结合在一起\n\n&lt;&lt; A = [1 2; 3 4; 5 6]A =   1   2   3   4   5   6&lt;&lt;  B = [11 12; 13 14; 15 16]B =   11   12   13   14   15   16&lt;&lt; C = [A B] %左右结合C =    1    2   11   12    3    4   13   14    5    6   15   16&lt;&lt; C = [A;B] %上下结合C =    1    2    3    4    5    6   11   12   13   14   15   16\n\n03 计算数据\n两个矩阵相乘\n\n&lt;&lt; A = [1 2; 3 4; 5 6]A =   1   2   3   4   5   6&lt;&lt;  B = [11 12; 13 14; 15 16]B =   11   12   13   14   15   16&lt;&lt; C = [1 1;2 2]C =   1   1   2   2&lt;&lt; A*Cans =    5    5   11   11   17   17\n\n\n两个矩阵对应数相乘\n\n&lt;&lt; A.*Bans =   11   24   39   56   75   96\n\n\nA的每个元素进行乘方\n\n&lt;&lt; A.^2ans =    1    4    9   16   25   36\n\n\n求V对应元素的倒数\n\n&lt;&lt; V = [1; 2; 3]V =   1   2   3&lt;&lt; 1 ./Vans =   1.0000   0.5000   0.3333\n\n\n以e为底，v中元素为指数的幂运算\n\n&lt;&lt; exp(V)ans =    2.7183    7.3891   20.0855\n\n\n求绝对值：abs( )\n求相反数直接加-；例如-V\n将V中每个元素+1\n\n&lt;&lt; V + ones(length(V),1) %与V +1等价ans =   2   3   4\n\n\n求A的转置\n\n&lt;&lt; A&#x27;ans =   1   3   5   2   4   6\n\n\n求X最大的数及其索引\n\n&lt;&lt; X = [1 15 2 0.5]X =    1.0000   15.0000    2.0000    0.5000&lt;&lt; val = max(X)val = 15&lt;&lt; [val,ind] = max(X)val = 15ind = 2%如果A是矩阵，那么将求出每一列最大值&lt;&lt; max(A)ans =   5   6\n\n\nX中每个元素与3比较，根据结果返回真和假\n\n&lt;&lt; X&lt;3ans =  1  0  1  1\n\n\n找到比3小的数并返回其索引\n\n&lt;&lt; find(X&lt;3)ans =   1   3   4\n\n\n生成一个幻方矩阵，每行、每列、每个对角线加起来都等于一个数\n\n&lt;&lt; B = magic(3)B =   8   1   6   3   5   7   4   9   2\n\n\n找出B中&gt;&#x3D;7的元素，并返回下标\n\n&lt;&lt; [r,c] = find(B &gt;=7)r =   1   3   2c =   1   2   3\n\n\nX中所有元素相加\n\n&lt;&lt; sum(X)ans = 18.500\n\n\nX中所有元素相乘\n\n&lt;&lt; prod(X)ans = 15\n\n\n对X中元素向下取整\n\n&lt;&lt; floor(X)ans =    1   15    2    0\n\n\n对X中元素向上取整\n\n&lt;&lt; ceil(X)ans =    1   15    2    1\n\n\n取两个随机矩阵中较大的数组合成一个较大值的矩阵\n\n&lt;&lt;  max(rand(3),rand(3))ans =   0.6957   0.9634   0.7179   0.8404   0.9784   0.8319   0.5236   0.8063   0.6697\n\n\n取每一列&#x2F;行最大值\n\n&lt;&lt; max(B,[],1)ans =   8   9   7&lt;&lt; max(B,[],2)ans =   8   7   9\n\n\n求每一行、每一列、对角线相加\n\n&lt;&lt; C = magic(9)C =   47   58   69   80    1   12   23   34   45   57   68   79    9   11   22   33   44   46   67   78    8   10   21   32   43   54   56   77    7   18   20   31   42   53   55   66    6   17   19   30   41   52   63   65   76   16   27   29   40   51   62   64   75    5   26   28   39   50   61   72   74    4   15   36   38   49   60   71   73    3   14   25   37   48   59   70   81    2   13   24   35&lt;&lt; sum(C,2)ans =   369   369   369   369   369   369   369   369   369&lt;&lt; sum(C,1)ans =   369   369   369   369   369   369   369   369   369&lt;&lt; sum(sum(C.*eye(9))) %正对角线相加ans = 369&lt;&lt; sum(sum(C.*flipud(eye(9)))) %副对角线相加，flipud表示使矩阵垂直翻转ans = 369\n\n04 数据绘制\n绘制一个正弦函数图像：plot( );\n\n&lt;&lt; t = [0:0.01:0.98];&lt;&lt; y1 = sin(2*pi*4*t);&lt;&lt; plot(t,y1);\n\n\n\n绘制一个余弦函数图像：plot( );\n\n&lt;&lt; y2 = cos(2*pi*4*t);&lt;&lt; plot(t,y2);\n\n\n\n在旧的图像上面绘制新的图像：hold on;\n\n&lt;&lt; t = [0:0.01:0.98];&lt;&lt; y1 = sin(2*pi*4*t);&lt;&lt; y2 = cos(2*pi*4*t);&lt;&lt; plot(t,y1);&lt;&lt; hold on;&lt;&lt; plot(t,y2,&#x27;r&#x27;);\n\n\n\n加上横与纵轴的标签，标记两条函数，输入标题，并保存到桌面\n\n&lt;&lt; xlabel(&#x27;time&#x27;)&lt;&lt; ylabel(&#x27;value&#x27;)&lt;&lt; legend(&#x27;sin&#x27;, &#x27;cos&#x27;)&lt;&lt; title(&#x27;my plot&#x27;)&lt;&lt; cd &#x27;C:\\Users\\1\\Desktop&#x27;; print -dpng &#x27;plot.png&#x27;\n\n\n\n\n为不同图像标号：就可以同时有两个图像\n\n&lt;&lt; figure(1); plot(t,y1);&lt;&lt; figure(2); plot(t,y2);\n\n\n\n将一个界面分为两个格子，其中正弦占第一个，余弦占第二个\n\nsubplot(1,2,1);&lt;&lt; plot(t,y1);&lt;&lt; subplot(1,2,2);&lt;&lt; plot(t,y2);\n\n\n\n设置横竖轴的范围\n\n&lt;&lt; plot(t,y1);&lt;&lt; axis([0.5 1 -1 1])\n\n\n\n可视化矩阵\n\n&lt;&lt; A = magic(5)A =   17   24    1    8   15   23    5    7   14   16    4    6   13   20   22   10   12   19   21    3   11   18   25    2    9&lt;&lt; imagesc(A)\n\n\n\n生成颜色图像、灰度分布图并在右边加入一个颜色分布\n\n&lt;&lt; imagesc(A), colorbar, colormap gray;\n\n\n\n添加环境路径，找文件时，即使不在文件环境，也可以使用其中的函数\n\naddpath(&#x27;C:\\Users\\1\\Desktop&#x27;)\n\n05 控制语句\noctave可以返回多个返回值\n\n函数定义\n\n\nfunction J = costFunctionJ(X,y, theta)  m = size(X,1);  predictions = X*theta;  sqrError = (predictions-y).^2;  J = 1/(2*m) * sum(sqrError);\n\n\n函数使用\n\n&lt;&lt; addpath(&#x27;C:\\Users\\1\\Desktop&#x27;)&lt;&lt; X = [1 1; 1 2; 1 3]X =   1   1   1   2   1   3&lt;&lt; y = [1; 2; 3]y =   1   2   3&lt;&lt; theta = [0;1];&lt;&lt; J = costFunctionJ(X,y, theta)J = 0&lt;&lt; theta = [0;0];&lt;&lt; J = costFunctionJ(X,y, theta)J = 2.3333&lt;&lt; (1^2+2^2+3^2)/(2*3)ans = 2.3333\n\n06 矢量\n非向量化与向量化的代码对比\n\n\n\n用C++语言及C++线性库所写代码\n\n\n\n向量化\n\n\n","tags":["机器学习"]},{"title":"机器学习 day06Logistic回归","url":"/2021/07/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day06Logistic%E5%9B%9E%E5%BD%92/","content":"01 分类\n针对于离散值来进行分类：y &#x3D; {0，1}\n0表示负类，没有什么东西\n1表示正类，有什么东西\n不建议将线性回归函数应用于分类情况中\n使用线性回归在分类问题，如果一个值远离其他值，将会使线性回归算法不够准确。\n\n\n\nLogistic回归算法的预测值一直介于0和1之间，并不会像线性回归算法大于1或者小于0\n\n02 假设陈述\n假设陈述：当有一个分类问题的时候，我们要使用哪个方程来表示我们的假设。\nLogistic函数的形式如下：对线性回归方程稍作修改。\n\n\n\n输出某个数字，我们会把这个数字当作对一个输入x，y&#x3D;1的概率估计\n\n\n03 决策界限\n决策界限可以帮助我们理解Logistic回归的假设函数在计算什么。\n可以从图看出什么时候预测y &#x3D; 1;什么时候预测y &#x3D; 0;\n\n\n\n决策边界将一个平面划分为两个区域，其中一片区域假设函数预测y &#x3D; 1；另一片区域假设函数预测y &#x3D; 0。只要我们确定好了参数，我们就将完全确定决策边界。例如下图所示：可以得出直线 X1 + X2 &#x3D; 3就是决策边界。\n\n\n\n例题：我们怎么才能使用Logistic回归来拟合这些数据呢？多项式回归及线性回归可以在特征中添加额外的高阶多项式，Logistic回归也可以使用。\n\n\n\n决策边界不是训练集的属性，而是假设本身及其参数的属性，只要给定了参数向量就可以确定决策边界\n\n04 代价函数如何拟合Logistic回归模型的参数。当代价函数为0时，可以得出与预测值想拟合。\n\n\n如果将代价函数带入到Logistic回归中可以得到左侧图像非凸函数，可是我们想要得到右侧这样得凸函数。\n\n\n\n因此我们需要重新找到个代价函数可以用在Logistic回归中，保证找到全局最小值。下面使y &#x3D; 1情况下。\n\n\n\n下面使y &#x3D; 0情况下\n\n\n05 简化代价函数与梯度下降\n简化后得代价函数\n\n\n\n式子是在统计学中得极大似然法得来得，他是统计学中为不同模型快速寻找参数得方法。同时他是凸的。\n\n\n\n如何最小化代价函数：使用梯度下降算法。虽然Logistic回归中梯度下降算法与线性回归中的梯度下降算法长的一样，但是由于假设的定义发生了变化，所以实际上是两种截然不同的。\n\n\n06 高级优化\n一些高级算法的优缺点\n\n\n\n自动求使代价函数最小的参数，使用代码将其实现\n\n\n\n写一个函数，他能返回代价函数值以及梯度值\n\n\n07 多元分类：一对多使用逻辑回归来解决多类别分类问题\n\n\n训练一个逻辑回归分类器，预测i类别y &#x3D; i的概率。在三个分类器中输入x，在其中选择h(x)最大的那个类别。也就是选择出三个里面可信度最高，效果最好的的哪个分类器。\n\n\n\n无论i是多少，我们都能得到一个最高的概率值，我们预测y就是那个值。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day07正则化","url":"/2021/07/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day07%E6%AD%A3%E5%88%99%E5%8C%96/","content":"01 过拟合问题正则化可以减少过度拟合问题\n\n1.1  线性回归过拟合问题\n欠拟合 | 刚好合适 | 过拟合\n\n\n\n过度拟合问题将会在变量过多的时候出现，这时训练出的假设能够很好的拟合训练集（所以代价函数实际上可能非常接近于0。或者恰好等于0），但是可能会得到图三这样的曲线，去拟合训练集，以至于它无法泛化到新的样本中。\n泛化是指一个假设模型应用到新样本的能力\n\n1.2  逻辑回归过拟合问题\n欠拟合 | 刚好合适 | 过拟合\n\n\n\n如果我们有过多的特征变量而只有少量的训练集就会出现过拟合问题。\n有两种方法解决过拟合问题：\n尽量减少特征变量的数量（模型选择算法会自动选择哪些变量保留，哪些舍弃）\n正则化：减少量级或者参数的大小\n\n\n\n02 代价函数\n正则化将多阶函数变成二阶函数（将参数尽可能减小），这些参数越小，我们得到的图像也就越圆滑越简单。\n\n\n\n一般来说我们只对参数1以及1之后的进行正则化\n在对代价函数进行修改，添加正则化项的目的是为了缩小参数的值。\n正则化参数是为了控制两个不同目标之间的取舍\n正则化参数如果过大，那么参数都会接近于0，这样就相当于把假设函数的全部项都忽略了，最终变成了欠拟合。\n\n\n03 线性回归的正则化\n线性回归正则化的梯度下降法\n\n\n\n线性回归正则化的正规方程法\n\n\n\nm&lt;&#x3D;n，说明矩阵是不可逆的，但是当正则参数&gt;0，算出来的矩阵一定是可逆的。\n\n\n04 Logistic 回归的正则化\nLogistic 回归添加正则化项\n\n\n\nLogistic 回归的正则化的梯度下降法\n\n\n\n如何在更高级的算法中使用正则化：定义一个costFunction函数，以theta作为输入。在fminunc函数中括号里写上@cosFunction。\nfminunc的意思是函数在无约束条件下的最小值，fminunc函数会将costFunction函数最小化，\n\n\n","tags":["机器学习"]},{"title":"机器学习 day08神经网络学习","url":"/2021/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day08%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/","content":"01 非线性假设为什么已经有线性回归和逻辑回归算法了，还要学习神经网络？\n\n\n因为有特别多的特征，许多机器学习都需要学习复杂的非线性假设。如果使用逻辑回归算法，由于项数过多，可以能会导致过拟合问题，此外也存在运算量过大的问题。如果项数只包括二次项的的子集，这样将二次项的数量减少到100个，但是最有可能拟合出右下角椭圆而拟合不出左上角复杂的分界线。\n\n\n\n下图车子例子所示：如果是一张50 * 50 像素的图像， 则会有 50 * 50 &#x3D; 2500个像素单位（如果是彩色，每个像素又有0-255的RGB取值。即有 2500 * 3 &#x3D; 7500），特征数量则有约 n^2 &#x2F; 2 约 3000000 个特征数量。\n\n\n02 神经元与大脑神经网络能够很好的解决不同的机器学习问题\n\n\n神经网络的起源及发展\n\n\n\n神经元是一个计算单元，它从输入通道接受一定数量的信息，并做一些计算，然后将结果通过它的轴突传送到其他节点，或者大脑中其他神经元。\n\n\n03 模型展示\n神经网络模拟了大脑中的神经元或者神经网络。\n在神经网络里我们将使用一个很简单的模型来模拟神经元工作，我们将神经元模拟成一个逻辑单元。黄色代表类似于神经元细胞体的东西，经过“输入”-&gt;“计算”-&gt;“输出”三个步骤，因为X0（偏置单元或偏置神经元）总是1，会根据实际情况判断时候加上X0。\n在神经网络中激活函数是指非线性函数g(z)。单个神经元图如下：\n\n\n\n在神经网络中第一层叫做输入层，因为我们在这一层输入特征；第二层叫做隐藏层（任何一个非输入层和非输出层），隐藏层的值在训练中是看不到的；最后一层叫输出层，因为在这一层输出假设的最终计算结果；\n\n\n\nai(j)代表第j层第i个神经元或者单元的激活项，激活项是由一个具体神经元计算并输出的值。参数(j)就是权重矩阵，它控制从某一层到另外一层的映射。计算三个隐藏单位的值及输出如下：\n\n\n\n如何高效进行计算，并展示一个向量化的实现方法。\n\n前向传播方法\n\n\n\n下面这个神经网络所作的事情就像是逻辑回归，它不是以原本的X1、X2、X3作为特征，而是用a1、a2、a3作为新的特征\n\n\n04 例子与直觉理解神经网络计算复杂非线性函数的输入\n\n\nX1 AND X2运算\n\n\n\nX1 OR X2运算\n\n\n\nNOT X1\n\n\n\nX1 XNOR X2\n\n\n05 多元分类\n要是在神经网络中实现多类别分类，采用的方法本质是一对多法的拓展（其中Xi代表图像，Yi代表那些向量）\n\n\n","tags":["机器学习"]},{"title":"机器学习 day09神经网络参数的反向传播算法","url":"/2021/07/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day09%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/","content":"01 代价函数\n有m组训练样本，L代表神经网络结构的总层数，S_l代表第L层的单元数也就是神经元的数量（不包括第L层的偏差单元）。其中二元分类与多类别分类问题如下：\n\n\n\n应用于神经网络的代价函数：h(x)是一个k维向量，h(x)_i代表第i个输出；k的求和符号应用于y_k和h_K,是因为我们主要是将第k个输出单元的值和y_k的值的大小作比较；y_k的值就是这些向量中其应属于哪个类的量。\n\n\n02 反向传播算法反向传播算法是计算代价函数关于所有参数的导数或者偏导数的一种有效方法。\n\n\n使用前向传播方法来计算的顺序，计算一下在给定输入的时候，假设函数是否会真的输出结果。\n\n\n\n反向传播算法中，下图上方下标j上标（l)代表了第l层的第j个结点的误差，下图上方下标j上标（l)实际上就是假设的输出值和训练集y值之间的差。反向传播算法类似于把输出层的误差反向传播给了第三层，然后再传播给第二层，注意没有第一层（第一层可以直观的观察到，没有误差）。\n\n\n\n如何实现反向传播算法来计算这些参数的偏导数：\n\n首先将每一个i和j对应的三角形（三角形是上图上方下标j上标（l)的大写）置0\n接下来遍历整个训练集，将输入层的激活函数设定他为第i个训练样本的输入值\n接下来用正向传播来计算第二层的激活值，然后第三层，最后到最后一层\n使用输出值来计算这个输出值对应的误差项（假设输出-目标输出）\n再通过反向传播算法计算前几层的误差项，一直到第二层\n最后通过三角形来累计我们再前面写好的偏导数项\n\n\n跳出循环后，通过下面的式子计算D(j等于0和j不等于0的情况)，计算出来的D正好就是关于每个参数的偏导数，然后可以用梯度下降法或者一些其他的高级优化算法。\n\n\n\n03 理解反向传播\n理解前向传播\n\n\n\n代价函数应用在只有一个输出单元的情况\n\n\n\n理解反向传播：代价函数是一个关于标签y和神经网络中h(x)的输出值的函数，只要稍微将z(l)j改一下，就会影响神经网络的h(x)，最终改变代价函数的值。\n\n\n04 使用注意：展开参数把参数从矩阵展开向量，以便在高级最优化步骤中的使用需要\n\n\n高级最优化算法都假定theta和initialTheta初始值都是参数向量，也许是n或者n+1维，同时假定这个代价函数的第二个返回值(梯度值)也是n维或者n+1维向量。但是现在在神经网络，参数不再是向量而是矩阵，三个参数在Octave表达如下；梯度矩阵在Octave表达也如下：\n\n\n\n取出矩阵，并将其展开成向量传入theta中，并得到梯度返回值。\nthetaVec就是将这些矩阵全部展开成为一个很长的向量；DVec同理。reshape将相应元素组合起来成相应矩阵。\n\n\n\n上面步骤通过Octave实现如下：\n\n&lt;&lt;Theta1 = ones(10,11)Theta1 =   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1&lt;&lt;Theta2 = 2*ones(10,11)Theta2 =   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2&lt;&lt;Theta3 = 3*ones(1,11)Theta3 =   3   3   3   3   3   3   3   3   3   3   3&lt;&lt;thetaVec = [ Theta1(:);Theta2(:);Theta3(:)];&lt;&lt;size(thetaVec)ans =   231     1&lt;&lt;reshape(thetaVec(1:110),10,11)ans =   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1&lt;&lt;reshape(thetaVec(111:220),10,11)ans =   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2&lt;&lt;reshape(thetaVec(221:231),1,11)ans =   3   3   3   3   3   3   3   3   3   3   3\n\n\n将这一方法应用于我们的学习算法\n\n\n05 梯度检测因为反向传播使用时会出现一些bug，而梯度检测可以很好的解决这些问题，确保前向传播及反向传播都百分百正确。\n\n\n求出该点导数的近似值（参数是实数的情况）\n\n\n\n当参数维向量参数的时候\n\n\n\n在Octave中为了估算导数所要实现的\n\n\n\n总结下如何实现数值上的梯度检验：（注意反向传播算法比梯度检测效率高，检测完一定要关闭梯度检测）\n\n\n06 随机初始化\n在神经网络中将所有参数初始为0，没有任何意义，所有输入都是一样，也就意味这最后输出就输出一个特征，阻挡了神经网络学习任何有趣的东西，我们称之为高度冗余。\n\n\n\n因此就应该使用随机初始化方法。值得注意的是这里的EPSILON与梯度检测中的完全没有关系。\n\n\n\n为了训练神经网络首先将权重随机初始化为一个接近0范围在-EPSILON到EPSILON之间，然后进行反向传播，在进行梯度检测，最后梯度下降算法或其他高级优化算法来最小化代价函数（关于参数sita的函数）。\n\n07 组合到一起\n训练神经网络做的第一件事就是选择一种合适的网络架构（神经元之间的连接模式），注意输出时是输出一个向量y。\n\n\n\n训练神经网络所需要的步骤\n\n\n\n\n反向传播算法是为了算出梯度下降算法的下降方向\n\n","tags":["机器学习"]},{"title":"机器学习 day10应用机器学习的建议","url":"/2021/07/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day10%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/","content":"01 决定下一步做什么\n开发一个机器学习系统，或者想试着改进一个机器学习系统的性能，应如何决定选择哪条路。不要随意选择。\n\n\n\n机器学习诊断法能够提前发现某些方法是无效的。\n\n\n02 评估假设\n将所有数据分为训练集和测试集，最经典的分割方法就是按照7:3的比例。\n\n\n\n线性回归算法和平方误差标准学习和测试学习算法，从训练集学习获得参数，在将参数带入测试集得到测试误差。\n\n\n\n训练和测试逻辑回归的步骤及用错误分类（0&#x2F;1分类错误）来定义测试误差。0&#x2F;1表示了你预测的分类是正确或错误的情况。\n\n\n03 模型选择和训练、验证、测试集\n模型选择问题（想要确定对于一个数据集最合适的多项式次数，怎样选用正确的特征来构造学习算法或者假如你需要选择学习算法中的正则化参数）\n\n模型选择问题：用不同的模型拟合数据集得到参数，接着对所有这些模型求出测试集误差，然后根据哪个模型有最小的测试误差来选择使用哪个模型。\n\n\n\n\n为了解决模型选择出现的问题，我们通常会采用如下的方法来评估一个假设。我们把数据分为三个部分，分别是训练集、验证集、测试集。分配比例分别是6:2:2。\n\n\n\n定义训练误差、交叉验证误差和测试误差\n\n\n\n用验证集选择模型而不是原来的测试集。省下来的测试集可以用它来衡量或者估算算法选择出的模型的泛化误差了。\n\n\n04 诊断偏差与方差如果一个算法表现得不理想，要么是偏差比较大，要么是方差比较大。换句话说要么欠拟合要么过拟合。\n\n\n训练误差随着我们增大多项式的次数而减小；随着我们增大多项式的次数，我们对训练集拟合的也就越好。对于验证误差来说，如果d为1，会有较大误差；如果d为中等次数大小，能够更好的拟合；当d为4时，也就可能过拟合。\n\n\n\n对于验证误差来说，左边这一端对应的就是高偏差问题；右边这一端对应的就是高方差问题。如果训练误差很小，并且验证误差远大于训练误差说明出现过拟合问题（高方差）。如果是高偏差，则训练误差和验证误差都很大。\n\n\n05  正则化和偏差、方差\n第一个图是高偏差，欠拟合；中间正合适；最后一个图是高方差，过拟合。\n\n\n\n我们对训练、验证、测试误差的定义都是平均的误差平方和，或者是不使用正则化项时，训练集、验证集和测试集的平均的误差平方和的一半。\n\n\n\n自动选择正则化参数的方法：首先选取一系列想要试用的步长，通常来说步长设为2倍速增长，直到一个比较大的值。这样就选取了12个对应的正则化参数。然后对这12个模型分别最小化代价函数，得到完全不同的参数向量。可以把这些模型用不同的正则化参数来进行拟合，然后我们可以用验证集来评价这些参数sita在验证集上的平均的误差平方和，最终选择误差最小的模型。\n\n\n\n当我们改变正则化参数时，我们的假设在训练集和验证集上的表现（对应本节第一个图）\n\n\n06 学习曲线学习曲线可以判断某一学习算法是否处于偏差或者方差问题，还是二者都有。\n\n\n当训练集个数很少的时候，能够十分完美的拟合数据，训练集误差基本为0，但是随着训练集越来越多，训练集误差也就会越来越大，逐渐趋于水平。而验证集误差，随着训练集的个数增加而减小，最终趋于水平。\n\n\n\n在高偏差的情况下，训练集误差和验证集误差最终将十分接近，再增加训练集数量将毫无意义。\n\n\n\n在高方差的情况下，总体来说随着训练集数量的增多，训练集误差将会增加，但是增加的很小。而验证集误差一直都比较高，虽然会有所下降，但是不多。所以增加训练集数量还是很有用的。\n\n\n07 决定接下来做什么\n接下来回到第一节的第一个图，1和2和6对应着高方差的情况，3和4和5对应高偏差的情况（个人理解：高方差就是在多项式的形式下出现的，高偏差就是在项数少的情况下出现的）。\n\n\n\n小型神经网络计算量少，大型神经网络比较容易出现过拟合问题（但是可以用正则化来进行解决），相对来说大型神经网络性能更好。\n还有就是选择隐含层层数的问题，可以将数据分为训练集、验证集还有测试集。用训练集分别训练一层、两层、三层的隐含层，最终用验证集来测试，选出合适的层数。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day11机器学习系统设计","url":"/2021/07/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day11%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","content":"01 确定执行的优先级在实际工作过程中，我们应该优先处理哪些事情\n\n\n以邮件筛选为例，选择邮件的特征向量的方法。通常我们会挑选出在训练集中出现频率最多的n个单词，将其作为特征向量。\n\n\n\n如何在有限时间里让垃圾邮件分类器具有高精准度和低错误率。\n用更复杂的特征变量来描述邮件（可以在邮件标题中获取复杂的特征，来捕捉这封邮件的来源，以此判断是否为垃圾邮件）。\n关注邮件的正文，并构建更复杂的特征。\n来检测单词是否故意出现拼写的错误\n\n\n\n\n02 误差分析误差分析就是一种手动地去检查算法所出现的失误的过程，走向最有成效的道路。\n\n\n通过手动检查分类错误的邮件，来看哪一类分类错误的多，哪一个出现错的情况最多，就着重去构造这类特征，加以训练。\n\n\n\n交叉验证错误率：单一规则的数值评价指标。\n如果只是手动地去检查看看这些例子表现得好不好，会让你很难去决定到底应不应该做出某种决定；但是通过交叉验证错误率就可以直观的看误差率是变大还是变小了，他能告诉你你的想法是提高了还是降低。\n\n\n\n一旦有了一个初始的算法实现，我们就能使用一个强有力的工具，来帮助决定下一步应该做什么：\n看看他所造成的错误：通过误差分析来看看它出现了什么失误，然后以此决定之后的优化方法。\n如果已经有了一个简单粗暴算法实现，又有一个数值评价指标，这些能帮助来试验新的想法，能够快速观察是否能够提高算法的表现，决定应该包含什么，应该舍弃什么。\n\n\n\n03 不对称性分类的误差评估当有倾斜类问题时，使用准确率与召回率来评价学习算法要比用分类误差或者分类准确率好得多。\n\n\n偏斜类：一个类中的样本数与另一个类中的数据相比多很多（比如，没有肿瘤的比有肿瘤的要多得多）。所以说恒把y&#x3D;0算出来的误差将会很小，因为有肿瘤的人很少。\n\n\n\n所以我们想要一个不同的评估度量值：查准率和召回率。其中查准率是指对于所有我们的预测，患有癌症的病人，有多大比率的病人是真正患有癌症的。召回率是指假设如果测试集或者验证集中的病人确实得了癌症，有多大比率正确预测他们得了癌症。也就是如果所有病人都得了癌症，有多少人我们能够正确告诉他们你需要治疗。查准率和召回率越高越好。算法预测值与实际值分别是：1&#x2F;1（真阳性）、0&#x2F;0（真阴性）、1&#x2F;0（假阳性）、0&#x2F;1（假阴性）。\n\n\n04 精确度和召回率的权衡\n在逻辑回归中逻辑输出在0到1之间，其中0.5是个分界值，但是我们想在十分确定得情况下告诉病人真实信息，因此分界值为0.7，甚至0.9（是一个高查准率的模型，但是召回率会变低）。现在我们将分界值设置到较低（有30%几率得病），会得到高召回率，较低得查准率。\n\n\n\n有没有办法自动选取临界值？或者说有不同的算法，我们如何比较不同的查准率和召回率？或者临界值不同，我们怎样决定哪个更好？–如果使用平均值来计算是不可行的，因为如果假设y &#x3D; 1和y &#x3D; 0这两种极端的情况（要么很高召回率、很低查准率，要么很低召回率、很高查准率），他们俩不是好的模型。再此我们使用F值的公式，因为它同时结合召回率及查准率。\n\n\n\n自动选择临界值来决定你希望预测y&#x3D;1还是y&#x3D;0合理的方法：试一试不同的临界值，在检验集进行测试，看哪个临界值可以在检验集得到最高的F。这就是为分类器自动选择临界值的合理方法。\n\n05 机器学习数据在一定条件下，得到大量的数据并在某种类型的学习算法中进行训练，可以是一种有效的方法来获取具有良好性能的学习算法。这种情况一般出现在这些条件对于你的问题都成立，并且可以得到大量数据。\n\n\n并不是拥有最好算法的人能成功，而是拥有最多数据的人能成功。\n\n\n\n如果让一个英语好的选词填空，它可以通过特征x让我们能够准确的预测y，相反的，我们让一个房地产专家预测一个房价，而只告诉它房子的面积，其他特征不告诉，他会很难预测。因此如果这个假设正确可以看出大量数据是很有意义的。\n\n\n\n得到一个低偏差（一个强大的具有很多参数的学习算法，可以很好的拟合复杂的函数）和低方差（如果训练集远大于参数的数量，就不大可能会过拟合）的学习算法（特征值足够并且训练集很庞大）\n\n\n","tags":["机器学习"]},{"title":"机器学习 day12支持向量机","url":"/2021/07/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day12%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/","content":"01 优化目标支持向量机（SVM）在学习复杂的非线性方程时，能够提供一种更为清晰和更加强大的方式。\n\n\n从逻辑回归开始，稍作改动成为支持向量机\n观察下逻辑回归的假设函数和sigmoid激活函数\n\n\n\n\n\n观察逻辑回归的代价函数，当把整个假设函数的定义代入其中，得到的就是每个样本对总体函数的具体贡献。\n\n\n\n为了构建支持向量机，我们从这个代价函数开始进行少量修改，我们取z&#x3D;1，画出要使用的代价函数，右边都是平的，左边画出一条和最开始的幅度相似的直线，这就是y&#x3D;1时使用的代价函数。同样的做出y&#x3D;0时使用的代价函数。\n\n\n\n有了这些定义后，就可以开始构造支持向量机了，将修改后的代价函数定义带入到原始的逻辑回归代价函数中。支持向量机的代价函数将1&#x2F;m去掉，因为1&#x2F;m是一个常数，不影响得到参数的最优值。对于SVM来说我们将用一个不同的参数来控制第一项A与第二项B的相对权重，如果把C设置的很小，那么B就比A占有更大的权重。于是就得到了支持向量机的总体优化目标\n\n\n\n最后和逻辑回归不同的是，支持向量机并不会输出概率，相对的我们得到的是通过优化这个代价函数得到参数sita，支持向量机它是进行了一个直接的预测y&#x3D;0&#x2F;y&#x3D;1,学习得到参数sita后，这就是支持向量机的假设函数的形式。\n\n\n02 直观上对大间隔的理解\n下面是SVM代价函数，支持向量机不是恰好能正确分类就行，因此需要比0大或者小很多（也就是1或者-1）。\n\n\n\n如果C非常的大，那么当最小化最优目标的时候，将迫切的希望找到一个值使得第一项等于0。在两种情况下，通过选择参数sita使得第一项为0。\n\n\n\n支持向量机会选择尽量把正样本和负样本以最大的间距分开的假设模型。可以看出黑色的决策边界和训练样本的最小距离要更大一些。\n\n\n\n下面的大间距分类器是在常数C被设的非常大情况下得出的，平常情况下会得到黑色线，但是如果在一侧加入异常样本，那么就可能会是粉色的线。如果C不是很大，那么就算是加入异常点也会是黑色线。\n\n\n03 大间隔分类器的数学原理\n向量内积\n\n\n\n支持向量机的优化目标函数，当n&#x3D;2时我们只有两个特征量（也就是只有两个参数sita）。因此对于优化目标函数来说支持向量机做的是最小化参数向量sita的范数的平方。（为了简便都令sita0&#x3D;0）\n\n\n\n将sita转置x(i)替换后的结果写入我们的优化目标函数。令sita0&#x3D;0意味着决策边界必须通过原点(0,0)。下图是支持向量机选择不同的决策边界的情况。（向量sita一定是垂直于决策边界的），支持向量机通过让间距变大，使得p(i)变大，以至于输出一个较小的sita的范数。（为了简便都令sita0&#x3D;0，即使不为0，效果也不变。支持向量机仍然会找出正样本和负样本之间大间距分隔）\n\n\n04 核函数1改造支持向量机算法来构造复杂的非线性分类器。\n\n\n希望拟合一个非线性的判别边界来区分正负实例。一种方法是构造一个复杂多项式特征的集合，在这里我们用f1、f2、f3来表示这些我们将要计算的新的特征变量。\n\n\n\n构造新特征f1、f2、f3的方法：首先手动选取三个点（标记），接着将新特征定义为一种相似度的度量即度量训练样本x与标记的相似度（用下面公式表达）。相似度函数就是一个核函数（这里是高斯核函数）。\n\n\n\n对于这个核函数取两种情况：一种是x与标记点很近，一种是x与标记点很远。\n\n\n\n下面是核函数参数大小不同时的表现：\n\n\n\n选择不同的点，来预测y值是1还是0。可以看出离l_1和l_2近的点预测y值为1（带入下面的预测函数中如果&gt;&#x3D;0说明y&#x3D;1;&lt;0说明y&#x3D;0)。\n\n\n05 核函数2\n特征函数基本上是在描述每一个样本距离样本集中其他样本的距离，下面是这个过程的大纲。\n\n\n\n当已知参数sita时，怎样做出预测的过程。因为标记点的个数等于训练点的个数（m），所以参数向量sita为m+1维\n\n\n\n但是怎样得到参数sita？通过解决最小化的问题，你就得到了支持向量机的参数sita。\n\n\n\n在使用支持向量机时，怎么选择支持向量机中的参数C？–C相当于正则化参数的倒数，根据需求选择C。高斯核函数中的参数？–当高斯核函数中的参数相对较大时，图像将会倾向于变得相对平滑，可能会带来较高的偏差和较低的方差；当高斯核函数中的参数相对较小时，图像弧度将会相对大，可能会带来低偏差和较高的方差。（图像跟第四节倒数第二个相配套）\n\n\n06 使用SVM高度优化好的软件库：liblinear、libsvm\n\n\n我们虽然不用自己写SVM优化库，但是还是有几件事需要我们做：\n参数C的选择\n选择内核参数或者想要使用的相似函数\n\n\n对于内核函数其中第一个选择是不需要任何内核参数，没有内核参数的理念又叫线性核函数。为什么想要做这件事呢？如果有大量的特征n，而训练集m很小，也许就想拟合一条线性的判定边界，而不去拟合一条复杂的非线性函数。因此选择线性核函数可能很合适。\n对于内核函数其中第二个选择是可以构造个高斯内核函数。n很少，m很多，使用高斯内核函数可能很合适。\n\n\n\n如果选择要用高斯核函数，接下来要做的事：\n根据使用的支持向量机软件包可能需要实现一个核函数或者相似函数。因此如果使用Octave来实现支持向量机的话，那么就需要提供一个函数来计算核函数的特征值，它将自动的生成所有特征变量。因此对应一个i需要计算f_i。\n如果有大小很不一样的特征变量，要在使用高斯核函数之前，将这些特征变量的大小按比例归一化。下面以计算x与l之间的范数为例，如果第一特征房子面积特别大，第二特征房间个数在1到5之间，那么间距可能都是由特征一所决定，所以需要归一化。\n\n\n\n\n\n默塞尔定理是确保所有的SVM包能够用大类的优化方法并可以快速得到参数sita。其他核函数也都满足默塞尔定理，如下所示：多项式核函数（一个是自己添加的值可以是0、1、3…，还有一个是指数可以修改）。\n\n\n\n在多类分类中，输出在多个类别中恰当的判定边界。如果有k个类别用以将每个类别从其他的类别中区分开来。例如第一个参数sita_1,y&#x3D;1作为正类别，其他作为负类别得到的，以此类推。\n\n\n\n逻辑回归开始构造了SVM，然后更改下代价函数。如果n相对于m足够大，那么我通常使用逻辑回归或者线性核函数；如果n很小，m适中，通常使用高斯核函数的SVM比较好；当n很小m很大，建议手动地创建拥有更多的特征变量，然后用逻辑回归或者不带核函数的支持向量机。这种情况不适用神经网络，因为运行会很慢，而且SVM不用去考虑局部最优的问题。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day13无监督学习","url":"/2021/07/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day13%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/","content":"01 无监督学习\n无监督学习：训练集没有标签，也就是图上的点没有任何标签信息。我们要将这系列无标签的数据，输入到算法中，然后我们要让算法找到一些隐含在数据中的结构，这个图中数据集中的点两组分开的簇，这种能够找到这些簇的算法叫做聚类算法。\n\n\n02 K-Means算法K均值算法是现在最为广泛运用的聚类算法\n\n\n通过K均值算法将下图分为两个簇的具体操作：\n随机生成两点（聚类中心），选取两点的原因是想将数据聚成两类。\n\n\nK均值算法是个迭代算法，可以做两件事：簇分配和移动聚类中心。\nK均值算法每次内循环的第一步是要进行簇分配，观察图中的绿点，是接近哪个聚类中心，距离哪个近就分配给哪个。\n\n\n\n根据离红色或者蓝色聚类中心的远近，将每个点染成红色或者蓝色。\n\n\n\nK均值算法每次内循环的第二步是移动聚类中心，将两个聚类中心移动到同色点的均值处。\n\n\n\n接着我们进入下一个簇分配步骤：再次检查所有的无标签样本，然后根据这些点离红色或者蓝色聚类中心的远近，将其染成红色或者蓝色。\n\n\n\n再一次移动聚类中心，将两个聚类中心移动到同色点的均值处。\n\n\n\n以此类推，不断重复上面操作，得到最终结果。\n\n\n\nX^(i)是一个n维实数向量，这也就是训练样本是n维向量而不是n+1维向量的原因。\n\n\n\n以更加规范的格式写出K均值算法。\n\n\n\n假设u_k是某个簇的均值，那么如果存在一个没有点的聚类中心，会怎么样？–直接移除那个聚类中心，这样会得到k-1个簇而不是k个簇；如果你确实必须要k个簇，那么就随机初始化这个聚类中心。\nK均值算法最常还应用在分离不佳的簇的问题（右图），如果想把衣服根据体重身高分为小中大三个号，这时就可以使用k均值算法。\n\n\n03 优化目标\n当运行k均值算法时，我们会对两组变量进行跟踪。\n\nc^(i)代表的是当前样本x^(i)所属的那个簇的索引。\n用u_k表示第k个聚类中心的位置（K表示聚类中心的数量，k表示聚类中心的下标）。\n\n\nk均值算法的优化目标即最小化代价函数，代价函数有时也叫失真代价函数或者K均值算法的失真：\n\n\n\n\n簇分配实际上就是，不改变聚类中心的位置，而是选出c^(1)到c^(m)来最小化这个代价函数；而移动聚类中心实际上就是选择u值来最小化J。然后保持迭代。\n\n\n04 随机初始化如何初始化K均值聚类算法？引导讨论如何使算法避开局部最优。\n\n\n初始化聚类中心的比较好的方法，通常随机挑选K个训练样本，然后设定u_1到u_k，由于随机初始化状态不同，所以K均值最后可能会得到不同的结果。（最好使用这种方法）\n\n\n\n随机化得到结果比较好（右上图），也可能得到不好的局部最优值（右下图）。局部最优值指的是畸变函数J的局部最优，相对来说左下角图的这些局部最优所对应的情况，其实是K均值算法落在了局部最优，因而不能很好的最小化J。如果想要K均值算法找到最有可能的聚类（右上图），我们可以尝试多次随机初始化，并且运行多次。\n\n\n\n具体步骤如下：典型运行K均值算法的次数在50到1000次，需要在最后选取代价最小的一个。如果你运行K均值算法时，所用的聚类数相当小（2到10之间），那么多次随机初始化通常能保证找到较好的局部最优解，保证能找到更好的聚类，很好的最小化J；如果K非常大的话，多次初始化也不会有太大的改善。更有可能第一次初始化就会有很好的结果。\n\n\n05 选取聚类数量K均值如何去选择聚类数量？–最常用还是根据观察可视化的图，或通过观察聚类算法的输出去手动选择。\n\n\n当谈到选择聚类数量的方法时，可能谈到的一种方法叫“肘部法则”。我们所要做的是改变K，我们先用一个类来聚类，然后计算代价函数，接着用两个、三个…..（其中可能会多次初始化），可能会得到一个图像（随着K增多J下降），选择K&#x3D;3可能是正确的，因为K&#x3D;3之前下降很快，而之后就下降很慢。但是实际上好多时候都是右图，比较平滑没有拐点，从而不能准确选择K。不能期望它能解决任何问题。\n\n\n\n如果后续目的如市场分割能给一个评估标准，那么决定K更好的方法是看哪个聚类数量能更好地应用于后续目的。从商业角度看，例如如果K&#x3D;5是否我的衣服能够很好的满足顾客需求，还是K&#x3D;3时更加符合利益。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day14降维","url":"/2021/07/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day14%E9%99%8D%E7%BB%B4/","content":"01 目标 I：数据压缩\n想要使用降维的的原因：\n数据压缩，数据压缩不仅能使数据占用少量的内存或硬盘空间，还能对算法进行加速。\n\n\n如果特征高度相关，那么真的可能需要降低维数。\n将二维降到一维：两个特征变成一个特征，把每个样本都保持为一个数字，这样就能把内存需求（数据空间需求）减半。\n\n\n\n从三维降到二维：\n\n\n02 目标 II：可视化\n想要使用降维的的原因：\n\n可视化数据：将数据从50维或者更高维降到三维或者两维，这样就可以将其在图中画出来更好的理解他。\n\n\n50维数据：\n\n\n\n\n从50维降到2维，通常我们要了解z特征大致意味着什么。\n\n\n\n并画出2维图像\n\n\n03 主成分分析问题规划1对于降维问题最常用的一种算法叫主成分分析方法(PCA)的算法，本节课会试着用公式准确的表述PCA的用途。\n\n\nPCA所做的就是试图寻找一个投影平面对数据进行投影，使得能最小化这个距离。（PCA所作的是找到一个低维平面也就是图中的线，然后将数据投影到上面，使得蓝色的小线段（投影误差）长度平方最小）。对比可得选择橘色的而不选择粉色的。\n\n\n\n在应用PCA之前最常规的做法是先进行均值归一化和特征规范化使得特征量x_1和x_2其均值为0，并且其数值在可比较的范围之内。\n\nPCA与线性回归的区别：左图为线性回归，右图为PCA。线性回归的点是垂直横轴的（最小化蓝线之和的平方），而PCA的点是垂直那条线的（最小化蓝线的长度）。线性回归是通过输入x来预测y，PCA的特征值x之间都是平级关系。\n\n\n\n04 主成分分析问题规划2\n在使用PCA之前首先要做的的就是对数据进行预处理。\n给定一个训练集一定要做的是执行均值标准化：我们首先计算每个特征的均值，我们用减去它的均值取代每个特征x，这将使每个特征的均值正好为0\n根据数据也有可能需要进行特征缩放，缩放每个特征到一个相对的价值范围。\n\n\n\n\n\nPCA要做的是：计算这些向量例如u^(1)（即投影平面）；计算这些数字z\n\n\n\n用公式求解的过程：我们想把n维数据降到k维度，我们首先要做的是计算协方差（通常用大写的Sigma表示，是表示矩阵而不是求和），然后运用Octave中的svd()(奇异值分解)，也可以用eig()，不过svd()在数值上更加稳定。输出的将是三个U,S,V矩阵，我们真正需要的是U矩阵，可以发现U矩阵的列正是我们想要的u^(1)、u^()….。把n维数据降到k维度，就提取前k个向量。\n\n\n\n接下来我们要做的是获取我们的原始实数域数据集x找到一个低维的表示z。然后运用公式求解z\n\n\n\n协方差矩阵sigma的一个向量化实现：sigma &#x3D; (1&#x2F;m)X^TX,类似于K均值这里的X_0不能为1.\n\n\n05 主成分数量选择n维特征减少为k维特征，k为PCA算法的一个参数，也被称为主成分的数字，人们如何考虑选取k？\n\n\nPCA试图去减小投影误差平方的平均值，也就是试图减小x和x在低维面的投影的距离的差的平方。\n数据的总方差为样本x的平方和的平均值，也就是我们训练集中每个样本的平均长度（我们样本距离全零向量（原点）的距离）。\n选择k一个常用的经验方法是选择较小的值，使得这两者之间的比值小于0.01：让平均投影误差平方&#x2F;数据的总方差（数据的波动程度）。我们希望这个比例小于0.01或者小于1%，用PCA语言来说就是99%的方差性会被保留。当然0.01也可以换成其他值。为了保留99%的方差可以减少数据维数，但仍保留大部分的方差。\n\n\n\n下面的算法不断尝试从1开始修改k的值，然后进行PCA运算，最终使99%的方差性会被保留。这是一种方式来选择最小的k从而使99%的方差被保留。另一种方法是：通过SVD()计算出S矩阵（只有对角才有值，剩下的值为0），然后通过公式直接将k从1开始带进去，取前k个对角线的值相加&#x2F;整个对角线的值相加，看是否大于0.99.如果大于就选择这个k。对比可以看出第二种算法效率高，因为只需调用一次SVD()，而第一种需要多次调用PCA算法，相对来说效率低。\n\n\n06 压缩重现如何从低维的z^(i)变回原来的高维x^(i)?\n\n\n原始数据的重构：从压缩之后的低维的z^(i)变回原来未压缩的高维x^(i)：应用如下公式：\n\n\n07 应用 PCA 的建议\n使用PCA算法对监督学习算法进行加速的步骤：\n检查已经被标记的训练集，并抽取输入x，我们就得到了一个无标签的训练集x^(1)….x^(m)。\n用PCA得到原始数据的低维表示z，得到新的训练集。\n我们可以把这个低维的训练集输入到一个学习算法中，可以是神经网络、逻辑回归算法进行预测。\n注意PCA运算只能在训练集拟合这些参数，而不能在验证集或者测试集。定义x到z的映射后才能应用验证集和测试集中\n\n\n\n\n\n对PCA错误的使用就是尝试使用PCA来减少数据维度去防止过拟合，正确方法就是使用正则化。PCA运算是不使用标签的，只是针对输入x^(i)变为低维z^(i)，而不关心y，如果有99%的方差得以保留可以防止过拟合，但是也可能舍弃一些重要的信息，使得方差保留过低。\n\n\n\n在写下一个包含PCA的项目计划之前，应该问一问这个问题：如果我们直接去做而不使用PCA会怎样？一般直接建议：首先使用最原始的数据x^(i)，只有这么做达不到目的的情况下才考虑使用PCA和z^(i)，不要一开始就花大量的时间去应用PCA，计算k等等。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day15异常检测","url":"/2021/07/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day15%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/","content":"01 问题动机异常检测主要用在非监督学习，但从某些角度看，跟有监督学习问题是非常相似的。\n\n\n异常检测问题就是我们希望知道新的测试数据是否有某种异常，换句话说新的测试数据是否需要进一步测试。如下面这个图（飞机引擎的例子），其中x_1、x_2是飞机引擎的特征。通过测试发现如果x_test在对应点里面，那么他就不存在异常，如果在对应的外面，那么就存在异常。\n\n\n\n我们通常认定这m个数据都是异常或者都不是异常的，我们需要一个算法告诉我们一个新的样本数据是否异常。因此我们要做的就是给定无标签训练集，我们对数据建模即p(x)，也就是对x的分布概率建模。如果测试集的概率p低于阈值那么就将其标为异常，否则正常。越中心的点概率越高。\n\n\n\n异常检测最常见的应用是欺诈检测，例如许多购物网站常用来识别异常用户。可以针对不同的用户活动计算特征变量x^(i)，于是建立一个模型来表示用户表现出各种行为的可能性。x_1也许是用户登陆的频率，x_2也许是用户访问某个页面的次数……，然后根据这些数据建立一个模型p(x),就可以用这个模型发现网站上行为可疑的人。\n另一个例子就是上面的飞机引擎例子。\n第三个是数据中心的计算机监控，这种技术被各大数据中心来监测大量的计算机可能发生的异常。\n\n\n02 高斯分布（正态分布）\n假设x是一个实数的随机变量，如果x的概率分布服从高斯分布，那么记作X~N(均值，方差（标准差的平方）)。高斯分布的概率密度绘制出来是一个钟形，均值控制中心位置，标准差控制宽度。\n\n\n\n下面是参数不同画出来的图像，不管怎么样阴影部分的积分一定是1。\n\n\n\n参数估计问题：给定数据集希望能找到能够估算出均值和方差的值。下面是公式：\n\n\n03 算法\n我们处理异常检测的方法是：我们我们要用数据集建立起模型概率p(x)，我们要试图解决出哪些特征量出现的概率较高，哪些出现的概率较低。分布项p(x)的估计问题有时也称为密度估计问题，我们列出p(x)的计算公式（x_1到x_n连乘）如下：\n\n\n\n异常检测算法：\n选择特征量（能够描述所收集数据的一般特性的特征），能够帮助我们指出那些反常的样本。\n给出m个未作标记的样本的训练集。\n进行参数拟合u_1到u_n，(sita_1)^2到(sita_n)^2,运用公式来求解这些参数。\n给一个测试样本，根据p(x)的公式来测量是否异常。\n\n\n\n\n\n如何对这些数据拟合出参数值，通过第一个图的数据求出第二个图（概率图），然后将第二个图两个数据进行相乘画出第三个图（三维图）。如果一个想要检测一个样本是否异常，可以直接看三维图，异常的都在图像下围显示（概率低），而正常都在图像上围（概率高），其中上下围以一个值（伊克塞了吗）作为分界线。\n\n\n04 开发和评估异常检测系统\n实数评估的重要思想：当你为某一个应用开发学习算法时，你需要进行一系列的选择，比如选择使用什么特征。如果有一个方法通过返回一个实数来评估算法，那么就将变得容易多。如果有一个特征要考虑该不该将其纳入，就可以将其带入算法中返回一个实数来告诉你纳入前后对算法的影响。\n能够评估异常检测算法的标准方法：用一些带标签的数据来指明哪些是异常样本，哪些是正常样本。\n我们首先假设一些训练集看作是无标签的，他们是很大的正常样本的集合，即使其中掺杂了少许的异常样本也没关系。接下来在定义一些验证集和测试集（包含了已知是异常的样本即y&#x3D;1）用来评估这个异常检测算法。\n\n\n\n举一个例子：飞机成产了一万个正常飞机，2到50个异常飞机。把这些数据分配给训练集、验证集和测试集的经典方法是：分配正常样本是6：2：2。异常样本只分给验证集和测试集一人一半。按照道理来说验证集和测试集应该是完全不同的两种数据。\n\n\n\n得到训练集、验证集和测试集后推导和评估算法：\n使用训练集拟合模型p(x)，也就是将这m个无标签（实际上都是正常的）样本都用高斯函数来拟合。\n在验证集和测试集给出x的值，算法将预测出y的值，y&#x3D;1对应异常样本，y&#x3D;0代表正常样本。\n\n\n对于这个问题如果数据是倾斜数据（绝大多数数据都是正常的），我们就应该采用原来学过的真阳性、假阳性、真阴性、假阴性来计算召回率和准确率来预测算法的好坏。\n如果有一个验证集一个选择参数（伊克塞了吗）的方法就是尝试去使用许多不同的值，然后选择一个能够最大化F_1-score这样的实数，或者有其他好表现的。\n\n\n05 异常检测 VS 监督学习\n什么情况下很可能使用异常检测算法以及什么时候使用监督学习算法？\n\n第一种–&gt;对于异常检测算法：它有很少的正样本和很多的负样本，当我们在处理估计p(x)的值来拟合所有的高斯参数的过程中，我们只需要负样本就够了；相反对于监督学习算法：在合理的范围内会有大量的正样本和负样本\n第二种–&gt;对于异常检测算法：经常会有许多不同类型的异常，因此如果是这种情况你会有很少量的正样本，对于一个算法就很难从少量的正样本去学习异常，尤其是未来可能出现的异常可能会和已有的异常截然不同。比如你在正样本中已经了解到5个或者更多发生故障的情况，但是可能到了明天你就需要检测一个全新的集合（新的异常），这种情况就可以对负样本用高斯分布模型来建模；相反对于监督学习算法：有一个足够多的正样本或者一个能识别正样本的算法（未来可能出现的正样本与你当前训练集中的正样本类似），他能观察大量的正样本和大量负样本来学习相应的特征，可以正确区分正负样本。（例如垃圾分类）\n\n\n\n下面是一些异常检测和监督学习的例子，对于欺诈行为&#x2F;飞机引擎&#x2F;计算机检测，如果有大量的欺诈行为&#x2F;引擎异常&#x2F;计算机运行异常的情况，就可以转化为监督学习，但是一般都是异常检测；对于垃圾分类，天气预报、癌症分类等问题有大量的同量级正负样本这些情况就使用监督学习。\n\n\n\n\n总结一句话就是异常检测以正常（负样本）来建模，监督学习以不正常（正样本）来训练。\n\n06 选择要使用的功能你使用什么特征来实现异常检测算法将会运用产生很大的影响\n\n\n在异常检测中我们要做的其中一件事就是使用高斯分布来对特征建模，所以我们经常做的一件事就是画出数据或者用直方图来表示数据，以确保这些数据在进入异常检测算法前看上去比较接近高斯分布。当然即使数据不是高斯分布也是可以运行的，就是运行好坏的问题。例如下图所示，图一是比较理想的，如果得到图二，我希望对数据进行一些如下不同的转换使得它看上去更接近高斯分布。\n\n\nhist(x.^0.05,50)\n\n\n你如何得到异常检测算法的特征：通常用的方法就是通过一个误差分析步骤（跟我们之前讨论监督学习算法时误差分析的步骤是类似的）。我们先完整地训练出一个算法，然后在一组验证集上运行算法，然后找出那些预测出错的样本，并看看我们能否找到一些其他的特征来帮助学习算法，让那些在验证集中判断出错的样本表现得更好。下面通过一个例子来解释这个过程。一些大众的问题就是正负样本的概率都很高，以一个特征为例，x&#x3D;2.5时的一个测试样本是异常的，但是混在了正常样本里，这时就需要找到一个新的特征来使算法可以很好的将x&#x3D;2.5的测试样本进行分离。（绿色的代表异常）。\n\n\n\n下面是一些对异常检测算法选择特征变量时的一些思考：对于那些可能异常的样本即不选择那些特别特别大，也不选择特别特别小的特征。以监控数据中心的计算机的例子，如果一个计算机出现了故障，下面给出了一些可选的特征包括占用内存、磁盘每秒访问的次数、CPU负载和网络流量，现在假如说我怀疑某个出错的情况，在我的数据集中我的CPU负载和网络流量应该是线性关系，比如说检测服务器，一个服务器在运行多台电脑，这时x_3和x_4都很高；如果在运行任务时出现了死循环（x_3升高，x_4正常），这时要检测就可以建立一个新的特征x_5或者x_6。通过建立新的特征就可以捕捉到这些特殊的特征组合所出现的异常值。\n\n\n07 多变量高斯分布这节课将会学习目前为止学习的异常检测算法的一种可能的延伸，这个延伸会用到多元高斯分布。他有一些优势也有一些劣势，他能捕捉到之前的算法检测不出来的异常。\n\n\n异常检测算法给x_1和x_2建模的方法如下，给出一个样本(绿色的)，可以从大体上看出x_1和x_2是线性的，而绿色的可以看出x_1很少，而x_2很多是不符合线性的。该图认为同一个圈的概率是一样的，但是实际上从图可以看出其实是不一样的。\n\n\n\n为了解决这个问题，我们要开发一个改良版的异常检测算法，要用到多元高斯分布或者叫多元正态分布。有一个特征向量x，我们不要对x_1和x_2分别建模，而是要建立一个整体的p(x)模型。它的参数是n维向量(u)和n×n的协方差矩阵。\ndet(Sigma)--&gt;用来计算行列式\n\n\n\n我们来看下这里的p(x)是什么样的。其中Sigma衡量的是方差或者说是x_1和x_2的变化量。缩小方差相当于缩小(Sigma)^2，下面是同时改变Sigma的两个值。\n\n\n\n\n接下来我们只改变特征向量x_1的方差，展示如下：\n\n\n\n同样的们只改变特征向量x_2的方差，展示如下：\n\n\n\n多元高斯分布一件很棒的事是你可以用它给数据的相关性建立模型（可以用它来给x_1和x_2高度相关的情况建立模型），如果改变非对角线上的元素你会得到一种不同的高斯分布，随着非对角线上的值不断增加可以看出x接近y（大部分数据落到了x_1&#x3D;x_2），变得更窄。当把其设为正值时如下：\n\n\n\n当把其设为负值时（x_1&#x3D;-x_2）如下：\n\n\n\n当然还可以改变平均参数u，即中心点所在位置。\n\n\n08 使用多变量高斯分布的异常检测\n给定参数集来进行参数拟合或者说是参数估计问题（其中Sigma和PCA中写的是一样的）。\n\n\n\n把这些结合起来开发一个异常检测算法：\n用我们的数据集来拟合模型\n有一个测试样本，用多元高斯分布的公式来计算p(x)\n比较p(x)与伊克塞了吗的大小来得出结果。\n\n\n\n\n\n原始模型对比多元高斯模型，多元高斯模型的轮廓都是轴对齐的。其实原始的模型就是多元高斯模型的特殊形式，，当多元高斯模型Sigma的非对角线都为0的情况下，将原始的方差放入到Sigma中，这时两个模型就会完全相同，也就是说这个用了多元高斯分布的新模型，比起之前的旧模型，这个新模型对应的分布方程的轮廓就是轴对齐的，所以不能用不同的特征之间的关系进行建模。\n\n\n\n那么什么时候用原始模型（比较常用），什么时候用多元高斯模型呢？比如之前计算机检测的例子，原始模型可能就需要建立一个新的特征，而多元高斯模型就能自动捕捉这种不同特征值之间的关系。\n原始模型的一个巨大的优势就是计算成本比较低（能适应数量巨大的特征），而多元高斯模型需要计算Sigma的逆矩阵也就意味着计算成本非常高。原始模型还有个优势是即使你有一个较小的有一定相关性的训练集也能顺利运行，而多元高斯分布模型需要样本的数量大于特征的数量（因为需要求逆矩阵）。我们使用多元高斯分布模型当且仅当m&gt;&gt;n（如果不满足这一点那么多元高斯分布模型就会有很多参数，因为协方差矩阵是一个n*n的，所以协方差矩阵有n^2个参数，同样因为是一个对称矩阵所以更接近n^2&#x2F;2），所以需要确保有一个很大的m值，确保有足够的数据来拟合变量。\n如果你需要捕捉一些具有相关性的特征，通常是手动设计新的特征，但是当m很大或者是n不是很大时这时多元高斯模型更好。\n如果在实际操作中发现Sigma是奇异的不可逆的那么有两种情况：\n没有满足m大于n的条件\n存在冗余特征（比如x_1&#x3D;x_2、x_3&#x3D;x_4+x_5）\n\n\n\n\n\n总结下使用多元高斯分布来做异常检测，可以自动地捕捉正负样本各特征之间地关系。如果发现某些特征的组合值是异常的他就会标为异常样本。\n\n","tags":["机器学习"]},{"title":"机器学习 day16推荐系统","url":"/2021/07/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day16%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/","content":"01 问题规划特征对于机器学习来说是十分重要的，机器学习领域有一个伟大的想法，对于某些问题有一些算法可以自动的学习一系列合适的特征。\n\n\n我们为什么要谈论推荐系统？\n它是机器学习中的一个重要的应用，比如说亚马逊会根据你之前所买的书来给你推荐一些书。\n有一些环境能让你开发某个算法来学习使用哪些特征，而推荐系统就是那些环境中的一个例子，通过推荐系统我们能领悟一些特征学习的思想。\n\n\n推荐系统问题的组成：以电影评分为例，先说下这些符号的意思。n_u表示用户的数量、n_m表示电影的数量、r(i,j)代表用户j是否对电影i进行评价（&#x3D;1代表评价了），当用户对电影进行评分后会得到一个值y(i,j)，它代表用户j对电影i所给出的评分（0~5星表示）。\n因此推荐系统的问题是给出r(i,j)和y(i,j)数据然后去查找那些没有评分的电影，并试图预测这些电影的评价星级。\n\n\n\n总结：如果我们想开发一个推荐系统，那我们应该想出一个学习算法，一个能自动为我们填补那些缺失值的算法，这样就可以知道用户还有哪些电影没看过并推荐新电影给用户。\n\n02 基于内容的推荐算法\n我们用x_1（一部电影为爱情片的程度）和x_2（一部电影为动作片的程度）来表示电影的特征。为了做出预测我们把每个用户的评价预测值看做成一个线性回归问题。预测值就是用户j所学参数的转置与电影特征的内积。\n\n\n\n我们要m^(j)表示评价了电影j的用户数量，为了学习用户参数向量（sita）^(j)我们应该怎么做呢？这是一个基本的线性回归问题，我们可以直接选择一个参数向量，那么这里的预测值会尽可能接近我们在训练集中观察的值。为了学习参数向量我们来最小化参数向量（我们对所有用户j评价的所有电影的(预测值-实际观测值)的平方求和）再除以m。这就像是线性回归我们选择参数向量来最小化这种方差项，并且也可以加入正则化项。如果将这个公式最小化，你可以得到一个很好的对参数向量的估计值，用来对用户j的电影评价做预测。\n\n\n\n当构建推荐系统时，我们不仅是要学习单个用户的参数，我们要学习的是所有用户的参数向量，这时就要用到下面这个式子：\n\n\n\n总结一下：图片上面是我们的优化目标函数，换一种写法J依旧是优化目标函数也是我们试图最小化的项。如果去推到梯度下降更新的话，将会得到下面公式（分别是k&#x3D;0和k!&#x3D;0的情况，因为上面的公式k是不等于0的），用梯度下降算法进行参数更新，最小化J来学习所有的参数。\n\n\n\n基于内容的推荐算法，因为我们假设变量是已有的即我们有描述电影内容的特征量（电影中爱情成分和动作成分有多少），同时用这些特征量来进行预测。\n\n03 协同过滤\n协同过滤有一个很有意思的特性叫特征学习，这种算法能自行学习所要使用的特征。\n我们假设已经知道了每个用户的参数，那么通过每个用户的评分就可以算出一个电影包含爱情和动作的程度。（右下角)\n\n\n\n我们将这一学习问题标准化到任意特征x^(i)，求出x^(i)让预测值尽可能的接近真实值。\n\n\n\n基于内容的推荐算法是给特征求参数，第二个是给参数求特征。实际上我们可以随机地猜取一些参数，然后就能得到特征，再根据特征求参数不断地迭代得到更好地参数和特征，最终将会收敛到一组合理的特征和参数。这个过程就是协同过滤算法。\n\n\n\n对于推荐系统问题，仅建立在每位用户都对数个电影进行了评价，并且每部电影都经过数位用户评价的情况下，这样才能重复这个迭代过程，才能求出参数和特征。\n总结下：协同过滤算法是指当你执行算法时，要观察大量的用户及用户的实际行为来协同得到每个人对电影更佳的评分值。协同的另一层的意思就是说每一位用户都在帮助算法更好的进行特征学习。如果每一个用户都对一部分电影做出了评价，那么每个用户都在帮助算法学习出更适合的特征，然后这些被学习出来的特征又可以更好的预测其他用户的评分。\n\n04 协同过滤算法\n存在一种算法不需要不停的计算特征和参数，而是能够将特征和参数同时计算出来。下面就是这种算法，需要将前两个优化目标函数结合为一个。第一个平方误差项（所有用户j的总和及所有被该用户评分过的电影总和）和第二个平方误差项（与上面那个是相反的运算：对每部电影i，将所有对它评分过的用户j求和）相加得到新的平方误差项（对所有有评分的用户和电影进行求和），剩下两项拖下来。\n新的优化目标函数J有一个特性，你将x作为常数并关于参数（sita）最优化其实就是在计算第一个式子，反过来你将参数（sita）作为常数并关于x求J的最小值的话，其实就是在计算第二个式子。\n当我们以这样的方法学习特征量时我们不再遵循原来的惯例（x_0&#x3D;1），理由是我们现在是在学习所有的特征，没有必要将一个特征值硬编码为1，因为如果算法真的需要一个特征值为1，那么它可以选择靠自己去获取1这个数值，比如将x_1设为1.\n\n\n\n协同过滤算法步骤：\n将特征和参数初始为小的随机值（这有点像神经网络）\n用梯度下降或者其他的高级优化算法将代价函数最小化（这里没有分出k&#x3D;0的情况是因为不存在x_0&#x3D;1这一项了）\n如果给你参数和特征，就可以预测评分了\n\n\n\n\n\n这个算法可以学习几乎所有电影的特征和所有用户参数，能对不同用户会如何对他们尚未评分的电影做出评价，给出相当准确的预测。\n\n05 矢量化：低轶矩阵分解将介绍协同过滤算法向量化的实现及使用算法可以实现的一些功能（比如说给定一个商品，可以找到与之相关的一些产品）。\n\n\n将数据的预测值写成矩阵形式：\n\n\n\n用另一种方法低轶矩阵分解（矩阵X乘以sita的转置）写出这个算法的所有预测评分：\n\n\n\n利用学习到的属性来找到相关的电影，通常算法会学到一些有意义的特征。我们可以衡量两个电影的相似度（两个电影的特征距离很接近）来找到相关影片。\n\n\n06 实施细节：均值规范化\n下面增加了一个用户，这个用户之前没有给任何电影评过分，将其带入协同过滤算法中。因为用户对电影没有评分，所以算法的第一项对用户参数的选择是没有影响的，只有最后一项可以影响参数的选择，又因为最后一项是正则化，所以说得出来的参数是二维的零向量。二维零向量与哪个二维向量内积都为0，这样的结果不是我们想要的。\n\n\n\n均值归一化的思想可以帮助我们解决这个问题，下面介绍它是如何工作的：把每个电影评分都归一化使得均分为0\n\n将所有的评分都放到Y矩阵中\n计算每个电影所得评分的均值，并将其存放在一个叫u的向量中\n将Y中所有元素-均值\n对新的评分数据集使用协同过滤算法来学习用户参数及电影特征\n最后来计算电影评分：用户参数的转置与电影特征的内积+u（因为训练集中减去了均值，因此在这里需要加上）\n\n\n之前用户参数为二维零向量的问题依然存在，但是第五个用户的预测评分变了，变成了电影评分的均值。选择一个大众比较喜欢的推荐给第五个用户，当然如果一个电影没有评分（就不应该推荐，因为关心没有评价电影的人比关系没有被评价过电影更有意义），也可以对Y的每一列进行均值归一化。\n\n\n\n\n总结一下：均值归一化的实现作为协同过滤算法的预处理步骤，根据不同的数据集，有时可以让你的算法表现得更好一些。\n\n","tags":["机器学习"]},{"title":"机器学习 day17大规模机器学习","url":"/2021/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day17%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","content":"01 学习大数据集大规模机器学习就是处理大数据集的算法\n\n\n一种获取高性能的机器学习系统的途径是采用低偏差的学习算法并用大数据进行训练。\n大数据集学习的特有问题是计算问题。\n在训练一亿个样本之前，我们可以随机选择一亿个样本中的一千个样本，然后用这一千个样本来训练我们的算法。如果用一千个样本训练效果也是一样的话，在训练大量的模型前预先检查往往也是一个明智的选择。如果效果相同的话，可以根据这一千个样本绘制学习曲线，如果画出左图高方差的曲线那么增加训练集还是有作用的，如果是右边高偏差的算法，样本也不会比训练1000个更好了，如果是右图那么自然而然地会添加额外地特征项或在神经网络中添加额外地隐藏单元，这样最终可能得到左边的图。\n\n\n02 随机梯度下降当我们训练集很大时，梯度下降算法的计算量会变得非常大，因此对普通的梯度下降法进行改良为随机梯度下降法，使得算法能够应用于大规模的数据训练。\n\n\n先来回顾下线性回归：第一个式子是假设函数，第二个式子是代价函数，第三个式子是不断地更新参数sita来使得代价函数趋于最小，右图是构建的三维函数可以看出是弓形。\n\n\n\n在参数初始值，运行梯度下降算法，将会不断迭代，最终得到参数的全局最小值。如果m的值非常的大，那么单单是计算微分项就需要很大的计算量，更何况还要一次次的迭代。这个梯度下降算法又叫批量梯度下降，其中批量是指每次都需要同时考虑全部的训练样本。\n\n\n\n随机梯度下降算法每次迭代不需要每次都同时考虑全部的训练样本，仅仅只考虑一个训练样本。为了更好的描述随机梯度下降算法，我们将代价函数定义为右侧的第一个式子，这个代价函数实际上是衡量我的假设函数在某个样本(x(i),y(i))上的表现。而左图第一个总体代价函数可以写成右图第二个式子（假设函数在m个训练样本中每一个样本(x(i),y(i))上的代价函数的平均值），随机梯度下降的步骤如下：\n将所有的m个训练样本重新随机排列。(这保证了遍历时对训练集样本的访问是以随机顺序排列的，这一步能让随机梯度下降在收敛时能够更快一点)\n对所有的训练样本进行遍历，然后做如下参数更新.（就是不断地对参数进行调整来依次适应第一个参数、第二个参数……..）\n\n\n随机梯度下降和批量梯度下降相比不需要对全部的m个样本求和来得到梯度项，而只需要对单个样本就可求出梯度项（黄色框画出来的就是梯度项）。在随机梯度下降过程中我们已经开始一点点把参数向全局最小值的方向进行修改了。\n\n\n\n随机梯度下降每一次迭代都会更快，因此我们不需要对所有训练样本进行求和，每一次迭代只要保证能拟合某一个训练样本即可。虽然它的参数走的线不是一条曲线，但是它是随机而迂回的路径朝着全局最小值的方向移动的。随机梯度下降和批量梯度下降相比收敛形式是不同的，他就是连续不断的在某个区域中朝着全局最小值的方向徘徊，而不是直接打到全局最小值（在实际应用中，只要能接近全局最小值就能得到一个很好的效果）。\n在随机梯度下降法中其实还有一个外层循环（1到10次，通常一次就可，还是取决于数据集m的大小）来决定内层循环的次数\n\n\n\n总结下：批量梯度下降算法是一次就需要遍历全部的训练集，然后在进行迭代（迭代一次就相当于遍历两次全部训练集）才有可能得到全局最小值，而随机梯度下降算法有可能只需要遍历一次就可以的到全局最小值。所以说将随机梯度下降法的思想应用到学习算法中来适应更大的数据集从而提升算法的性能。\n\n03 Mini-Batch 梯度下降Mini-Batch 梯度下降有时甚至比随机梯度下降还要快一些。\n\n\n总结下我们迄今为止学的梯度下降算法：\n批量梯度下降算法每次迭代都要用到所有的m个样本\n随机梯度下降算法每次迭代只需要使用一个样本\n而Mini-Batch 梯度下降算法每次迭代会使用b个样本（b是一个称为Mini-Batch大小的参数，通常选择b&#x3D;10，b的范围是2~100），它是介于批量梯度下降算法和随机梯度下降算法之间的算法。\n\n\n\n\n\nMini-Batch 梯度下降完整算法如下：以步长为10增长为例，仅用前十个样本就能运行算法来更新参数，这也是为什么Mini-Batch 梯度下降比批量梯度下降算法要快的原因。为什么Mini-Batch 梯度下降不像随机梯度下降算法一样每次只使用一个样本呢？–&gt;因为在向量化过程中Mini-Batch 梯度下降比随机梯度下降更快（仅当有好的向量化方法）。\nMini-Batch 梯度下降算法的缺点之一是当有一个额外的参数b时，你需要确定Mini-Batch大小，这需要额外的时间，当然如果有好的向量化算法Mini-Batch 梯度下降比随机梯度下降更快。\n\n\n\n如果有一个合适的向量化的方法，蓝框的求和公式将在10个样本中实现部分并行计算，换句话来说通过合适的向量化方法计算余下的样本，可以部分使用好的数值代数库，然后对b个样本并行进行梯度计算，随机梯度下降算法每次只针对一个样本肯定没有太多的并行计算。\n\n04 随机梯度下降收敛当你运行随机梯度下降算法时如何确保调试过程已经完成，并且已收敛到合适的位置呢？怎样调整随机梯度下降算法中的学习速率a的值呢？\n\n\n批量梯度下降算法确保梯度下降已经收敛的一个标准方法就是绘制优化代价函数（关于迭代次数的函数），我们要确保代价函数J每一次迭代都是下降的。当m教小时使用这个还算可以，但是当训练集m特别大时，你肯定不希望得定期的暂停这个算法来计算蓝色框中的式子，因为每次计算都会遍历整个数据集。\n对于随机梯度下降算法为了检查算法是否收敛可以进行下面的工作：当随机梯度下降法对训练集进行扫描时，在我们使用某个样本(x(i),y(i))来更新参数sita之前，让我们来计算出这个训练样本假设的表现有多好即cost()函数。最后为了检查是否收敛，每1000次迭代就画出前一步骤所计算出来的cost()函数前一千个样本的的平均值，这样通过观察图就可以看是否下降收敛，可以看出算法在你前一千个样本中表现得有多好。\n\n\n\n下面第一个图中红色线代表更小的学习速率a，可以看出更加得平缓但是能得到更好的效果。（因为随机梯度下降不是直接达到全局最小值，而是在这个区域不断震荡，学习速率越小震荡幅度也就越小。）第二个图中得红色线代表样本从一千增加到五千，可以看出得到的曲线比较平滑，但是得到的关于算法表现有多好的反馈就有一点延迟，因为图中每一个数据点是从五千个样本中得到，而不是从之前的1000个样本得到。第三个图由于样本太少所以表现得好像没有下降收敛一样，红线代表样本增加到5000，可以看出比最开始显得下降了。而粉色线也代表样本增加到了五千但是没有啥变化，这就说明算法基本就没有学习，这时需要调整学习速率或者特征或者其他东西。第四个图是上升的趋势，这时算法发散了，这时就需要更小的学习速率。\n\n\n\n总结：如果出现噪声太大或者图像老是上下振动，就可以试着增加求均值的样本的数量，如果图像上升那么就用一个更小的学习速率。\n如果你想要将随机梯度下降到更好的收敛到全局最小值（也是接近哈），那么就需要让学习速率的值随时间变化而逐渐减小。经典的做法就是让a&#x3D;某个常数1&#x2F;（迭代次数+某个常数2），但是很少用，原因有二：一是收敛得到的值已经很满意了，二是还需要确定两个常数，无形中又增加了算法的复杂性还有计算量。\n\n\n05 在线学习在线学习机制可以让我们模型化一些问题，就是我们有连续一波数据，想要用算法从中学习的这类问题。\n\n\n以提供运输服务为例，y&#x3D;1是购买运输服务，y&#x3D;0是不购买，我们想要用（出发地、目的地、我们提供的价格等）特征来学习他们选择我们来运输包裹的概率。如果我们可以估计出每种价格下用户选择使用服务的概率，我们就可以选择一个价格即可能使用户选择我们，我们还会有回报。算法如下：当用户访问我们时，我们会得到与其对应的（x，y）对，在线学习算法就会利用刚得到的（x，y）(因为我们不使用固定的训练集，所以这里不是（x^(i),y^(i)）)来更新参数theta。我们使用完这个样本就会将其丢弃不在使用，这也就是为什么一次只处理一个样本。\n\n\n\n在比如说搜索的例子（又叫点击率预测学习问题 -CTR），当你搜索手机时，他会从100个手机里给你推送10个，提供了特征x(与你搜索的手机关联度)，y&#x3D;1是点击进入。运行此类网站的一个方法就是不停的给用户展示你对他们可能会喜欢的十个手机的预测，每一次用户访问你将会得到十个样本即十个对应的（x，y）对，然后运行在线学习算法来更新参数，对这十个样本利用10步梯度下降法来更新参数。\n\n\n\n在线学习的一个优点就是如果有一个变化的用户群又或者是你在预测的事情在缓慢的变化，在线学习算法可以慢慢地调试你所学习到的假设，将其调节到最新的用户行为。\n总结：在线学习算法与随机梯度下降算法的唯一的区别就是我们不会使用一个固定的数据集，而是获取一个用户样本从那个样本中学习，然后丢弃那个样本继续处理下一个。如果某一个应用有一个连续的数据流，这样的算法是非常值得考虑的。\n\n06 减少映射与数据并行MapReduce思想可以将学习算法应用于随机梯度下降不能解决的规模更大的问题。\n\n\n根据MapReduce思想我们把训练集分为不同的子集，有几台电脑或者机器并行处理训练集数据就分为几个子集。每台机器使用相对应的子集来处理梯度下降算法中的求和部分，这样每个机器都进行工作，效率就提高了好几倍。最后我们将这些temp变量发送给一个中心服务器，中心服务器会整合这些结果，尤其是将更新我的参数theta。可以说这个公式完全等同于批量梯度下降法，只是不需要在一台机器上处理这400个数据。\n\n\n\n就例子而言，四台电脑各自承担四分之一的计算量，你可以加速到四倍速，如果没有网络延迟和忽略传输数据所有时间，那么就是四倍的速度，当然现实中的网络延迟及汇总所需要额外的时间，实际速度比四倍小。\n\n\n\n使用MapReduce思想还需要考虑学习算法是否可以表示成对训练集的一种求和。如果可以就能将学习算法的适用范围扩充到非常非常大的数据集。下面一个例子：高级优化算法需要计算优化目标的代价函数的计算过程和这些偏导项的计算过程，电脑把他们发送给中心服务器，然后将各部分和（temp^(i)_j）加起来，获得总的代价函数获得总的偏导项，接着将这两个值发送给高级优化算法。\n\n\n\n现在也可以在单机上使用MapReduce，因为电脑有多个处理核心CPU，CPU又有多个核心。这样的好处是可以不用担心网络延迟问题。如果你有一个多核机器，同时你有某些线性代数库（可以自动在一台电脑不同核心上进行并行代数运算），并且你的学习算法有非常好的向量化表示，你就可以直接以向量化的形式应用标准学习算法，不用担心并行（线性代数库就可以处理好）。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day18应用举例：照片OCR（光学字符识别）","url":"/2021/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day18%E5%BA%94%E7%94%A8%E4%B8%BE%E4%BE%8B%EF%BC%9A%E7%85%A7%E7%89%87OCR%EF%BC%88%E5%85%89%E5%AD%A6%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%EF%BC%89/","content":"01 问题描述与 OCR pipeline照片OCR问题注重的是如何让计算机读出照片中的文字信息（照片OCR对于读取文档来说很简单，但是对于数码照片来说还是很难的）\n\n\n照片OCR当你输入文字时，计算机就能自动的帮你找到相册里带有这些文字的照片，它有如下几个步骤：\n给定某个照片，将其图像扫描一遍。\n找出照片中的文字信息\n找出照片中的文字信息之后，将重点关注这些文字区域，并对区域中的文字进行识别，当它正确读出这些文字之后，他会将这些文字内容显示并记录下来。\n\n\n\n\n\n总体来说步骤分为三类：文字检测、字符分割以及字符分类（其实还有个拼写校正）。\n\n\n\n像这样的系统，我们把它称为机器学习流水线：首先有一个照片，然后把它传给文字检测系统，识别出文字区域后，将文字区域中的单个字符分割出来，最后对这些单个字母进行识别。\n\n\n02 滑动窗口关于流水线中每个独立的组件的工作原理，主要讲一个叫滑动窗口分类器。\n\n\n照片OCR问题难在文字区域对应的矩形具有不同的长宽比例，而对于行人检测来说，人们的长宽比基本相同。\n\n\n\n建立一个行人检测系统，我们可以这么做：假如决定要把比例标准定为82 * 36（当然其他比例也可以），然后从数据集中收集一些正样本和负样本（都是82 * 36的照片），在你的网络中训练或者使用其他学习算法向其中输入一个82 * 36的图块来对y进行分类，来划分每个图块是否包括一个行人\n\n\n\n下图相当于一个训练集，首先在图片中选取一个矩形块（比如是左上角绿框），然后将图块传送给我们的分类器，来检查图块中是否有行人，然后每次以一定的步长（也称滑动参数）来移动图块，传送给分类器不断地判断图块中是否有行人。然后再以更大窗口移动来判断是否有行人，这样算法便能检测出图中各个地方是否出现行人。这就是一个监督学习分类器，然后使用一个滑动窗口分类器来找出图中所有行人。\n\n\n\n接下来看一下在图片OCR中如何找出图中的文字区域：\n\n首先也是拿出一系列的包括正样本和负样本的训练集。\n\n\n\n训练完后将其应用在一个新的测试集中的图片，在此使用固定比例的滑动窗口，会得到左下角的图片（白色表示文本检查系统发现了文本，而深浅不同的灰色对应的是分类器认为该处有文字的概率），然后将分类器的输出应用到一种叫放大算子（就是扩大白色区域，如何扩大呢？就是通过检查像素附近是否存在白色像素，然后把这一范围内都变成白色）的东西上得到右下角的图，然后需要在右下角图中白色周围绘制边框，文本周围的框宽度应该远大于高度，通过这个特性就可以筛选出正常的文字区域。\n\n\n\n接下来进入识别文本阶段也就是字符分割，在此我们再次使用监督学习算法用一些正样本（可以进行分割）和负样本（不可以进行分割），对分类器进行训练完就可以将其运行在文字检测系统输出的这些文本中，最终可以将图像全部分成单独的字符。\n\n\n\n\n03 获取大量数据和人工数据一个最可靠得到高性能机器学习系统的方法是使用一个低偏差机器学习算法并且使用庞大的训练集去训练他。其中人工数据合成可以为合适的机器学习问题轻松得到大规模的训练集。\n\n\n人工数据合成主要有两种形式：\n\n自己创造数据（从0开始创造新数据）\n已经有小的标签训练集，然后以某种方法扩充训练集（引入失真）\n\n\n假如我们收集到了一个大的标签数据集如左图所示，我们的目标是输入一个图像块然后识别出图像块中央的字符。为了简化操作我们将图片处理成灰度图像而不是彩色图像。如果想要更多的训练样本一个方法就是用不同的字体生成字符，然后将其粘贴到任意不同的背景中，然后可以应用一点模糊算子或者仿射变换（仿射的意思是进行等分、缩放和一些旋转操作），完成这些操作就会得到一个人工合成训练集如右图所示。这个就是自己创造数据。\n\n\n\n\n使用现有的样本生成训练集。可以对图片进行人工拉伸或者人工扭曲（必须要合理的，具有代表性），这样就可以将一个样本变成16个新样本了。通过这种方法就能将一个小的标签训练集扩充为一个更大的训练集。当然不同的机器学习应用，可能其他类型的失真将更合理。以语音识别为例，目的是从对话中获取内容，可以通过人工添加失真引入不同背景音乐，得到大量的训练集。生成的新样本一定要具有代表性是有可能在测试集中见到的样本。\n\n\n\n\n在生成大量人工训练集之前最好画一个学习曲线保证你有一个低偏差高方差的分类器。如果你的偏差太高，可以尝试持续增加分类器的特征数量或者增加神经网络隐藏单元的数量，然后在花精力在生成大量人工训练集，这样就避免了花费大量的时间来收集数据却发现没有多大作用。用学习曲线做一个合理的检验看更多的数据是否真的有用。\n\n获得目前训练集十倍的量需要花费多少工作量（方法）？\n\n人工合成数据\n自己收集数量或者添加标签\n众包数据标记：从花钱网上找人来帮你标记训练集\n\n\n\n\n04 天花板分析：下一步工作的 pipeline上线分析：当你自己或者跟你的团队在设计某个机器学习系统工作流时，这种方法能够提供一个很有价值的信号，知道你工作流中哪一部分最值得花费时间去研究。\n\n\n为了决定如何开发系统一个有效的方法就是对学习系统使用一个数值评价量度，假如我们用字符准确度作为这个量度，给定一个测试样本图像，那么这个数值就表示我们对测试图像中的文本识别正确的比例。如图所示：不管你用什么度量值来度量，整个系统的总的准确率为72%。\n下面是上线分析的主要思想：还是以图片OCR流水线为例，首先我们先关注文本检测，对于每一个测试样本都给一个正确的文本检测结果，换句话说就是要100%正确检测出图片中的文本信息。只需要找到对应图像，然后人为的识别出测试集图像中出现文本的区域，让这个模块人为的输出正确的结果，将结果传送给字符分割模块，然后运行后面两个模块，使用之前一样的评价量度指标算出整个系统总的准确率89%，同样的在上一个处理的基础上，字符分割模块也用全部正确的结果去输出，得到了90%的准确率，字符分类也一样（全都是正确的当然是100%）。\n使用上限分析就可以看出每个模块进行改善后各自的成长空间是多少，可以看出完美的文本检测得到的增益最大。\n\n\n\n人脸识别也是一样：\n\n\n","tags":["机器学习"]},{"title":"机器学习总结","url":"/2021/07/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/","content":"\n监督学习算法：线性回归、逻辑回归、神经网络、支持向量机（在这些问题中会有带标签的数据和样本）\n无监督学习：K-均值聚类算法、主成分分析法（进行降维）、异常检测算法（对算法进行评估）\n特定的应用和话题：推荐系统、大规模机器学习系统（包括并行和映射-化简算法）\n其他的应用：滑动窗口分类器（计算机视觉问题）\n从各个不同的方面给出了如何构建机器学习系统的建议：偏差和方差（尝试了是什么使得机器学习算法工作或者是不工作）、正则化（解决一些方差问题）、学习算法的评估方法：召回率和F1分数这样的评价指标和实践方面的评测方法：训练集-交叉验证集-测试集（当你开发一个机器学习系统时如何合理分配你的时间）、诊断方法：学习曲线和误差分析及上限分析（如何调试算法确保学习算法能够正常工作）。所有这些工具都能帮助你决定下一步该做什么以及怎么分配时间。\n\n\n","tags":["机器学习"]},{"title":"当你的浏览器中地址栏输入地址并回车的一瞬间到页面能够展示回来，经历了什么？","url":"/2022/04/12/%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E5%BD%93%E4%BD%A0%E7%9A%84%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%AD%E5%9C%B0%E5%9D%80%E6%A0%8F%E8%BE%93%E5%85%A5%E5%9C%B0%E5%9D%80%E5%B9%B6%E5%9B%9E%E8%BD%A6%E7%9A%84%E4%B8%80%E7%9E%AC%E9%97%B4%E5%88%B0%E9%A1%B5%E9%9D%A2%E8%83%BD%E5%A4%9F%E5%B1%95%E7%A4%BA%E5%9B%9E%E6%9D%A5%EF%BC%8C%E7%BB%8F%E5%8E%86%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/","content":"（1）浏览器本身是一个客户端，当你输入URL的时候，首先浏览器会去请求DNS服务器，通过DNS获取相应的域名对应的IP（2）然后通过IP地址找到IP对应的服务器后，要求建立TCP连接（3）浏览器发送完HTTP Request（请求）包后，服务器接收到请求包之后才开始处理请求包（4）在服务器收到请求之后，服务器调用自身服务，返回HTTP Response（响应）包（5）客户端收到来自服务器的响应后开始渲染这个Response包里的主体（body），等收到全部的内容随后断开与该服务器之间的TCP连接。\n","tags":["面试题"]},{"title":"请你谈谈网站是如何进行访问的","url":"/2022/04/12/%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E8%AF%B7%E4%BD%A0%E8%B0%88%E8%B0%88%E7%BD%91%E7%AB%99%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E8%AE%BF%E9%97%AE%E7%9A%84/","content":"\n输入一个域名；回车 \n检查本机的 C:\\Windows\\System32\\drivers\\etc\\hosts配置文件下有没有这个域名映射；\n\n\n有：直接返回对应的ip地址，这个地址中，有我们需要访问的web程序，可以直接访问\n没有：去DNS服务器找，找到的话就返回，找不到就返回找不到；\n\n\n","tags":["面试题"]}]