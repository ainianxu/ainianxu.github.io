[{"title":"java day01 Typora","url":"/2021/07/06/java%20day01%20Typora/","content":"Typora的使用熟练使用Markdown语法\n标题的使用一级标题为**#**\n二级标题为**##**\n三级标题为**###**\n字体的使用粗体 hello-&gt;左右两个*\n斜体hello-&gt;左右一个*\n斜体加粗hello-&gt;左右三个*\n删除线hello-&gt;左右两个~\n引用的使用\n引用别人文章时使用，左侧一个&gt;\n\n分割线\n\n左侧三个-\n左侧三个*\n\n\n图片\n本地图片\n\n\n\n网络图片\n\n\n通用方法：**!+[名字]+()**\n超链接CSDN\n方法：**[名称]+(链接)**\n列表\n前面使用的都是有序列表\n方法：数字+.+空格\n\n无须列表方法：**-+空格**\n\nA\nB\n\n\n\n表格\n\n\n名字\n性别\n年龄\n\n\n\n小昊\n女\n20\n\n\n格式如下所示：\n名字|性别|年龄\n–|–|–\n小昊|女|20\n代码public\n\n方法如下：\n英文下的&#96;&#96;&#96;(tab上面的按键)+想要写的语言\n被忽略的windows快捷键\nalt+F4：关闭所在页面\nshift+delete：永久删除\nwindows+tab：切换程序\n\n","tags":["java基础"]},{"title":"java day01 基础","url":"/2021/07/07/java%20day01%20%E5%9F%BA%E7%A1%80/","content":"01 注释单行注释：\n// 单行注释可以注释一行文字\n\n多行注释：\n/*多行注释可以注释一段文字*/\n\n文档注释：\n/***配合JavaDoc使用*/\n\n02 标识符与关键字关键字：class,public等Java硬性要求的代码。\n标识符：类名，变量名，方法名都是标识符。\n标识符的注意事项：\n\n所有标识符都应该以字母，$，或者下划线(_)开始\nString name = &quot;xiaofang&quot;;String $name = &quot;xiaofang&quot;;String _name = &quot;xiaofang&quot;;\n\n首字母之后可以是字母，$，或者下划线(_)或者数字\nString A$ = &quot;xiaofang&quot;;String A_ = &quot;xiaofang&quot;;String A1 = &quot;xiaofang&quot;;\n\n\n\n不能使用关键字作为变量名或方法名\n\n标识符不建议使用中文\n\n标识符是大小写敏感的\n\n\n03 数据类型Java是强类型语言，要求所有变量都必须定义后才能使用。\n\n基本数据类型如下表所示：\n\n\n\n整数类型\n浮点类型\n字符类型\n布尔类型\n\n\n\nbyte占1字节\nfloat占4字节\nchar占2字节\ntrue占1位\n\n\nshort占2字节\ndouble占8字节\n\nfalse占1位\n\n\nint占4字节\n\n\n\n\n\nlong占8字节\n\n\n\n\n\n//整数byte num = 10;short num1 = 15;int num2 = 20;long num3 = 30L;//long类型要在数字后加上L//浮点数float num5 = 10.1f;//float类型要在数字后加上fdouble num6 = 10.33333;//字符char name = &#x27;f&#x27;;//注意String不是关键字//布尔boolean flag = true;boolean flag1 = false;\n\n字节与位的关系：1 Byte&#x3D;8 bit\n\n数据类型面试拓展\n\n整型拓展：\n\nint i = 10;//输出10int i2 = 010;//八进制0开头 输出8int i3 = 0x10;//十六进制0x开头（范围：0~9 A~F） 输出16\n\n\n浮点数拓展：\n由于浮点数有舍入误差，接近但不等于的特点，最好不适用浮点数进行比较，可以使用BigDecimal提供的方法进行比较。\n\n字符拓展：\n所有字符的本质还是数字\nchar s1 = &#x27;a&#x27;;char s2 = &#x27;小&#x27;;System.out.println(s1);//输出 aSystem.out.println((int)s1);//强制转换 输出 97System.out.println(s2);//输出 小System.out.println((int)s2);//强制转换 输出 23567\n\n布尔拓展：\nboolean flag =true;if(flag)&#123;&#125; == if(flag==true)&#123;&#125;//二者是等价的\n\n04 类型转换\n强制类型转换：一般是高容量转换到低容量的转换。格式：**(类型)变量名**\n\nint i = 12;byte b = (byte)i;System.out.println(i);//输出12System.out.println(b);//输出12\n\n\n自动类型转化：低容量到高容量直接转换。\n低 -------------------------------------&gt;高 byte,short,char-&gt;int-&gt;long-&gt;float-&gt;double\n\nint i = 12;double b = i;System.out.println(i);//输出12System.out.println(b);//输出12.0\n\n注意点\n\n布尔类型不能进行转换\n转换的时候可能出现内存溢出，或者精度问题\n\n\n\n//溢出问题int money = 10_0000_0000;//数字之间可以用下划线分割int year = 20;int total = money*year;//计算时溢出 输出为-1474836480long total1 = money*year;//默认为int类型，转换之前就出了问题。所以输出依旧是-1474836480long total2 = money*((long)year);//输出20000000000\n\n//精度问题System.out.println((int)23.7);//输出23System.out.println((int)-20.4f);//输出-20\n\n","tags":["java基础"]},{"title":"java day02 基础","url":"/2021/07/08/java%20day02%20%E5%9F%BA%E7%A1%80/","content":"01 变量、作用域、常量1.1 变量\n变量的格式： 数据类型  变量名 &#x3D; 值\n注意事项：\n数据类型可以是基本类型，还可以是引用类型\n变量名必须是合法的标识符\n变量声明必须以;结尾\n\n\n\nchar x = &#x27;A&#x27;;//基本数据类型int a = 1;//基本数据类型String name = &quot;xiaofang&quot;;//引用类型\n\n1.2 变量作用域public class Hello &#123;    static double salary = 1000;//类变量在类中不在方法中，由static修饰符修饰    String name;//实例变量从属于对象，整型变量默认值为0；布尔变量默认值为false;基本数据类型外默认值都为null。    public static void main(String[] args) &#123;        //定义在方法中为局部变量        int i =10;        System.out.println(i);//输出10        //使用实例变量如下所示：        Hello hello = new Hello();//变量类型 变量名 = new 变量类型        System.out.println(hello.name);//输出null        //类变量        System.out.println(salary);//输出1000.0    &#125;&#125;\n\n1.3 常量\n常量初始化后，值不能再改变\n初始化格式：final 常量名 &#x3D; 值；\n常量名都用大写字母\n\n\n命名规则\n类成员变量：首字母小写+驼峰原则：除了第一个单词外，后面单词首字母大写。xiaoFang\n局部变量：首字母小写+驼峰原则\n常量：大写字母+下划线：XIAO_FANG\n类名：首字母大写+驼峰原则\n方法名：小写+驼峰原则\n\n02 运算符2.1 二元运算符int a = 10;int b = 20;int c = 21;System.out.println(a+b);//输出30System.out.println(a-b);//输出-10System.out.println(a*b);//输出200System.out.println(a/b);//由于int类型，需要舍弃小数点，所以输出0System.out.println(a/(double)b);//输出0.5System.out.println(c%a);//输出1(取余)\n\n2.2 类型转换long a = 101010120121L;int b = 20;short c = 10;byte d = 8;//如果有一个数是long类型，那么最后输出也是long类型System.out.println(a+b+c+d);//输出101010120159//下面自动转为int类型System.out.println(b+c+d);//输出38System.out.println(c+d);//输出18\n\n2.3 关系运算符//关系运算符输出结果是布尔类型int a = 2;int b = 3;System.out.println(a&gt;b);//输出falseSystem.out.println(a&lt;b);//输出trueSystem.out.println(a==b);//输出falseSystem.out.println(a!=b);//输出true\n\n2.4 一元运算符int a = 10;int b = a++;//先赋值再自增int c = ++a;//先自增再赋值System.out.println(a);//输出12System.out.println(b);//输出10System.out.println(c);//输出12\n\n2.5 Math类double pow =Math.pow(3,2);//幂运算System.out.println(pow);//输出9.0\n\n2.6 逻辑运算符boolean a = true;boolean b = false;//逻辑与，两个变量都为真，结果才为真，否则为假System.out.println(&quot;a &amp;&amp; b:&quot;+(a &amp;&amp; b));//输出a &amp;&amp; b:false//逻辑或，两个变量只要有一个为真，结果就为真System.out.println(&quot;a || b:&quot;+(a || b));//输出a || b:true//逻辑否，真变假，假变真System.out.println(&quot;!(a &amp;&amp; b):&quot;+!(a &amp;&amp; b));//输出!(a &amp;&amp; b):true//短路原则int c = 5;boolean d = (c&lt;4)&amp;&amp;(c++&lt;4);//与运算，当第一个为假时，结果就以确定，不再进行下面操作。System.out.println(d);//输出falseSystem.out.println(c);//输出5\n\n2.7 位运算符A = 0011 1100;B = 0000 1101;A&amp;B = 0000 1100;//位与运算，同1才为1，否则为0A|B = 0011 1101;//位或运算，有一就为1，否则为0A^B = 0011 0001;//位异或运算，相同为0，不同为1~A = 1100 0011;//0变1，1变02&gt;&gt;1// 右移/2输出12&lt;&lt;1//左移*2输出4\n\n2.8 字符串连接符a = 10;int b = 20;System.out.println(&quot;&quot;+a+b);//输出1020，String类型在前面+用于连接System.out.println(a+b+&quot;&quot;);//输出30，String类型在后面正常输出\n\n2.9 三元运算符//x ? y : z//如果x==true,则结果为y，否则为zint x =62;String type = x&gt;60 ? &quot;及格&quot; : &quot;不及格&quot;;System.out.println(type);//输出及格\n\n","tags":["java基础"]},{"title":"java day03 基础","url":"/2021/07/09/java%20day03%20%E5%9F%BA%E7%A1%80/","content":"01 包机制\n包就是相当于一个文件夹\n包语句的语法格式：\n\n//package pkg1.pkg2；package com.fang;\n\n\n一般利用公司域名倒置作为包名\n使用某一个包的成员，需要用”import”导入，格式：\n\n//import package1.package1.classname；import com.fang.demo；\n\n02 JavaDoc生成文档/** * @author Fang //@author 用于标记作者 * @version 1.0 //@version 用于标记当前版本，默认为1.0 * @since 1.8 //@since 一般用于标记文件创建时项目当时对应的版本，跟版本号，也可以跟是一个时间，表示文件当前创建的时间 */public class Hello &#123;    String name;    /**     * @param name //@param用于标记参数     * @return //@return 用于返回值     * @throws Exception //@throws 用于抛出异常     */    public String test(String name)throws Exception&#123;        return name;    &#125;&#125;\n\n\n使用cmd生成文档\n\njavadoc -encoding UTF-8 -charset UTF-8 Hello.java\n\n\n使用IDEA生成文档\n\n在IDEA找到工具里的生成JavaDoc文档，配置其他命令行参数-encoding UTF-8 -charset UTF-8防止乱码。\n","tags":["java基础"]},{"title":"java day03 流程控制","url":"/2021/07/09/java%20day03%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","content":"01 Scanner对象\n基本语法：\n\nScanner s = new Scanner(System.in);\n\n\n通过Scanner类的next()和nextLine()方法获取输入字符串，在读取之前一般采用hasNext()与hasNextLine()判断是否还有输入数据。\n\n//创建一个扫描对象，用于接收数据Scanner scanner = new Scanner(System.in);System.out.println(&quot;请输入数据&quot;);//判断用户有没有输入字符if(scanner.hasNext())&#123;//使用next接收String str = scanner.next();//输入xiao fangSystem.out.println(&quot;输出内容为&quot;+str);//输出 输出内容为xiao&#125;scanner.close();//使用完一定要给关闭掉，节省资源\n\n//创建一个扫描对象，用于接收数据Scanner scanner = new Scanner(System.in);System.out.println(&quot;请输入数据&quot;);//判断用户有没有输入字符if(scanner.hasNextLine())&#123;//使用nextLine接收String str = scanner.nextLine();//输入xiao fangSystem.out.println(&quot;输出内容为&quot;+str);//输出 输出内容为xiao fang&#125;scanner.close();//使用完一定要给关闭掉，节省资源\n\n\nnext()与nextLine()的区别\nnext()以有效字符之后的空格作为分隔符胡总和结束符，对于之前遇到的空格，next()会将其去掉；nextLine()以Enter作为结束符。\nnext()不能获得带有空格的字符；nextLine()能获得带有空格的字符。\n\n\n\n02 Scanner进阶使用我们可以输入多个数字，并求其总数及平均值，每输入一个数字用回车确认，通过输入非数字结束输入并输出结果。\npublic class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        double sum = 0;        int count = 0;        while(scanner.hasNextDouble())&#123;            double x = scanner.nextDouble();            count++;            sum +=x;            System.out.println(&quot;输入第&quot;+count+&quot;个数据,总和为&quot;+sum);        &#125;        System.out.println(&quot;总和为&quot;+sum);        System.out.println(&quot;平均数为&quot;+sum/count);        scanner.close();    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day04 流程控制","url":"/2021/07/10/java%20day04%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","content":"01 顺序结构\nJava的最基本的结构就是顺序结构\n它是任何一个算法都离不开的一种基本算法结构\n\n02 if选择结构2.1 if单选择结构public class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(&quot;请输入&quot;);        String str = scanner.nextLine();        //判断字符串是否相等        if(str.equals(&quot;hello&quot;))&#123;            System.out.println(str);        &#125;        System.out.println(&quot;end&quot;);        scanner.close();    &#125;&#125;\n\n2.2 if双选择结构//考试分数大于60就是及格，小于60就是不及格public class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(&quot;请输入&quot;);        int num = scanner.nextInt();        if(num&gt;60)&#123;            System.out.println(&quot;及格&quot;);        &#125;else &#123;            System.out.println(&quot;不及格&quot;);        &#125;        scanner.close();    &#125;&#125;\n\n2.3 多选择结构public class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(&quot;请输入&quot;);        int num = scanner.nextInt();        if(num&lt;=100 &amp;&amp; num&gt;=90)&#123;            System.out.println(&quot;A&quot;);        &#125;else if(num&lt;90 &amp;&amp; num&gt;=80)&#123;            System.out.println(&quot;B&quot;);        &#125;else if(num&lt;80 &amp;&amp; num&gt;=70)&#123;            System.out.println(&quot;C&quot;);        &#125;else if(num&lt;70 &amp;&amp; num&gt;=60)&#123;            System.out.println(&quot;D&quot;);        &#125;else&#123;            System.out.println(&quot;成绩不对&quot;);        &#125;        scanner.close();    &#125;&#125;\n\n03 switch多选择结构public class Hello &#123;    public static void main(String[] args) &#123;        Scanner scanner = new Scanner(System.in);        System.out.println(&quot;请输入&quot;);        String str = scanner.nextLine();        switch (str)&#123;//JDK7之后就可以用字符串            case &quot;fang&quot;:                System.out.println(&quot;fang&quot;);                break;            case &quot;xiao&quot;:                System.out.println(&quot;xiao&quot;);                break;            default:                System.out.println(&quot;wu&quot;);        &#125;        scanner.close();    &#125;&#125;\n\n\ncase穿透：如果没有break，则会按顺序执行，直到遇到break或者程序结束\n\n","tags":["java基础"]},{"title":"java day05 流程控制","url":"/2021/07/11/java%20day05%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","content":"01 while循环\n只要布尔表达式为true，循环就会一直执行下去。\n我们大多数的情况需要让循环停止下来，需要一个让表达式失效的方式来结束循环。\n先判断在执行\n正常业务应该尽量避免死循环。\n如果不满足条件，则不能进入循环。\n\n//1+2.....+100int i = 0;int sum = 0;while(i&lt;100)&#123;    i++;    sum+=i;&#125;\n\n02 do…..while循环\ndo…..while循环至少执行一次\n先执行后判断\n\n//1+2.....+100int i = 0;int sum = 0;do&#123;    i++;    sum+=i;&#125;while (i&lt;100);\n\n\nwhile与do while区别\n\nint i = 0;while (i&lt;0)&#123;    System.out.println(i);//不输出&#125;System.out.println(&quot;..........................&quot;);do&#123;    System.out.println(i);//输出0&#125;while (i&lt;0);\n\n03 For循环\nfor循环语句时支持迭代的一种通用结构，最有效、最灵活的循环结构。\nfor循环执行的次数是在执行前就确定的。\nfor循环也有死循环，格式如下：\n\nfor ( ; ; )&#123; &#125;\n\n\n计算0到100之间的奇数和偶数的和\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        int oddSum = 0;        int evenSum = 0;        for (int i = 0; i &lt;= 100; i++) &#123;            if(i%2==0)&#123;                evenSum+=i;            &#125;else&#123;                oddSum+=i;            &#125;        &#125;        System.out.println(&quot;偶数和&quot;+evenSum);        System.out.println(&quot;奇数和&quot;+oddSum);    &#125;&#125;\n\n\n循环输出1-1000之间能被5整除的数，并且每行输出3个\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        for (int i = 0; i &lt;= 1000; i++) &#123;            if(i%5==0)&#123;                System.out.print(i+&quot;\\t&quot;);//\\t加空格            &#125;            if(i%(5*3)==0)&#123;                System.out.println();//输出完自动换行                //System.out.print(&quot;\\n&quot;);输出完不会换行            &#125;        &#125;    &#125;&#125;\n\n\n打印九九乘法表\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        for (int i = 1; i &lt;= 9; i++) &#123;            for(int j = 1; j&lt;=i;j++)&#123;                System.out.print(i+&quot;*&quot;+j+&quot;=&quot;+(i*j)+&quot;\\t&quot;);            &#125;            System.out.println();        &#125;    &#125;&#125;\n\n04 增强for循环\n主要用来遍历数组与集合\n格式：for(声明语句 ：表达式){ }\n声明语句：是声明局部变量，该变量类型必须和数组元素的类型匹配。\n表达式：是要访问的数组名，或者是返回值是数组的方法。\n\n\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        int[] number = &#123;10, 20, 30, 40&#125;;        for (int x : number)&#123;            System.out.println(x);        &#125;    &#125;&#125;\n\n05 break与continue\nbreak用于强制退出循环，不再执行循环中剩余语句。\ncontinue用于终止某次循环结构，进行下次循环\n\npublic class Hello &#123;    public static void main(String[] args) &#123;       int i = 1;       while (i&lt;100)&#123;           i++;           if(i%10==0)&#123;               System.out.println();               continue;//1               //break;2           &#125;           System.out.print(i+&quot; &quot;);       &#125;    &#125;&#125;1./*1 2 3 4 5 6 7 8 9               2.   1 2 3 4 5 6 7 8 9 11 12 13 14 15 16 17 18 19 21 22 23 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 41 42 43 44 45 46 47 48 49 51 52 53 54 55 56 57 58 59 61 62 63 64 65 66 67 68 69 71 72 73 74 75 76 77 78 79 81 82 83 84 85 86 87 88 89 91 92 93 94 95 96 97 98 99 */\n\n\n打印三角形\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        for (int i = 1; i &lt;= 5; i++) &#123;            for (int j = 5; j &gt;= i; j--) &#123;                System.out.print(&quot; &quot;);            &#125;            for (int j = 1; j &lt;= i; j++)&#123;                System.out.print(&quot;*&quot;);            &#125;            for (int j = 1; j &lt; i; j++)&#123;                System.out.print(&quot;*&quot;);            &#125;            System.out.println();        &#125;    &#125;&#125;","tags":["java基础"]},{"title":"java day06 方法","url":"/2021/07/12/java%20day06%20%E6%96%B9%E6%B3%95/","content":"01 方法定义和调用1.1 方法定义//类.对象.方法System.out.println();\n\n\nJava一定是值传递\nJava方法是语句的集合，他们在一起执行一个功能。\n方法包括在类或对象中。\n方法在程序中被创建，在其他地方被引用。\n一个方法只完成一个功能。\n\n//修饰符+返回值类型+方法名（参数类型+参数名）public static int max(int num1,int num2)&#123;    return 0;&#125;\n\n//比较大小public class Hello &#123;    public static void main(String[] args) &#123;        int max =max(3,2);        System.out.println(max);    &#125;    public static int max(int num1,int num2)&#123;        int result = 0;        if(num1 == num2)&#123;            System.out.println(&quot;等价&quot;);        &#125;else if(num1&gt;num2)&#123;            result = num1;        &#125;else&#123;            result = num2;        &#125;        return result;    &#125;&#125;\n\n1.2 方法调用\n调用方法：对象名.方法名（实参列表）\n当方法返回一个值时，方法调用通常被当作一个值。例如\n\nint max =max(3,2);\n\n\n当方法返回值是void，方法调用一定是一条语句。\n\nSystem.out.println(&quot;hello&quot;);\n\n02 方法的重载\n重载就是在一个类中，有相同的函数名称，但形式参数不同的函数。\n方法重载的规则：\n方法名称必须相同。\n参数列表必须不同（个数不同、类型不同、参数排列顺序不同）。\n返回类型可以相同也可以不同。\n仅仅返回类型不同，不是方法的重载。\n\n\n\npublic static int max(int num1,int num2)public static int max(double num1,double num2)","tags":["java基础"]},{"title":"java day07 数组","url":"/2021/07/13/java%20day07%20%E6%95%B0%E7%BB%84/","content":"01 数组的定义\n数组是相同数据类型的有序集合\n按照一定的先后次序排列组合而成\n每一个数据称作一个数组元素，每个数组元素都可以通过一个下标来进行访问\n\n02 数组的声明及创建\n数组的元素是通过索引访问的，数组索引从0开始\n获得数组的长度：arrays.length\n声明数组：\n\nint[] arrays;//首选int arrays[];//不是首选\n\n\n创建一个数组：\n\narrays = new int[10];\n\n\n声明+创建数组：\n\nint[] arrays = new int[10];","tags":["java基础"]},{"title":"java day07 方法","url":"/2021/07/13/java%20day07%20%E6%96%B9%E6%B3%95/","content":"01 可变参数\n在方法声明时，在（ ）中指定参数类型后加…\n一个方法中只能指定一个可变参数，它必须是方法的最后一个参数。\n\npublic class Hello &#123;    public static void main(String[] args) &#123;       max(1, 2, 3, 4, 5);       max(0.45, 0.55, 0.12);    &#125;    public static void max(double ...i)&#123;//i为可变参数        if(i.length == 0)&#123;            System.out.println(&quot;No Print&quot;);        &#125;        double result = i[0];        for(int number = 0;number&lt;i.length;number++)&#123;            if(result&lt;i[number])&#123;                result = i[number];            &#125;        &#125;        System.out.println(&quot;The Max is&quot;+result);    &#125;&#125;\n\n02 递归\n递归就是：自己调用自己\n递归结构包括：\n递归头：什么时候不调用自身方法。\n递归体：什么时候需要调用自身方法。\n\n\n\npublic class Hello &#123;    public static void main(String[] args) &#123;        System.out.println(f(4));    &#125;    public static int f(int i)&#123;      if(i == 1)&#123;          return 1;      &#125;else&#123;          return i*f(i-1);      &#125;    &#125;&#125;\n\n\n递归的形式：\n\n\n","tags":["java基础"]},{"title":"java day08 数组","url":"/2021/07/15/java%20day08%20%E6%95%B0%E7%BB%84/","content":"01 三种初始化及内存分析\n内存分析\n堆是用来存放new的对象和数组；可以被所有线程共享，不会存放别的对象引用\n栈是用来存放基本变量类型（包含具体数值）；或者存放引用对象变量\n方法区包括了所有的class和static变量\n\n\n\n\n\n三种初始化\n\n静态初始化\n\nint[] arrays = &#123;1,2,3,4,5,6,7&#125;;Man[] man = &#123;new Man(),new Man()&#125;;//在此之前先创建个Man类，进行引用\n\n\n动态初始化\n\nint[] a = new int[2];a[0] = 1;a[1] = 2;\n\n\n默认初始化：数组分配空间后，int类型默认为0\n\n\n\n02 下标越界\n数组的四个基本特点\n\n其长度是确定的，数组一旦被创建，它的大小就是不可以改变的。\n其元素必须是相同类型的。\n数组中的元素可以是任何数据类型，包括基本类型和引用类型。\n数组对象本身是在堆中的,数组元素相当于对象的成员变量。\n\n\n下标的合法区间：[0,length-1]\n\n\n","tags":["java基础"]},{"title":"java day09 数组","url":"/2021/07/16/java%20day09%20%E6%95%B0%E7%BB%84/","content":"01 数组的使用\n配合for循环使用\n\npublic class Hello &#123;    public static void main(String[] args) &#123;      int[] a = &#123;1,2,3,4,5&#125;;      //打印全部的数组元素        for(int i = 0;i&lt;a.length;i++)&#123;            System.out.println(a[i]);        &#125;        System.out.println(&quot;============&quot;);        //计算所有数组的和        int sum = 0;        for(int i = 0;i&lt;a.length;i++)&#123;            sum+=a[i];        &#125;        System.out.println(&quot;总和&quot;+sum);        System.out.println(&quot;============&quot;);        //查找最大的数        int max = a[0];        for(int i = 0;i&lt;a.length;i++)&#123;           if(a[i]&gt;max)&#123;               max = a[i];           &#125;        &#125;        System.out.println(&quot;最大数&quot;+max);    &#125;&#125;\n\n\nFor-Each循环\n\npublic class Hello &#123;    public static void main(String[] args) &#123;      int[] a = &#123;1,2,3,4,5&#125;;        for (int i : a) &#123;//i就是数组元素，a就代表数组            System.out.println(i);        &#125;    &#125;&#125;\n\n\n数组作方法入参\n\n////打印全部的数组元素public class Hello &#123;    public static void main(String[] args) &#123;      int[] a = &#123;1,2,3,4,5&#125;;      printArray(a);    &#125;    public static  void printArray(int[] a)&#123;        for (int i = 0;i&lt;a.length;i++)&#123;            System.out.println(a[i]);        &#125;    &#125;&#125;\n\n\n数组作返回值\n\n//反转数组public class Hello &#123;    public static void main(String[] args) &#123;      int[] a = &#123;1,2,3,4,5&#125;;      int[] reverse = reverse(a);      printArray(reverse);    &#125;    public  static int[] reverse(int[] a)&#123;        int[] b = new int[a.length];        for(int i = 0,j = b.length-1;i&lt;b.length;i++,j--)&#123;            b[j] = a[i];        &#125;        return b;    &#125;    public static  void printArray(int[] a)&#123;        for (int i = 0;i&lt;a.length;i++)&#123;            System.out.println(a[i]);        &#125;    &#125;&#125;\n\n02 二维数组int a[][] = new int[2][5];int[][] b = &#123;&#123;1,2&#125;,&#123;3,4&#125;,&#123;5,6&#125;&#125;;\n\n03 Arrays类\n数组的工具类java.util.Arrays\nArrays类中的方法都是static修饰的静态方法，在使用的时候可以直接使用类名进行调用，而不用适用对象来调用。\n\nint[] a =&#123;1,2,3,55645,121,11&#125;;//数组进行排序   Arrays.sort(a);//数组进行填充   Arrays.fill(a,2,4,0);//从2到4之间进行填充//打印数组元素   System.out.println(Arrays.toString(a));","tags":["java基础"]},{"title":"java day11 稀疏数组","url":"/2021/07/18/java%20day11%20%E6%95%B0%E7%BB%84/","content":"稀疏数组public class Hello &#123;    public static void main(String[] args) &#123;        //1.创建一个二维数组11*11        int[][] array1 = new int[11][11];        array1[1][2] = 1;        array1[2][3] = 2;        //2.输出原始数组        System.out.println(&quot;输出原始数组&quot;);        for (int[] ints : array1) &#123;//ints 相当于array1的每一行            for (int anInt : ints) &#123;//anInt相当于每一个元素                System.out.print(anInt+&quot;\\t&quot;);            &#125;            System.out.println();        &#125;        //3.获取有效数值        int sum = 0;        for (int i = 0; i &lt; 11; i++) &#123;            for (int j = 0; j &lt; 11; j++) &#123;                if(array1[i][j]!=0)&#123;                    sum++;                &#125;            &#125;        &#125;        System.out.println(&quot;有效个数&quot;+sum);        //4.创建一个稀疏矩阵数组        int[][] array2 = new int[sum+1][3];        array2[0][0] = 11;        array2[0][1] = 11;        array2[0][2] = 2;        //5.遍历二位数组，有非零值，存放在稀疏矩阵中        int cout = 0;        for(int i =0;i&lt;array1.length;i++)&#123;            for(int j =0;j&lt;array1[i].length;j++)&#123;                if(array1[i][j]!=0)&#123;                    cout++;                    array2[cout][0] = i;                    array2[cout][1] = j;                    array2[cout][2] = array1[i][j];                &#125;            &#125;        &#125;        //6.输出稀疏数组        System.out.println(&quot;稀疏数组：&quot;);        for (int i = 0;i&lt; array2.length;i++)&#123;            System.out.println(array2[i][0]+&quot;\\t&quot;                    +array2[i][1]+&quot;\\t&quot;                    +array2[i][2]+&quot;\\t&quot; );        &#125;        //7.读取稀疏矩阵        int[][] array3 = new int[array2[0][0]][array2[0][1]];        //8.给其他元素还原        for(int i = 1;i&lt; array2.length;i++)&#123;            array3[array2[i][0]][array2[i][1]] = array2[i][2];        &#125;        //9.打印        System.out.println(&quot;还原数组：&quot;);        for (int[] ints : array3) &#123;//ints 相当于array1的每一行            for (int anInt : ints) &#123;//anInt相当于每一个元素                System.out.print(anInt+&quot;\\t&quot;);            &#125;            System.out.println();        &#125;&#125;    &#125;\n\n输出原始数组0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t有效个数2稀疏数组：11\t11\t2\t1\t2\t1\t2\t3\t2\t还原数组：0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n\n","tags":["java基础"]},{"title":"java day12 面向对象","url":"/2021/07/20/java%20day12%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":"01 什么是面向对象\n属性+方法&#x3D;类 \n面向过程思想\n步骤清晰简单，第一步做什么，第二部做什么….\n面向过程适合处理一些较为简单的问题\n\n\n面向对象思想\n物以类聚，分类的思维模式\n面向对象适合处理复杂的问题\n\n\n对于描述复杂的事务，为了从宏观上把握，从整体上合理分析，我们需要使用面向对象的思想来分析整个系统。但是，具体到微观操作，仍然需要面向过程的思想。\n面向对象编程的本质：以类的方式组织代码，以对象的组织（封装）数据。\n三大特性：封装、继承、多态\n\n02 回顾方法\n当一个类调用静态方法时，调用形式：类名+方法名\n\npublic class Student &#123;    public static void say() &#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;public class Hello &#123;    public static void main(String[] args) &#123;        Student.say();&#125;    &#125;\n\n\n当调用非静态方法时，调用形式：将这个类实例化\n\npublic class Student &#123;    public  void say() &#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;public class Hello &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.say();&#125;    &#125;\n\n\nstatic是和类一起加载的，而不含static的是在类实例化之后才存在，所以下面代码是错误的\n\npublic  static void a()&#123;        b();&#125;public void b()&#123;&#125;\n\n\n一个类中只有一个public class,但是有很多class。\n\n03 类和对象的关系\n使用new关键字创建对象，除了分配内存空间，还会初始化，以及对类中构造器的使用。\n一个项目应该只存在一个main方法\n\npublic class Student &#123;    //属性:字段    String name;    int age;    //方法    public  void study() &#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        //类：抽象的，实例化        //类实例化后会返回一个自己的对象        //student对象就是一个Student类的具体实例。        Student xm = new Student();        Student xh = new Student();        xm.name = &quot;xiaoming&quot;;        xm.age = 3;        System.out.println(xm.name);//xiaoming        System.out.println(xm.age);//3        System.out.println(xh.name);//默认值null        System.out.println(xh.age);//默认值0        xh.study();//hello    &#125;&#125;\n\n04 构造器详解\n一个类即使什么都不写，也会构造一个方法。\n\n构造器：\n\n特点：必须和类的名字相同；必须没有返回类型，也不能写void。\n作用：new本质就是调用构造方法；初始化对象的值。\n注意点：定义有参构造之后，如果想使用无参构造，必须显示的定义一个无参构造。\n\n\n调用无参构造函数\n\n\n\npublic class Student &#123;    String name;    public Student()&#123;        this.name = &quot;xiaofang&quot;;    &#125;    public Student(String name)&#123;        this.name = name;//this.name代表对象本身的name,name是传递下来的name。    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;     Student student = new Student();        System.out.println(student.name);//xiaofang    &#125;&#125;\n\n\n调用有参构造函数\n\npublic class Student &#123;    String name;    public Student()&#123;        this.name = &quot;xiaofang&quot;;    &#125;    public Student(String name)&#123;        this.name = name;//this.name代表对象本身的name,name是传递下来的name。    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;     Student student = new Student(&quot;xiaoxu&quot;);        System.out.println(student.name);//xiaoxu    &#125;&#125;","tags":["java基础"]},{"title":"java day10 冒泡排序","url":"/2021/07/17/java%20day10%20%E6%95%B0%E7%BB%84/","content":"01 冒泡排序冒泡排序：两层循环，外层冒泡轮数，里层依次比较。\npublic class Hello &#123;    public static void main(String[] args) &#123;        int[] a = &#123;1, 2, 3, 8, 11, 1, 55, 12&#125;;        int[] array = sort(a);        System.out.println(Arrays.toString(array));    &#125;    public static int[] sort(int[] array) &#123;        int temp = 0;        for (int i = 0; i &lt; array.length - 1; i++) &#123;            boolean flag = false;            for (int j = 0; j &lt; array.length - 1; j++) &#123;                if (array[j + 1] &lt; array[j]) &#123;                    temp = array[j + 1];                    array[j + 1] = array[j];                    array[j] = temp;                    flag = true;                &#125;            &#125;                if (flag == false) &#123;                    break;                &#125;        &#125;        return array;    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day13 面向对象三大特征1","url":"/2021/07/21/java%20day13%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A71/","content":"01 封装\n我们程序设计追求高内聚低耦合。\n高内聚：类的内部数据操作细节自己完成，不允许外部干涉。\n低耦合：仅暴露少量的方法给外部使用。\n\n\n封装的意义：\n提高程序的安全性，保护数据\n隐藏代码的实现细节\n统一接口\n系统可维护增加了\n\n\n属性私有，get&#x2F;set\n信息隐藏：禁止直接访问一个对象中数据的实际表示，而应通过操作接口来访问。\n\npublic class Student &#123;    //属性私有    private String name;//姓名    private int id;//学号    private char sex;//性别    //get 获得这个数据    public String getName()&#123;        return this.name;    &#125;    //set 给这个数据设置值    public void setName(String name)&#123;        this.name = name;    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.setName(&quot;小方&quot;);        System.out.println(student.getName());    &#125;&#125;\n\n02 继承\n继承的本质是对某一批类的抽象，从而实现对现实世界更好的建模。\nextends的意思是”扩展”。子类是父类的扩展。\nJAVA只有单继承，没有多继承。一个爸爸可以有多个儿子，一个儿子只能有一个爸爸。\n继承是类与类之间的一种关系\n\npublic class Person &#123;    public void say()&#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;public class Student extends Person &#123;&#125;public class Application &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.say();//hello    &#125;&#125;\n\n\n私有的东西无法被继承。\n在Java中，所有的类，都默认直接或者间接继承object\n\n03 Super\nsuper注意点：\n\nsuper调用父类的构造方法，必须在构造方法的第一个\nsuper必须只能出现在子类的方法或者构造方法中。\nsuper和this不能同时调用构造方法。\n\n\nsuper VS this\n\n代表的对象不同：this（本身调用这个对象），super（代表父类对象的引用）。\n前提：this（没有继承也可以使用），super（只有在继承条件下才可以使用）。\n构造方法：this():本类的构造，super():父类的构造\n\npublic class Person &#123;    public Person()&#123;        System.out.println(&quot;Person无参&quot;);    &#125;    protected String name = &quot;xiaofang&quot;;    public void print()&#123;        System.out.println(&quot;Person&quot;);    &#125;&#125;public class Student extends Person &#123;    //隐藏代码：调用父类的无参构造    public Student()&#123;        super();        System.out.println(&quot;Student无参&quot;);    &#125;    private String name = &quot;xiaoxu&quot;;    public void print()&#123;        System.out.println(&quot;student&quot;);    &#125;    public  void test(String name)&#123;        System.out.println(name);//方        System.out.println(this.name);//xiaoxu        System.out.println(super.name);//xiaofang    &#125;    public  void test1()&#123;        print();//student        this.print();//student        super.print();//Person    &#125;&#125;public class Application &#123;    public Application() &#123;    &#125;    public static void main(String[] args) &#123;        Student student = new Student();//先调用父类Person无参，在调用子类Student无参        student.test(&quot;方&quot;);        student.test1();    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day13 面向对象三大特征2","url":"/2021/07/28/java%20day13%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A72/","content":"01 方法重写\n重写：需要有继承关系，子类重写父类的方法！\n\n方法名必须相同\n参数列表必须相同\n修饰符：范围可以扩大但是不能缩小（public&gt;Protected&gt;Default&gt;private）\n抛出的异常：范围可以缩小但是不能扩大\n快捷键：Alt+Insert(override)\n\n\n为什么需要重写：因为父类的功能，子类不一定需要，或者不一定满足\n\n静态的方法和非静态方法差别很大：\n\n静态方法：方法的调用只和左边定义的数据类型有关\n\npublic class Person &#123;    public static void print()&#123;        System.out.println(&quot;Person&quot;);    &#125;&#125;public class Student extends Person &#123;    public static void print()&#123;        System.out.println(&quot;Student&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.print();//Student        //父类的引用指向了子类        Person person = new Student();        person.print();//Person    &#125;&#125;\n\n\n非静态方法：重写\n\n\n\npublic class Person &#123;    public void print()&#123;        System.out.println(&quot;Person&quot;);    &#125;&#125;public class Student extends Person &#123;    public void print()&#123;        System.out.println(&quot;Student&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        Student student = new Student();        student.print();//Student        //父类的引用指向了子类        Person person = new Student();        person.print();//Student    &#125;&#125;\n\n02 多态多态就是同一方法可以根据发送对象的不同而采用多种不同的行为方式。\n\n\n多态注意事项：\n\n多态时方法的多态，属性没有多态\n存在条件：继承关系，方法需要重写，父亲引用指向子类对象\n\n\n不能重写的方法：\n\nstatic方法属于类不属于实例\nfinal常量\nprivate方法\n\n\n\npublic class Person &#123;    public void print()&#123;        System.out.println(&quot;Person&quot;);    &#125;&#125;public class Student extends Person &#123;    public void print()&#123;        System.out.println(&quot;Student&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        //一个对象的实际类型是确定的--&gt;new Student(); new Person()        //可以指向的引用类型就不确定了：父类的引用指向子类        //Student能调用的方法都是自己的或者继承父类的        Student student = new Student();        student.print();//Student        //Person父类型可以指向子类，但是不能调用子类独有的方法        Person person = new Student();        person.print();//Student    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day14 面向对象","url":"/2021/07/29/java%20day14%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","content":"01 instanceof和类型转换\ninstanceof的格式是System.out.println(x instanceof y);如果x和y是同一类型或者能类型转换（兄弟之间不能类型转换，父子之间可以类型转换）则编译通过，否则不通过。编译通过后会把x和y比较，如果x是y本类或者子类的对象，结果就是true，反之就是flase。\n\npublic class Application &#123;    public static void main(String[] args) &#123;        //Object &gt; String        //Object &gt; Person &gt; Teacher        //Object &gt; Person &gt; Student        Object object = new Student();        System.out.println(object instanceof Object);//true        System.out.println(object instanceof Person);//true        System.out.println(object instanceof Teacher);//false        System.out.println(object instanceof Student);//true        System.out.println(object instanceof String);//false        System.out.println(&quot;=========================&quot;);        Person person = new Student();        System.out.println(person instanceof Object);//true        System.out.println(person instanceof Person);//true        System.out.println(person instanceof Teacher);//false        System.out.println(person instanceof Student);//true        //System.out.println(person instanceof String);编译不通过        System.out.println(&quot;=========================&quot;);        Student student = new Student();        System.out.println(student instanceof Object);//true        System.out.println(student instanceof Person);//true        //System.out.println(student instanceof Teacher);编译不通过        System.out.println(student instanceof Student);//true        //System.out.println(student instanceof String);编译不通过        System.out.println(&quot;=========================&quot;);    &#125;&#125;\n\n\n类型转换：\n把子类转换成父类，向上转型\n把父类转换成子类，向下转型：强制转换\n\n\n\npublic class Student extends Person &#123;    public void go()&#123;        System.out.println(&quot;Student&quot;);    &#125;&#125;public class Application &#123;    public static void main(String[] args) &#123;        //高转低        Person obj = new Student();        //方法一        Student student = (Student) obj;        student.go();//Student        //方法二        ((Student) obj).go();//Student        //低转高可能丢失一些自己本来的方法        Student student = new Student();        Person person = student;       //person.go();报错！    &#125;&#125;\n\n02 static关键字详解\n对于代码块来说：\n\npublic class Person &#123;    &#123;        System.out.println(&quot;匿名代码块&quot;);    &#125;    static &#123;        System.out.println(&quot;静态代码块&quot;);//只执行一次    &#125;    public Person()&#123;        System.out.println(&quot;构造方法&quot;);    &#125;    public static void main(String[] args) &#123;        Person p1 = new Person();        System.out.println(&quot;==========&quot;);        Person p2 = new Person();    &#125;&#125;                                /*静态代码块                                匿名代码块                                构造方法                                ==========                                匿名代码块                                构造方法*/\n\n\n非静态方法和静态方法可以调用静态方法，而静态方法不能调用非静态方法。\n静态导入包：\n\n//静态导入包import static java.lang.Math.random;public class Person &#123;    public static void main(String[] args) &#123;        System.out.println(random());//这就可以直接使用random()，而不用Math.random()    &#125;&#125;\n\n\n调用非静态方法必须new一个对象进行调用，而调用静态方法可以直接用类调用，比如Student.run()。\n在方法中调用变量：调用非静态变量不能直接用类调用，要创建一个对象进行调用，而调用静态变量既可以用类进行调用，也可以用对象进行调用。\n\n03 抽象类\nabstract修饰符，如果修饰方法就是抽象方法，如果修饰类就是抽象类。\n抽象类中可以没有抽象方法，但是只要有抽象方法，必须声明抽象类。\n抽象类不能用new实例化。\n抽象方法只有方法的声明而没有具体实现，实现是让子类来完成的。\n子类继承抽象类，就必须实现抽象类中没有实现的抽象方法，否则子类也要声明为抽象类。\n\npublic abstract class Application &#123;   public abstract void run();   public void go()&#123;       System.out.println(&quot;有普通方法也是可以的&quot;);   &#125;&#125;\n\n04 接口\n接口的本质是契约，是对对象的抽象\n用interface定义接口\n接口的作用：\n约束\n定义一些方法，让不同的人实现（10个人可以实现一个接口）\n接口中的所有定义的方法其实都是抽象的 public abstract\n接口中的所有定义的变量其实都是静态常量 public static final\n接口也不能被实例化（没有构造方法）\nimplements可以实现多个接口，就是相当于多继承\n实现接口，必须要做重写接口中方法\n\n\n\npublic interface Person &#123;    void add(String name);    void delete(String name);    void update(String name);    void query(String name);&#125;public interface Teacher  &#123;    void run();&#125;//Ait+insert直接生成的重写方法public class Student implements Person,Teacher &#123;    @Override    public void add(String name) &#123;    &#125;    @Override    public void delete(String name) &#123;    &#125;    @Override    public void update(String name) &#123;    &#125;    @Override    public void query(String name) &#123;    &#125;    @Override    public void run() &#123;    &#125;&#125;\n\n","tags":["java基础"]},{"title":"java day15 异常","url":"/2021/07/30/java%20day15%E5%BC%82%E5%B8%B8/","content":"01 Error和Exception\n异常是指程序运行时出现的不期而至的各种状况，如：文件找不到、网络连接失败、非法参数。\n三种类型的异常：\n检查性异常：是用户错误或问题引起的异常，这时程序员无法遇见的。比如打开一个不存在的文件。\n运行时异常：是可能被程序员避免的异常。\n错误：错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如堆栈溢出，在编译时也检测不到。\n\n\nJava把异常当作对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。\n这些异常通常分为两大类：错误Error和异常Exception\n在Exception分支中有一个重要的子类RuntimeException（运行时异常）：\nArrayIndexOutOfBoundsException（数组下标越界）\nNullPointerException（空指针异常）\nArithmeticException（算数异常）\nMissingResourceException（丢失资源）\nClassNotFoundException（找不到类）\n\n\n\n02 捕获和抛出异常\n异常处理五个关键字：try、catch、finally、throw、throws\n\n//方法一public abstract class Application &#123;    public static void main(String[] args) &#123;        int a = 1;        int b = 0;        //假设要捕获多个异常：从小到大        try&#123;//try监控区域            System.out.println(a/b);        &#125;catch(Error e)&#123;            System.out.println(&quot;Error&quot;);        &#125;catch(Exception e)&#123;            System.out.println(&quot;Exception&quot;);        &#125;catch (Throwable t)&#123;            System.out.println(&quot;Throwable&quot;);        &#125;finally &#123;//处理善后工作            System.out.println(&quot;finally&quot;);        &#125;    &#125;&#125;//打印出Exception和finally//方法二public abstract class Application &#123;    public static void main(String[] args) &#123;        int a = 1;        int b = 0;        //通过Ctrl+Alt+t快捷键来完成        try &#123;            System.out.println(a/b);        &#125; catch (Exception e) &#123;            e.printStackTrace();//打印错误的栈信息        &#125; finally &#123;        &#125;    &#125;&#125;//打印出ava.lang.ArithmeticException: / by zero//方法三public  class Application &#123;    public static void main(String[] args) &#123;        new Application().test(1,0);    &#125;    public void test(int a, int b)&#123;        if(b==0)&#123;            throw new ArithmeticException();//主动抛出异常        &#125;    &#125;&#125;//打印出Exception in thread &quot;main&quot; java.lang.ArithmeticException//方法四public  class Application &#123;    public static void main(String[] args) &#123;        try &#123;            new Application().test(1,0);        &#125; catch (ArithmeticException e) &#123;            e.printStackTrace();        &#125;    &#125;    //假设方法处理不了这个异常。那么就将其向上抛出，在方法上抛出。    public void test(int a, int b)throws ArithmeticException&#123;        if(b==0)&#123;            throw new ArithmeticException();//主动抛出异常        &#125;    &#125;&#125;//输出java.lang.ArithmeticException\n\n03 自定义异常\n自定义异常类，大体可以分为以下几个步骤：\n创建自定义异常类\n在方法中通过throw关键字抛出异常对象\n如果在当前抛出异常的方法中处理异常，可以使用try-catch语句捕获并处理；否则在方法的声明处通过throws关键字指明要抛出给方法调用者的异常，继续进行下一步操作\n在出现异常方法的调用者中捕获并处理异常\n\n\n\npublic class MyException extends Exception&#123;    //传递数字&gt;10    private  int detail;    public MyException(int a) &#123;        this.detail = a;    &#125;    //toString:异常的打印信息    @Override    public String toString() &#123;        return &quot;MyException&#123;&quot; + &quot;detail=&quot; + detail + &#x27;&#125;&#x27;;    &#125;&#125;public  class Application &#123;    public static void main(String[] args) &#123;        try &#123;            new Application().test(11);        &#125; catch (MyException e) &#123;            System.out.println(&quot;MyException=&gt;&quot;+e);        &#125;    &#125;    //假设方法处理不了这个异常。那么就将其向上抛出，在方法上抛出。    public void test(int a)throws MyException&#123;        System.out.println(&quot;传递的参数为：&quot;+a);        if(a&gt;10)&#123;            throw new MyException(a);//主动抛出异常        &#125;        System.out.println(&quot;OK&quot;);    &#125;&#125;\n\n\n在实际应用中的经验：\n处理运行时异常时，采用逻辑去合理规避同时辅助try-catch处理\n在多重catch块后面，可以加一个catch(Exception)来处理可能会被遗漏的异常\n对于不确定的代码，也可以加上try-catch，处理潜在的异常（当在IDEA中出现红色波浪线可以Alt+Enter）\n尽量去处理异常，不要只是简单的调用printStackTrace()去打印输出\n尽量添加finally语句块去释放占用资源\n\n\n\n","tags":["java基础"]},{"title":"1编程作业：线性回归","url":"/2021/08/06/1%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","content":"原任务是在Octave&#x2F;MATLAB实现，本次编程作业全部以python完成。\n\n01 简单的练习总结下题目：输出一个5*5的单位矩阵\n\n\n在此我们用np.eye(N,M&#x3D;None, k&#x3D;0, dtype&#x3D;&lt;type ‘float’&gt;)，首先N代表的是输出方阵的维度，第二个参数不用设置默认M&#x3D;N，主要看第三个参数，默认是对角线为1，其余全为0；如果k为正数，则对角线往上第k个全为1，其余全为0；如果k为负数，则对角线往下第k个全为1，其余全为0。\n\nimport numpy as npA = np.eye(5)print(A)&quot;&quot;&quot;[[1. 0. 0. 0. 0.] [0. 1. 0. 0. 0.] [0. 0. 1. 0. 0.] [0. 0. 0. 1. 0.] [0. 0. 0. 0. 1.]]&quot;&quot;&quot;\n\n02 单变量线性回归根据这座城市的人口数量及该城市小吃店的利润，来预测开小吃店的利润。\n\n2.1 绘制数据\n读入数据：在此我们引入pandas库，该库可以帮助我们从诸如 csv 类型的文件导入数据，并且可以用它快速的对数据进行转换和过滤的操作。\n\nimport pandas as pdpath = &quot;machine-learning-ex1\\machine-learning-ex1\\ex1\\ex1data1.txt&quot;data = pd.read_csv(path,header=None,names=[&#x27;Population&#x27;,&#x27;Profit&#x27;])#header决定要不要原始的表头，name给出自定义的表头。print(data.head())#从头查询数据&quot;&quot;&quot;   population   profit0      6.1101  17.59201      5.5277   9.13022      8.5186  13.66203      7.0032  11.85404      5.8598   6.8233&quot;&quot;&quot;\n\n\n数据可视化：在此我们引入matplotlib.pyplot库，使用plot函数画图。\n\nimport matplotlib.pyplot as pltdata.plot(kind=&#x27;scatter&#x27;, x=&#x27;Population&#x27;, y=&#x27;Profit&#x27;, figsize=(12,8))#生成图形，kind‘指定所画图的类型，figsize 指定图片大小。plt.show()#显示图形\n\n\n2.2 梯度下降这部分需要使用梯度下降将线性回归参数 θ 拟合到数据集上。\n2.21 公式\n代价函数\n\n\n\n假设函数\n\n\n\n参数更新\n\n\n\n随着梯度下降不断地更新参数，参数也就越接近使代价函数最小的最优值\n\n2.22 实现\n我们要为我们之前读取的数据添加一列x，用来更新θ_0。\n\ndata.insert(0, &#x27;Ones&#x27;, 1) #相当于在第0列，添加一个表头名为Ones，并且该列均为1print(data.head())&quot;&quot;&quot;   Ones  Population   Profit0     1      6.1101  17.59201     1      5.5277   9.13022     1      8.5186  13.66203     1      7.0032  11.85404     1      5.8598   6.8233&quot;&quot;&quot;\n\n\n分割X和y。使用pandas的iloc来进行选择训练集X和目标y\n\n# 分割X和ylists = data.shape[1]#输出列数X = data.iloc[:,:-1]#X是第一列到最后一列，但不包括最后一列，因为 python的范围/切片不包括终点y = data.iloc[:,lists-1:lists]#最后一列#y = data.iloc[:,-1]#也是最后一列print(X.head())&quot;&quot;&quot;   Ones  Population0     1      6.11011     1      5.52772     1      8.51863     1      7.00324     1      5.8598&quot;&quot;&quot;print(y.head())&quot;&quot;&quot;    Profit0  17.59201   9.13022  13.66203  11.85404   6.8233&quot;&quot;&quot;\n\n\n我们还要将θ初始化为0，并将θ、X、y全部转化为矩阵\n\nX = np.matrix(X.values)y = np.matrix(y.values)theta = np.matrix(np.array([0,0]))print(X.shape)#(97, 2)print(y.shape)#(97, 1)print(theta.shape)#(1, 2)\n\n2.23 计算J(θ)\n计算代价函数来检测代价函数的收敛性。根据上面的公式我们写出代价函数。\n\ndef computeCost(X, y, theta):    inner = np.power((X * theta.T)-y,2)#数组元素求n次方    return np.sum(inner) / (2 * len(X))print(computeCost(X, y, theta)) #32.072733877455676\n\n2.24 梯度下降代价函数J(θ)的参数是由向量θ表示，假设你已经实现了梯度下降，如果计算正确，J(θ)的值不应该增加，而应该减小然后在算法结束时收敛到一个稳定值。\ndef gradientDescent(X, y, theta, alpha, iters):    temp = np.matrix(np.zeros(theta.shape))#创建0矩阵[[0. 0.]]    parameters = int(theta.ravel().shape[1]) #ravel()将多维数组转换为一维数组,.shape[1]是看列数为多少-2    cost = np.zeros(iters)#初始化代价函数数组    for i in range(iters):        error = (X * theta.T) - y        for j in range(parameters):            term = np.multiply(error, X[:, j])            temp[0, j] = theta[0, j] - ((alpha / len(X)) * np.sum(term))#更新参数        theta = temp        cost[i] = computeCost(X, y, theta)    return theta, costalpha = 0.01iters = 1500g, cost = gradientDescent(X, y, theta, alpha, iters)print(g)#[[-3.63029144  1.16636235]]predict1 = [1,3.5]*g.Tprint(predict1)#[[0.45197679]]predict2 = [1,7]*g.Tprint(predict2)#[[4.53424501]]\n\n2.3 调试\npython可视化：原始数据以及拟合的直线\n\n# 在指定的间隔内返回均匀间隔的数字：从data.Population的最小值到最大的范围内，等间距的返回100个样本x = np.linspace(data.Population.min(), data.Population.max(), 100)f = g[0, 0] + (g[0, 1] * x)#参数为最优值的直线fig, ax = plt.subplots(figsize=(12,8))#创建一个12*8的图即多维窗口ax.plot(x, f, &#x27;r&#x27;, label=&#x27;Prediction&#x27;) #定义x, y, 颜色，图例上显示的东西ax.scatter(data.Population, data.Profit, label=&#x27;Traning Data&#x27;)ax.legend(loc=2)#指定图例的位置ax.set_xlabel(&#x27;Population&#x27;)ax.set_ylabel(&#x27;Profit&#x27;)ax.set_title(&#x27;Predicted Profit vs. Population Size&#x27;)plt.show()\n\n\n03 多变量线性回归根据ex1data2.txt里的数据建立模型，预测房屋的价格，其中第一列是房屋大小，第二列是卧室数量，第三列是房屋售价\n\n\n第一步依旧是读入数据：\n\npath = &#x27;machine-learning-ex1\\machine-learning-ex1\\ex1\\ex1data2.txt&#x27;data2 = pd.read_csv(path,header = None,names=[&#x27;Size&#x27;, &#x27;Bedrooms&#x27;, &#x27;Price&#x27;])print(data2.head())&#x27;&#x27;&#x27; Size  Bedrooms   Price0  2104         3  3999001  1600         3  3299002  2400         3  3690003  1416         2  2320004  3000         4  539900&#x27;&#x27;&#x27;\n\n3.1 特征归一化特征缩放的目的只是为了运行更快。使特征值比较接近，使图像变得比较圆。以至于梯度下降的速度更快，收敛所需要的迭代次数更少，收敛更快。\n\n\nmean()函数功能：求取均值，std()函数是用来求标准差的（std &#x3D; sqrt(mean(abs(x - x.mean())**2))）。\n\ndata2 = (data2 - data2.mean()) / data2.std()print(data2.head())&#x27;&#x27;&#x27;      Size  Bedrooms     Price0  0.130010 -0.223675  0.4757471 -0.504190 -0.223675 -0.0840742  0.502476 -0.223675  0.2286263 -0.735723 -1.537767 -0.8670254  1.257476  1.090417  1.595389&#x27;&#x27;&#x27;\n\n3.2 梯度下降data2.insert(0, &#x27;Ones&#x27;, 1)cols = data2.shape[1]X2 = data2.iloc[:,0:cols-1]y2 = data2.iloc[:,cols-1:cols]X2 = np.matrix(X2.values)y2 = np.matrix(y2.values)theta2 = np.matrix(np.array([0,0,0]))g2, cost2 = gradientDescent(X2, y2, theta2, alpha, iters)print(g2)&#x27;&#x27;&#x27;[[-1.10898288e-16  8.84042349e-01 -5.24551809e-02]]&#x27;&#x27;&#x27;\n\n3.3 正规方程训练集特征矩阵为 X（包含了x_0&#x3D;1）训练集结果为向量 y，则利用正规方程解出向量:其中np.linalg.inv()：矩阵求逆。\n\ndef normalEqn(X, y):    theta = ((np.linalg.inv(X.T.dot(X))).dot(X.T)).dot(y)    # theta = np.linalg.inv(X.T@X)@X.T@y    return thetatheta2=normalEqn(X2, y2)print(theta2)&#x27;&#x27;&#x27;[[-7.11223170e-17] [ 8.84765988e-01] [-5.31788197e-02]] &#x27;&#x27;&#x27;\n\n04 代码总结import matplotlib.pyplot as pltimport numpy as npimport pandas as pdpath = &quot;machine-learning-ex1\\machine-learning-ex1\\ex1\\ex1data1.txt&quot;data = pd.read_csv(path,header=None,names=[&#x27;Population&#x27;,&#x27;Profit&#x27;])#header决定要不要原始的表头，name给出自定义的表头。#data.plot(kind=&#x27;scatter&#x27;, x=&#x27;Population&#x27;, y=&#x27;Profit&#x27;, figsize=(12,8))#生成图形，kind‘指定所画图的类型，figsize 指定图片大小。# plt.show()#显示图形#==============================================================================data.insert(0, &#x27;Ones&#x27;, 1) #相当于在第0列，添加一个表头名为Ones，并且该列均为1# 分割X和ylists = data.shape[1]#输出列数X = data.iloc[:,:-1]#X是第一列到最后一列，但不包括最后一列，因为 python的范围/切片不包括终点y = data.iloc[:,lists-1:lists]#最后一列#y = data.iloc[:,-1]#也是最后一列X = np.matrix(X.values)y = np.matrix(y.values)theta = np.matrix(np.array([0,0]))def computeCost(X, y, theta):    inner = np.power((X * theta.T)-y,2)#数组元素求n次方    return np.sum(inner) / (2 * len(X))# print(computeCost(X, y, theta)) #32.072733877455676#梯度下降算法如下：def gradientDescent(X, y, theta, alpha, iters):    temp = np.matrix(np.zeros(theta.shape))#创建0矩阵[[0. 0.]]    parameters = int(theta.ravel().shape[1]) #ravel()将多维数组转换为一维数组,.shape[1]是看列数为多少    cost = np.zeros(iters)    for i in range(iters):        error = (X * theta.T) - y        for j in range(parameters):            term = np.multiply(error, X[:, j])            temp[0, j] = theta[0, j] - ((alpha / len(X)) * np.sum(term))        theta = temp        cost[i] = computeCost(X, y, theta)    return theta, costalpha = 0.01iters = 1500g, cost = gradientDescent(X, y, theta, alpha, iters)#print(g)#[[-3.63029144  1.16636235]]predict1 = [1,3.5]*g.T#print(predict1)#[[0.45197679]]predict2 = [1,7]*g.T#print(predict2)#[[4.53424501]]# 在指定的间隔内返回均匀间隔的数字：从data.Population的最小值到最大的范围内，等间距的返回100个样本x = np.linspace(data.Population.min(), data.Population.max(), 100)f = g[0, 0] + (g[0, 1] * x)#参数为最优值的直线fig, ax = plt.subplots(figsize=(12,8))#创建一个12*8的图即多维窗口ax.plot(x, f, &#x27;r&#x27;, label=&#x27;Prediction&#x27;) #定义x, y, 颜色，图例上显示的东西ax.scatter(data.Population, data.Profit, label=&#x27;Traning Data&#x27;)ax.legend(loc=2)#指定图例的位置ax.set_xlabel(&#x27;Population&#x27;)ax.set_ylabel(&#x27;Profit&#x27;)ax.set_title(&#x27;Predicted Profit vs. Population Size&#x27;)#plt.show()#===========================================================================path = &#x27;machine-learning-ex1\\machine-learning-ex1\\ex1\\ex1data2.txt&#x27;data2 = pd.read_csv(path,header = None,names=[&#x27;Size&#x27;, &#x27;Bedrooms&#x27;, &#x27;Price&#x27;])data2 = (data2 - data2.mean()) / data2.std()data2.insert(0, &#x27;Ones&#x27;, 1)cols = data2.shape[1]X2 = data2.iloc[:,0:cols-1]y2 = data2.iloc[:,cols-1:cols]X2 = np.matrix(X2.values)y2 = np.matrix(y2.values)theta2 = np.matrix(np.array([0,0,0]))g2, cost2 = gradientDescent(X2, y2, theta2, alpha, iters)print(g2)def normalEqn(X, y):    theta = ((np.linalg.inv(X.T.dot(X))).dot(X.T)).dot(y)    # theta = np.linalg.inv(X.T@X)@X.T@y    return thetatheta2=normalEqn(X2, y2)print(theta2)\n","tags":["机器学习"]},{"title":"机器学习 day01初识机器学习","url":"/2021/07/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day01%E5%88%9D%E8%AF%86%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","content":"01 监督学习\n监督学习是指我们给算法一个数据集，其中包含了正确的答案。算法的目的就是给出更多的正确答案。\n回归是指我们设法预测连续值的属性，可以应用在预测房子价格等方面。\n分类是指我们设法预测离散值的输出(0或1)，可以应用在判断账户是否被入侵等方面。\n\n02 无监督学习\n无监督学习也会给一个数据集，但是数据集不包括正确答案(里面的数据要么都有相同的标签要么都没有标签)。无监督学习会将数据分为一个个不同的簇，这就是聚类算法。\n聚类算法可以应用在|搜集新闻并将相关新闻组合在一起|星系形成理论|市场销售等领域\n\n\n建议使用Octave免费开源的软件，许多学习算法都可以用几行代码将其实现。例如svd函数(奇异值分解)已经作为线性代数常规函数内置在Octave中了。\n","tags":["机器学习"]},{"title":"机器学习 day02单变量线性回归","url":"/2021/07/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day02%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","content":"01 模型描述为了更好的描述监督学习问题，需要给出训练集并以此构建一个模型。\n\n下面先学习几个符号：\n\nm:代表的是训练集有几个\nx:代表的是输入的特征\ny:代表的是输出，也就是预测的目标变量\nh:代表假设函数，引导从x得到y的函数\n\n02 代价函数（平方误差函数）\n可以通过代价函数来衡量假设函数的准确性。\n\n代价函数取值越小，假设函数就越准确。\n\n\n\n\n代价函数有助于我们弄清楚如何把最有可能的直线与我们的数据相拟合。\n\n在线性回归中，我们要解决的是最小化问题\n\n代价函数是解决回归问题最常用的手段\n\n\n\n03 梯度下降梯度下降法：可以将代价函数最小化\n\n一般将两个参数初始化为0，再不断的改变参数的值，使得代价函数取值达到最小。\n\n\na：代表学习率（永远为正），用来控制使用梯度下降时，迈出步子的大小。下面是a太小与太大的情况。\n\n\n\n导数的含义：针对于只有一个参数的，两种不同初始点的情况分析。\n\n\n\n事实上，当取值越接近最优解时，梯度下降的幅度也就越小，因为导数始终向0靠拢。\n\n\n04 线性回归的梯度下降\n将代价函数带入梯度下降算法，并求偏导数可得：\n\n\n\n将所求的偏导数带回梯度下降算法\n\n\n\n通过梯度下降算法，一步步的进行，最终可以得到与数据最拟合的直线\n\n\n","tags":["机器学习"]},{"title":"机器学习 day03线性代数基础","url":"/2021/07/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day03%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/","content":"01 矩阵与向量\n小写字母表示向量：a b c\n大写字母表示矩阵：A B C\n\n02 加法和标量乘法\n只有维度相同的矩阵才能相加\n一个数乘一个矩阵与一个矩阵乘一个数的结果相同\n\n\n03 矩阵向量乘法\n矩阵与向量相乘\n\n\n\n例子：\n\n\n\n将一个方程转化为矩阵向量相乘的形式\n\n\n04 矩阵相乘\n矩阵相乘计算原理：只需将第二个矩阵的每一列提取出来，计算矩阵与向量相乘，最终将其拼接成为最终答案。\n\n\n\n将三个方程转化为两个矩阵相乘的形式\n\n\n05 矩阵乘法特性\n不能使用乘法交换律（单位矩阵除外），会改变结果的维度及数值\n\n\n\n矩阵与实数一样，都符合乘法结合律\n\n\n06 逆和转置\n只有方阵才有逆矩阵\n\n\n\n矩阵的转置：将A的第一行变成A的转置的第一列，将A的第二行变成A的转置的第二列。。。。。。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day04多变量线性回归","url":"/2021/07/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day04%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","content":"01 多元线性回归–多特征向量情况下的假设形式\n一些符号表示：\n\n\n\n简化下面等式的表达方法：向量内积转化\n\n\n02 多元梯度下降算法\n多元线性回归方程+代价函数+梯度下降函数\n\n\n\n单元及多元线性回归的梯度下降法对比\n\n\n03 多元梯度下降法–特征缩放\n特征缩放的目的只是为了运行更快。使特征值比较接近，使图像变得比较圆。以至于梯度下降的速度更快，收敛所需要的迭代次数更少，收敛更快。缩放前后对比图如下：\n\n\n\n特征值的取值别太大也别太小，与下面这个范围足够接近最好。\n\n\n\n均值归一化的工作：X &#x3D;（当前值-平均值）&#x2F;【（最大值-最小值）只要是这个范围左右就可以】\n\n\n04 多元梯度下降法–学习率\n梯度算法正常工作图如下：代价函数随迭代次数的变化，最终收敛。\n\n\n\n如果所得图像不是一直减小的，那么需要减小学习率，当然学习率也不能过小，否则梯度下降将会十分缓慢，迭代次数无限增加。\n\n\n\n得到一个不错的学习率：按照三的倍数来取值，尝试一系列的学习率，找到个太小的值，再找到另一个太大的值，然后取太大的值，或者比太大的值略小的比较合理的值\n\n\n05 特征和多项式回归\n特征可以根据自己的需求选择合适的特征，例如将两个不同的特征相乘得到一个新的特征\n如果只用多次函数，适当使用特征缩放将起到很好的效果：\n\n\n\n可以有多种合理的选择，比如也可以是平方根。\n\n\n06 正规方程–区别于迭代方法的直接解法\n正规方程：对代价函数求偏导数，并将其置0，就可以得到使代价函数最小的值。\n\n\n\n方程的形式及例子：\n\n\n\n使用正规方程就不用对特征进行缩放了。\n\n选择合适的算法（梯度下降还是正规方程）一般特征&lt;10000时选用正规方程直接求解，他们二者的优缺点：\n\n\n\n07 正规方程在矩阵不可逆情况下的解决方法\n在Octave中pinv（伪逆）与inv（逆）是求逆矩阵的，就算矩阵没有逆，pinv也会求出它的逆。\n\n首先看是否有多余的特征（两个特征线性相关），选择进行删除，直到没有多余的为止；再观察是否特征过多，选择没有影响的特征进行删除。\n\n\n\n","tags":["机器学习"]},{"title":"机器学习 day05Octave教程","url":"/2021/07/12/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day05Octave%E6%95%99%E7%A8%8B/","content":"01 基本操作\n注释表达：%\n&gt;&gt; 1~= 2 %注释ans = 1\n\n\n\n不等号表达：~&#x3D;\n&gt;&gt; 1~= 2ans = 1\n\n\n\n隐藏提示命令：PS1(‘&gt;&gt; ‘);\noctave:6&gt; PS1(&#x27;&gt;&gt; &#x27;);&gt;&gt;\n\n\n\n想分配一个变量，但是不想在屏幕上显示结果：只需在结尾加分号（;）\n&gt;&gt; a = pi;&gt;&gt; a = pia = 3.1416\n\n\n\n显示命令：disp( );\n&gt;&gt; disp(a);3.1416\n\n用disp( );显示字符串\n&gt;&gt; disp(sprintf(&#x27;2 decimals:%0.2f&#x27;,a)) %0.2f:小数点后两位2 decimals:3.14\n\n显示更多的小数点后几位：format long\n&gt;&gt; format long&gt;&gt; aa = 3.141592653589793\n\n\n\n显示少量的小数点后几位：format short\n&gt;&gt; format short&gt;&gt; aa = 3.1416\n\n\n\n建立一个矩阵：\n\n\n&gt;&gt; A = [1 2;3 4;5 6]A =   1   2   3   4   5   6&gt;&gt; A = [1 2;&gt; 3 4;&gt; 5 6]A =   1   2   3   4   5   6\n\n\n\n\n建立向量：\n\n&gt;&gt; v = [1 2 3] %行向量v =   1   2   3&gt;&gt; v = [1; 2; 3] %列向量v =   1   2   3&gt;&gt; v = 1:0.1:2 %从1开始每次增加0.1到2的行向量v =    1.0000    1.1000    1.2000    1.3000    1.4000    1.5000    1.6000    1.7000    1.8000    1.9000    2.0000&gt;&gt; V = 1:6 %从1到6的整数V =   1   2   3   4   5   6\n\n\n生成单位矩阵\n\n&gt;&gt; ones(2,3) %2×3的ans =   1   1   1   1   1   1\n\n\n生成零矩阵\n\n&lt;&lt; zeros(2,3)ans =   0   0   0   0   0   0\n\n\n随机生成0到1的值\n\n&lt;&lt; rand(3,3)ans =   0.914686   0.131127   0.563647   0.296402   0.590713   0.134373   0.243013   0.477658   0.071331\n\n\n生成服从高斯分布的随机数：均值为0，标准差或者方差为1\n\n&lt;&lt;  w = randn(1,3)w =  -0.1177   2.0111   0.7261\n\n\n绘制直方图：hist( ):均值为-6，方差为10，标准差为根号10\n\n\n\n生成单位矩阵：eye( )\n\n&lt;&lt; eye(4)ans =Diagonal Matrix   1   0   0   0   0   1   0   0   0   0   1   0   0   0   0   1\n\n\n显示帮助：help eye;help help;按q退出\n\n显示矩阵大小:size( )\n\n\n&lt;&lt; A = [1 2; 3 4; 5 6]A =   1   2   3   4   5   6&lt;&lt; size(A)ans =   3   2&lt;&lt; size(A,1) %显示行数ans = 3&lt;&lt; size(A,2) %显示列数ans = 2\n\n\n返回最大维度大小：length( )|一般对向量使\n\n&lt;&lt; length(A)ans = 3 %3×2，最大维度为3&lt;&lt; length([1;2;3;4;5])ans = 5\n\n02 移动数据\n显示当前在内存中存储的所有变量：who\nwhos显示更加完善的信息\n\n&lt;&lt; whoVariables visible from the current scope:A    ans&lt;&lt; whosVariables visible from the current scope:variables in scope: top scope   Attr Name        Size                     Bytes  Class   ==== ====        ====                     =====  =====        A           3x2                         48  double        ans         1x10                        10  charTotal is 16 elements using 58 bytes\n\n\n载入文件格式：load+文件；load(‘文件’)\n删除某个变量：clear+变量\n存储数据到硬盘中：save+存储文件名+数据\n在找矩阵某一个元素时，：表示这一行或者这一列的元素\n\n&lt;&lt; A(2,1)ans = 3&lt;&lt; A(2,:)ans =   3   4&lt;&lt; A(:,2)ans =   2   4   6\n\n\n索引操作：同时取得1、3行所有元素\n\n&lt;&lt; A([1 3],:)ans =   1   2   5   6\n\n\n将第二列用其他元素代替\n\n&lt;&lt; A(:,2) = [10; 11; 12]A =    1   10    3   11    5   12    \n\n\n在A的右侧附加一列\n\n&lt;&lt; A = [A,[100; 200; 300]]A =     1    10   100     3    11   200     5    12   300\n\n\n把A所有元素放在单独的一列\n\n&lt;&lt; A(:)ans =     1     3     5    10    11    12   100   200   300\n\n\n将两个矩阵结合在一起\n\n&lt;&lt; A = [1 2; 3 4; 5 6]A =   1   2   3   4   5   6&lt;&lt;  B = [11 12; 13 14; 15 16]B =   11   12   13   14   15   16&lt;&lt; C = [A B] %左右结合C =    1    2   11   12    3    4   13   14    5    6   15   16&lt;&lt; C = [A;B] %上下结合C =    1    2    3    4    5    6   11   12   13   14   15   16\n\n03 计算数据\n两个矩阵相乘\n\n&lt;&lt; A = [1 2; 3 4; 5 6]A =   1   2   3   4   5   6&lt;&lt;  B = [11 12; 13 14; 15 16]B =   11   12   13   14   15   16&lt;&lt; C = [1 1;2 2]C =   1   1   2   2&lt;&lt; A*Cans =    5    5   11   11   17   17\n\n\n两个矩阵对应数相乘\n\n&lt;&lt; A.*Bans =   11   24   39   56   75   96\n\n\nA的每个元素进行乘方\n\n&lt;&lt; A.^2ans =    1    4    9   16   25   36\n\n\n求V对应元素的倒数\n\n&lt;&lt; V = [1; 2; 3]V =   1   2   3&lt;&lt; 1 ./Vans =   1.0000   0.5000   0.3333\n\n\n以e为底，v中元素为指数的幂运算\n\n&lt;&lt; exp(V)ans =    2.7183    7.3891   20.0855\n\n\n求绝对值：abs( )\n求相反数直接加-；例如-V\n将V中每个元素+1\n\n&lt;&lt; V + ones(length(V),1) %与V +1等价ans =   2   3   4\n\n\n求A的转置\n\n&lt;&lt; A&#x27;ans =   1   3   5   2   4   6\n\n\n求X最大的数及其索引\n\n&lt;&lt; X = [1 15 2 0.5]X =    1.0000   15.0000    2.0000    0.5000&lt;&lt; val = max(X)val = 15&lt;&lt; [val,ind] = max(X)val = 15ind = 2%如果A是矩阵，那么将求出每一列最大值&lt;&lt; max(A)ans =   5   6\n\n\nX中每个元素与3比较，根据结果返回真和假\n\n&lt;&lt; X&lt;3ans =  1  0  1  1\n\n\n找到比3小的数并返回其索引\n\n&lt;&lt; find(X&lt;3)ans =   1   3   4\n\n\n生成一个幻方矩阵，每行、每列、每个对角线加起来都等于一个数\n\n&lt;&lt; B = magic(3)B =   8   1   6   3   5   7   4   9   2\n\n\n找出B中&gt;&#x3D;7的元素，并返回下标\n\n&lt;&lt; [r,c] = find(B &gt;=7)r =   1   3   2c =   1   2   3\n\n\nX中所有元素相加\n\n&lt;&lt; sum(X)ans = 18.500\n\n\nX中所有元素相乘\n\n&lt;&lt; prod(X)ans = 15\n\n\n对X中元素向下取整\n\n&lt;&lt; floor(X)ans =    1   15    2    0\n\n\n对X中元素向上取整\n\n&lt;&lt; ceil(X)ans =    1   15    2    1\n\n\n取两个随机矩阵中较大的数组合成一个较大值的矩阵\n\n&lt;&lt;  max(rand(3),rand(3))ans =   0.6957   0.9634   0.7179   0.8404   0.9784   0.8319   0.5236   0.8063   0.6697\n\n\n取每一列&#x2F;行最大值\n\n&lt;&lt; max(B,[],1)ans =   8   9   7&lt;&lt; max(B,[],2)ans =   8   7   9\n\n\n求每一行、每一列、对角线相加\n\n&lt;&lt; C = magic(9)C =   47   58   69   80    1   12   23   34   45   57   68   79    9   11   22   33   44   46   67   78    8   10   21   32   43   54   56   77    7   18   20   31   42   53   55   66    6   17   19   30   41   52   63   65   76   16   27   29   40   51   62   64   75    5   26   28   39   50   61   72   74    4   15   36   38   49   60   71   73    3   14   25   37   48   59   70   81    2   13   24   35&lt;&lt; sum(C,2)ans =   369   369   369   369   369   369   369   369   369&lt;&lt; sum(C,1)ans =   369   369   369   369   369   369   369   369   369&lt;&lt; sum(sum(C.*eye(9))) %正对角线相加ans = 369&lt;&lt; sum(sum(C.*flipud(eye(9)))) %副对角线相加，flipud表示使矩阵垂直翻转ans = 369\n\n04 数据绘制\n绘制一个正弦函数图像：plot( );\n\n&lt;&lt; t = [0:0.01:0.98];&lt;&lt; y1 = sin(2*pi*4*t);&lt;&lt; plot(t,y1);\n\n\n\n绘制一个余弦函数图像：plot( );\n\n&lt;&lt; y2 = cos(2*pi*4*t);&lt;&lt; plot(t,y2);\n\n\n\n在旧的图像上面绘制新的图像：hold on;\n\n&lt;&lt; t = [0:0.01:0.98];&lt;&lt; y1 = sin(2*pi*4*t);&lt;&lt; y2 = cos(2*pi*4*t);&lt;&lt; plot(t,y1);&lt;&lt; hold on;&lt;&lt; plot(t,y2,&#x27;r&#x27;);\n\n\n\n加上横与纵轴的标签，标记两条函数，输入标题，并保存到桌面\n\n&lt;&lt; xlabel(&#x27;time&#x27;)&lt;&lt; ylabel(&#x27;value&#x27;)&lt;&lt; legend(&#x27;sin&#x27;, &#x27;cos&#x27;)&lt;&lt; title(&#x27;my plot&#x27;)&lt;&lt; cd &#x27;C:\\Users\\1\\Desktop&#x27;; print -dpng &#x27;plot.png&#x27;\n\n\n\n\n为不同图像标号：就可以同时有两个图像\n\n&lt;&lt; figure(1); plot(t,y1);&lt;&lt; figure(2); plot(t,y2);\n\n\n\n将一个界面分为两个格子，其中正弦占第一个，余弦占第二个\n\nsubplot(1,2,1);&lt;&lt; plot(t,y1);&lt;&lt; subplot(1,2,2);&lt;&lt; plot(t,y2);\n\n\n\n设置横竖轴的范围\n\n&lt;&lt; plot(t,y1);&lt;&lt; axis([0.5 1 -1 1])\n\n\n\n可视化矩阵\n\n&lt;&lt; A = magic(5)A =   17   24    1    8   15   23    5    7   14   16    4    6   13   20   22   10   12   19   21    3   11   18   25    2    9&lt;&lt; imagesc(A)\n\n\n\n生成颜色图像、灰度分布图并在右边加入一个颜色分布\n\n&lt;&lt; imagesc(A), colorbar, colormap gray;\n\n\n\n添加环境路径，找文件时，即使不在文件环境，也可以使用其中的函数\n\naddpath(&#x27;C:\\Users\\1\\Desktop&#x27;)\n\n05 控制语句\noctave可以返回多个返回值\n\n函数定义\n\n\nfunction J = costFunctionJ(X,y, theta)  m = size(X,1);  predictions = X*theta;  sqrError = (predictions-y).^2;  J = 1/(2*m) * sum(sqrError);\n\n\n函数使用\n\n&lt;&lt; addpath(&#x27;C:\\Users\\1\\Desktop&#x27;)&lt;&lt; X = [1 1; 1 2; 1 3]X =   1   1   1   2   1   3&lt;&lt; y = [1; 2; 3]y =   1   2   3&lt;&lt; theta = [0;1];&lt;&lt; J = costFunctionJ(X,y, theta)J = 0&lt;&lt; theta = [0;0];&lt;&lt; J = costFunctionJ(X,y, theta)J = 2.3333&lt;&lt; (1^2+2^2+3^2)/(2*3)ans = 2.3333\n\n06 矢量\n非向量化与向量化的代码对比\n\n\n\n用C++语言及C++线性库所写代码\n\n\n\n向量化\n\n\n","tags":["机器学习"]},{"title":"机器学习 day06Logistic回归","url":"/2021/07/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day06Logistic%E5%9B%9E%E5%BD%92/","content":"01 分类\n针对于离散值来进行分类：y &#x3D; {0，1}\n0表示负类，没有什么东西\n1表示正类，有什么东西\n不建议将线性回归函数应用于分类情况中\n使用线性回归在分类问题，如果一个值远离其他值，将会使线性回归算法不够准确。\n\n\n\nLogistic回归算法的预测值一直介于0和1之间，并不会像线性回归算法大于1或者小于0\n\n02 假设陈述\n假设陈述：当有一个分类问题的时候，我们要使用哪个方程来表示我们的假设。\nLogistic函数的形式如下：对线性回归方程稍作修改。\n\n\n\n输出某个数字，我们会把这个数字当作对一个输入x，y&#x3D;1的概率估计\n\n\n03 决策界限\n决策界限可以帮助我们理解Logistic回归的假设函数在计算什么。\n可以从图看出什么时候预测y &#x3D; 1;什么时候预测y &#x3D; 0;\n\n\n\n决策边界将一个平面划分为两个区域，其中一片区域假设函数预测y &#x3D; 1；另一片区域假设函数预测y &#x3D; 0。只要我们确定好了参数，我们就将完全确定决策边界。例如下图所示：可以得出直线 X1 + X2 &#x3D; 3就是决策边界。\n\n\n\n例题：我们怎么才能使用Logistic回归来拟合这些数据呢？多项式回归及线性回归可以在特征中添加额外的高阶多项式，Logistic回归也可以使用。\n\n\n\n决策边界不是训练集的属性，而是假设本身及其参数的属性，只要给定了参数向量就可以确定决策边界\n\n04 代价函数如何拟合Logistic回归模型的参数。当代价函数为0时，可以得出与预测值想拟合。\n\n\n如果将代价函数带入到Logistic回归中可以得到左侧图像非凸函数，可是我们想要得到右侧这样得凸函数。\n\n\n\n因此我们需要重新找到个代价函数可以用在Logistic回归中，保证找到全局最小值。下面使y &#x3D; 1情况下。\n\n\n\n下面使y &#x3D; 0情况下\n\n\n05 简化代价函数与梯度下降\n简化后得代价函数\n\n\n\n式子是在统计学中得极大似然法得来得，他是统计学中为不同模型快速寻找参数得方法。同时他是凸的。\n\n\n\n如何最小化代价函数：使用梯度下降算法。虽然Logistic回归中梯度下降算法与线性回归中的梯度下降算法长的一样，但是由于假设的定义发生了变化，所以实际上是两种截然不同的。\n\n\n06 高级优化\n一些高级算法的优缺点\n\n\n\n自动求使代价函数最小的参数，使用代码将其实现\n\n\n\n写一个函数，他能返回代价函数值以及梯度值\n\n\n07 多元分类：一对多使用逻辑回归来解决多类别分类问题\n\n\n训练一个逻辑回归分类器，预测i类别y &#x3D; i的概率。在三个分类器中输入x，在其中选择h(x)最大的那个类别。也就是选择出三个里面可信度最高，效果最好的的哪个分类器。\n\n\n\n无论i是多少，我们都能得到一个最高的概率值，我们预测y就是那个值。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day07正则化","url":"/2021/07/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day07%E6%AD%A3%E5%88%99%E5%8C%96/","content":"01 过拟合问题正则化可以减少过度拟合问题\n\n1.1  线性回归过拟合问题\n欠拟合 | 刚好合适 | 过拟合\n\n\n\n过度拟合问题将会在变量过多的时候出现，这时训练出的假设能够很好的拟合训练集（所以代价函数实际上可能非常接近于0。或者恰好等于0），但是可能会得到图三这样的曲线，去拟合训练集，以至于它无法泛化到新的样本中。\n泛化是指一个假设模型应用到新样本的能力\n\n1.2  逻辑回归过拟合问题\n欠拟合 | 刚好合适 | 过拟合\n\n\n\n如果我们有过多的特征变量而只有少量的训练集就会出现过拟合问题。\n有两种方法解决过拟合问题：\n尽量减少特征变量的数量（模型选择算法会自动选择哪些变量保留，哪些舍弃）\n正则化：减少量级或者参数的大小\n\n\n\n02 代价函数\n正则化将多阶函数变成二阶函数（将参数尽可能减小），这些参数越小，我们得到的图像也就越圆滑越简单。\n\n\n\n一般来说我们只对参数1以及1之后的进行正则化\n在对代价函数进行修改，添加正则化项的目的是为了缩小参数的值。\n正则化参数是为了控制两个不同目标之间的取舍\n正则化参数如果过大，那么参数都会接近于0，这样就相当于把假设函数的全部项都忽略了，最终变成了欠拟合。\n\n\n03 线性回归的正则化\n线性回归正则化的梯度下降法\n\n\n\n线性回归正则化的正规方程法\n\n\n\nm&lt;&#x3D;n，说明矩阵是不可逆的，但是当正则参数&gt;0，算出来的矩阵一定是可逆的。\n\n\n04 Logistic 回归的正则化\nLogistic 回归添加正则化项\n\n\n\nLogistic 回归的正则化的梯度下降法\n\n\n\n如何在更高级的算法中使用正则化：定义一个costFunction函数，以theta作为输入。在fminunc函数中括号里写上@cosFunction。\nfminunc的意思是函数在无约束条件下的最小值，fminunc函数会将costFunction函数最小化，\n\n\n","tags":["机器学习"]},{"title":"机器学习 day08神经网络学习","url":"/2021/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day08%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/","content":"01 非线性假设为什么已经有线性回归和逻辑回归算法了，还要学习神经网络？\n\n\n因为有特别多的特征，许多机器学习都需要学习复杂的非线性假设。如果使用逻辑回归算法，由于项数过多，可以能会导致过拟合问题，此外也存在运算量过大的问题。如果项数只包括二次项的的子集，这样将二次项的数量减少到100个，但是最有可能拟合出右下角椭圆而拟合不出左上角复杂的分界线。\n\n\n\n下图车子例子所示：如果是一张50 * 50 像素的图像， 则会有 50 * 50 &#x3D; 2500个像素单位（如果是彩色，每个像素又有0-255的RGB取值。即有 2500 * 3 &#x3D; 7500），特征数量则有约 n^2 &#x2F; 2 约 3000000 个特征数量。\n\n\n02 神经元与大脑神经网络能够很好的解决不同的机器学习问题\n\n\n神经网络的起源及发展\n\n\n\n神经元是一个计算单元，它从输入通道接受一定数量的信息，并做一些计算，然后将结果通过它的轴突传送到其他节点，或者大脑中其他神经元。\n\n\n03 模型展示\n神经网络模拟了大脑中的神经元或者神经网络。\n在神经网络里我们将使用一个很简单的模型来模拟神经元工作，我们将神经元模拟成一个逻辑单元。黄色代表类似于神经元细胞体的东西，经过“输入”-&gt;“计算”-&gt;“输出”三个步骤，因为X0（偏置单元或偏置神经元）总是1，会根据实际情况判断时候加上X0。\n在神经网络中激活函数是指非线性函数g(z)。单个神经元图如下：\n\n\n\n在神经网络中第一层叫做输入层，因为我们在这一层输入特征；第二层叫做隐藏层（任何一个非输入层和非输出层），隐藏层的值在训练中是看不到的；最后一层叫输出层，因为在这一层输出假设的最终计算结果；\n\n\n\nai(j)代表第j层第i个神经元或者单元的激活项，激活项是由一个具体神经元计算并输出的值。参数(j)就是权重矩阵，它控制从某一层到另外一层的映射。计算三个隐藏单位的值及输出如下：\n\n\n\n如何高效进行计算，并展示一个向量化的实现方法。\n\n前向传播方法\n\n\n\n下面这个神经网络所作的事情就像是逻辑回归，它不是以原本的X1、X2、X3作为特征，而是用a1、a2、a3作为新的特征\n\n\n04 例子与直觉理解神经网络计算复杂非线性函数的输入\n\n\nX1 AND X2运算\n\n\n\nX1 OR X2运算\n\n\n\nNOT X1\n\n\n\nX1 XNOR X2\n\n\n05 多元分类\n要是在神经网络中实现多类别分类，采用的方法本质是一对多法的拓展（其中Xi代表图像，Yi代表那些向量）\n\n\n","tags":["机器学习"]},{"title":"机器学习 day09神经网络参数的反向传播算法","url":"/2021/07/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day09%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95/","content":"01 代价函数\n有m组训练样本，L代表神经网络结构的总层数，S_l代表第L层的单元数也就是神经元的数量（不包括第L层的偏差单元）。其中二元分类与多类别分类问题如下：\n\n\n\n应用于神经网络的代价函数：h(x)是一个k维向量，h(x)_i代表第i个输出；k的求和符号应用于y_k和h_K,是因为我们主要是将第k个输出单元的值和y_k的值的大小作比较；y_k的值就是这些向量中其应属于哪个类的量。\n\n\n02 反向传播算法反向传播算法是计算代价函数关于所有参数的导数或者偏导数的一种有效方法。\n\n\n使用前向传播方法来计算的顺序，计算一下在给定输入的时候，假设函数是否会真的输出结果。\n\n\n\n反向传播算法中，下图上方下标j上标（l)代表了第l层的第j个结点的误差，下图上方下标j上标（l)实际上就是假设的输出值和训练集y值之间的差。反向传播算法类似于把输出层的误差反向传播给了第三层，然后再传播给第二层，注意没有第一层（第一层可以直观的观察到，没有误差）。\n\n\n\n如何实现反向传播算法来计算这些参数的偏导数：\n\n首先将每一个i和j对应的三角形（三角形是上图上方下标j上标（l)的大写）置0\n接下来遍历整个训练集，将输入层的激活函数设定他为第i个训练样本的输入值\n接下来用正向传播来计算第二层的激活值，然后第三层，最后到最后一层\n使用输出值来计算这个输出值对应的误差项（假设输出-目标输出）\n再通过反向传播算法计算前几层的误差项，一直到第二层\n最后通过三角形来累计我们再前面写好的偏导数项\n\n\n跳出循环后，通过下面的式子计算D(j等于0和j不等于0的情况)，计算出来的D正好就是关于每个参数的偏导数，然后可以用梯度下降法或者一些其他的高级优化算法。\n\n\n\n03 理解反向传播\n理解前向传播\n\n\n\n代价函数应用在只有一个输出单元的情况\n\n\n\n理解反向传播：代价函数是一个关于标签y和神经网络中h(x)的输出值的函数，只要稍微将z(l)j改一下，就会影响神经网络的h(x)，最终改变代价函数的值。\n\n\n04 使用注意：展开参数把参数从矩阵展开向量，以便在高级最优化步骤中的使用需要\n\n\n高级最优化算法都假定theta和initialTheta初始值都是参数向量，也许是n或者n+1维，同时假定这个代价函数的第二个返回值(梯度值)也是n维或者n+1维向量。但是现在在神经网络，参数不再是向量而是矩阵，三个参数在Octave表达如下；梯度矩阵在Octave表达也如下：\n\n\n\n取出矩阵，并将其展开成向量传入theta中，并得到梯度返回值。\nthetaVec就是将这些矩阵全部展开成为一个很长的向量；DVec同理。reshape将相应元素组合起来成相应矩阵。\n\n\n\n上面步骤通过Octave实现如下：\n\n&lt;&lt;Theta1 = ones(10,11)Theta1 =   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1&lt;&lt;Theta2 = 2*ones(10,11)Theta2 =   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2&lt;&lt;Theta3 = 3*ones(1,11)Theta3 =   3   3   3   3   3   3   3   3   3   3   3&lt;&lt;thetaVec = [ Theta1(:);Theta2(:);Theta3(:)];&lt;&lt;size(thetaVec)ans =   231     1&lt;&lt;reshape(thetaVec(1:110),10,11)ans =   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1&lt;&lt;reshape(thetaVec(111:220),10,11)ans =   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2&lt;&lt;reshape(thetaVec(221:231),1,11)ans =   3   3   3   3   3   3   3   3   3   3   3\n\n\n将这一方法应用于我们的学习算法\n\n\n05 梯度检测因为反向传播使用时会出现一些bug，而梯度检测可以很好的解决这些问题，确保前向传播及反向传播都百分百正确。\n\n\n求出该点导数的近似值（参数是实数的情况）\n\n\n\n当参数维向量参数的时候\n\n\n\n在Octave中为了估算导数所要实现的\n\n\n\n总结下如何实现数值上的梯度检验：（注意反向传播算法比梯度检测效率高，检测完一定要关闭梯度检测）\n\n\n06 随机初始化\n在神经网络中将所有参数初始为0，没有任何意义，所有输入都是一样，也就意味这最后输出就输出一个特征，阻挡了神经网络学习任何有趣的东西，我们称之为高度冗余。\n\n\n\n因此就应该使用随机初始化方法。值得注意的是这里的EPSILON与梯度检测中的完全没有关系。\n\n\n\n为了训练神经网络首先将权重随机初始化为一个接近0范围在-EPSILON到EPSILON之间，然后进行反向传播，在进行梯度检测，最后梯度下降算法或其他高级优化算法来最小化代价函数（关于参数sita的函数）。\n\n07 组合到一起\n训练神经网络做的第一件事就是选择一种合适的网络架构（神经元之间的连接模式），注意输出时是输出一个向量y。\n\n\n\n训练神经网络所需要的步骤\n\n\n\n\n反向传播算法是为了算出梯度下降算法的下降方向\n\n","tags":["机器学习"]},{"title":"机器学习 day10应用机器学习的建议","url":"/2021/07/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day10%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE/","content":"01 决定下一步做什么\n开发一个机器学习系统，或者想试着改进一个机器学习系统的性能，应如何决定选择哪条路。不要随意选择。\n\n\n\n机器学习诊断法能够提前发现某些方法是无效的。\n\n\n02 评估假设\n将所有数据分为训练集和测试集，最经典的分割方法就是按照7:3的比例。\n\n\n\n线性回归算法和平方误差标准学习和测试学习算法，从训练集学习获得参数，在将参数带入测试集得到测试误差。\n\n\n\n训练和测试逻辑回归的步骤及用错误分类（0&#x2F;1分类错误）来定义测试误差。0&#x2F;1表示了你预测的分类是正确或错误的情况。\n\n\n03 模型选择和训练、验证、测试集\n模型选择问题（想要确定对于一个数据集最合适的多项式次数，怎样选用正确的特征来构造学习算法或者假如你需要选择学习算法中的正则化参数）\n\n模型选择问题：用不同的模型拟合数据集得到参数，接着对所有这些模型求出测试集误差，然后根据哪个模型有最小的测试误差来选择使用哪个模型。\n\n\n\n\n为了解决模型选择出现的问题，我们通常会采用如下的方法来评估一个假设。我们把数据分为三个部分，分别是训练集、验证集、测试集。分配比例分别是6:2:2。\n\n\n\n定义训练误差、交叉验证误差和测试误差\n\n\n\n用验证集选择模型而不是原来的测试集。省下来的测试集可以用它来衡量或者估算算法选择出的模型的泛化误差了。\n\n\n04 诊断偏差与方差如果一个算法表现得不理想，要么是偏差比较大，要么是方差比较大。换句话说要么欠拟合要么过拟合。\n\n\n训练误差随着我们增大多项式的次数而减小；随着我们增大多项式的次数，我们对训练集拟合的也就越好。对于验证误差来说，如果d为1，会有较大误差；如果d为中等次数大小，能够更好的拟合；当d为4时，也就可能过拟合。\n\n\n\n对于验证误差来说，左边这一端对应的就是高偏差问题；右边这一端对应的就是高方差问题。如果训练误差很小，并且验证误差远大于训练误差说明出现过拟合问题（高方差）。如果是高偏差，则训练误差和验证误差都很大。\n\n\n05  正则化和偏差、方差\n第一个图是高偏差，欠拟合；中间正合适；最后一个图是高方差，过拟合。\n\n\n\n我们对训练、验证、测试误差的定义都是平均的误差平方和，或者是不使用正则化项时，训练集、验证集和测试集的平均的误差平方和的一半。\n\n\n\n自动选择正则化参数的方法：首先选取一系列想要试用的步长，通常来说步长设为2倍速增长，直到一个比较大的值。这样就选取了12个对应的正则化参数。然后对这12个模型分别最小化代价函数，得到完全不同的参数向量。可以把这些模型用不同的正则化参数来进行拟合，然后我们可以用验证集来评价这些参数sita在验证集上的平均的误差平方和，最终选择误差最小的模型。\n\n\n\n当我们改变正则化参数时，我们的假设在训练集和验证集上的表现（对应本节第一个图）\n\n\n06 学习曲线学习曲线可以判断某一学习算法是否处于偏差或者方差问题，还是二者都有。\n\n\n当训练集个数很少的时候，能够十分完美的拟合数据，训练集误差基本为0，但是随着训练集越来越多，训练集误差也就会越来越大，逐渐趋于水平。而验证集误差，随着训练集的个数增加而减小，最终趋于水平。\n\n\n\n在高偏差的情况下，训练集误差和验证集误差最终将十分接近，再增加训练集数量将毫无意义。\n\n\n\n在高方差的情况下，总体来说随着训练集数量的增多，训练集误差将会增加，但是增加的很小。而验证集误差一直都比较高，虽然会有所下降，但是不多。所以增加训练集数量还是很有用的。\n\n\n07 决定接下来做什么\n接下来回到第一节的第一个图，1和2和6对应着高方差的情况，3和4和5对应高偏差的情况（个人理解：高方差就是在多项式的形式下出现的，高偏差就是在项数少的情况下出现的）。\n\n\n\n小型神经网络计算量少，大型神经网络比较容易出现过拟合问题（但是可以用正则化来进行解决），相对来说大型神经网络性能更好。\n还有就是选择隐含层层数的问题，可以将数据分为训练集、验证集还有测试集。用训练集分别训练一层、两层、三层的隐含层，最终用验证集来测试，选出合适的层数。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day11机器学习系统设计","url":"/2021/07/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day11%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","content":"01 确定执行的优先级在实际工作过程中，我们应该优先处理哪些事情\n\n\n以邮件筛选为例，选择邮件的特征向量的方法。通常我们会挑选出在训练集中出现频率最多的n个单词，将其作为特征向量。\n\n\n\n如何在有限时间里让垃圾邮件分类器具有高精准度和低错误率。\n用更复杂的特征变量来描述邮件（可以在邮件标题中获取复杂的特征，来捕捉这封邮件的来源，以此判断是否为垃圾邮件）。\n关注邮件的正文，并构建更复杂的特征。\n来检测单词是否故意出现拼写的错误\n\n\n\n\n02 误差分析误差分析就是一种手动地去检查算法所出现的失误的过程，走向最有成效的道路。\n\n\n通过手动检查分类错误的邮件，来看哪一类分类错误的多，哪一个出现错的情况最多，就着重去构造这类特征，加以训练。\n\n\n\n交叉验证错误率：单一规则的数值评价指标。\n如果只是手动地去检查看看这些例子表现得好不好，会让你很难去决定到底应不应该做出某种决定；但是通过交叉验证错误率就可以直观的看误差率是变大还是变小了，他能告诉你你的想法是提高了还是降低。\n\n\n\n一旦有了一个初始的算法实现，我们就能使用一个强有力的工具，来帮助决定下一步应该做什么：\n看看他所造成的错误：通过误差分析来看看它出现了什么失误，然后以此决定之后的优化方法。\n如果已经有了一个简单粗暴算法实现，又有一个数值评价指标，这些能帮助来试验新的想法，能够快速观察是否能够提高算法的表现，决定应该包含什么，应该舍弃什么。\n\n\n\n03 不对称性分类的误差评估当有倾斜类问题时，使用准确率与召回率来评价学习算法要比用分类误差或者分类准确率好得多。\n\n\n偏斜类：一个类中的样本数与另一个类中的数据相比多很多（比如，没有肿瘤的比有肿瘤的要多得多）。所以说恒把y&#x3D;0算出来的误差将会很小，因为有肿瘤的人很少。\n\n\n\n所以我们想要一个不同的评估度量值：查准率和召回率。其中查准率是指对于所有我们的预测，患有癌症的病人，有多大比率的病人是真正患有癌症的。召回率是指假设如果测试集或者验证集中的病人确实得了癌症，有多大比率正确预测他们得了癌症。也就是如果所有病人都得了癌症，有多少人我们能够正确告诉他们你需要治疗。查准率和召回率越高越好。算法预测值与实际值分别是：1&#x2F;1（真阳性）、0&#x2F;0（真阴性）、1&#x2F;0（假阳性）、0&#x2F;1（假阴性）。\n\n\n04 精确度和召回率的权衡\n在逻辑回归中逻辑输出在0到1之间，其中0.5是个分界值，但是我们想在十分确定得情况下告诉病人真实信息，因此分界值为0.7，甚至0.9（是一个高查准率的模型，但是召回率会变低）。现在我们将分界值设置到较低（有30%几率得病），会得到高召回率，较低得查准率。\n\n\n\n有没有办法自动选取临界值？或者说有不同的算法，我们如何比较不同的查准率和召回率？或者临界值不同，我们怎样决定哪个更好？–如果使用平均值来计算是不可行的，因为如果假设y &#x3D; 1和y &#x3D; 0这两种极端的情况（要么很高召回率、很低查准率，要么很低召回率、很高查准率），他们俩不是好的模型。再此我们使用F值的公式，因为它同时结合召回率及查准率。\n\n\n\n自动选择临界值来决定你希望预测y&#x3D;1还是y&#x3D;0合理的方法：试一试不同的临界值，在检验集进行测试，看哪个临界值可以在检验集得到最高的F。这就是为分类器自动选择临界值的合理方法。\n\n05 机器学习数据在一定条件下，得到大量的数据并在某种类型的学习算法中进行训练，可以是一种有效的方法来获取具有良好性能的学习算法。这种情况一般出现在这些条件对于你的问题都成立，并且可以得到大量数据。\n\n\n并不是拥有最好算法的人能成功，而是拥有最多数据的人能成功。\n\n\n\n如果让一个英语好的选词填空，它可以通过特征x让我们能够准确的预测y，相反的，我们让一个房地产专家预测一个房价，而只告诉它房子的面积，其他特征不告诉，他会很难预测。因此如果这个假设正确可以看出大量数据是很有意义的。\n\n\n\n得到一个低偏差（一个强大的具有很多参数的学习算法，可以很好的拟合复杂的函数）和低方差（如果训练集远大于参数的数量，就不大可能会过拟合）的学习算法（特征值足够并且训练集很庞大）\n\n\n","tags":["机器学习"]},{"title":"机器学习 day12支持向量机","url":"/2021/07/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day12%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/","content":"01 优化目标支持向量机（SVM）在学习复杂的非线性方程时，能够提供一种更为清晰和更加强大的方式。\n\n\n从逻辑回归开始，稍作改动成为支持向量机\n观察下逻辑回归的假设函数和sigmoid激活函数\n\n\n\n\n\n观察逻辑回归的代价函数，当把整个假设函数的定义代入其中，得到的就是每个样本对总体函数的具体贡献。\n\n\n\n为了构建支持向量机，我们从这个代价函数开始进行少量修改，我们取z&#x3D;1，画出要使用的代价函数，右边都是平的，左边画出一条和最开始的幅度相似的直线，这就是y&#x3D;1时使用的代价函数。同样的做出y&#x3D;0时使用的代价函数。\n\n\n\n有了这些定义后，就可以开始构造支持向量机了，将修改后的代价函数定义带入到原始的逻辑回归代价函数中。支持向量机的代价函数将1&#x2F;m去掉，因为1&#x2F;m是一个常数，不影响得到参数的最优值。对于SVM来说我们将用一个不同的参数来控制第一项A与第二项B的相对权重，如果把C设置的很小，那么B就比A占有更大的权重。于是就得到了支持向量机的总体优化目标\n\n\n\n最后和逻辑回归不同的是，支持向量机并不会输出概率，相对的我们得到的是通过优化这个代价函数得到参数sita，支持向量机它是进行了一个直接的预测y&#x3D;0&#x2F;y&#x3D;1,学习得到参数sita后，这就是支持向量机的假设函数的形式。\n\n\n02 直观上对大间隔的理解\n下面是SVM代价函数，支持向量机不是恰好能正确分类就行，因此需要比0大或者小很多（也就是1或者-1）。\n\n\n\n如果C非常的大，那么当最小化最优目标的时候，将迫切的希望找到一个值使得第一项等于0。在两种情况下，通过选择参数sita使得第一项为0。\n\n\n\n支持向量机会选择尽量把正样本和负样本以最大的间距分开的假设模型。可以看出黑色的决策边界和训练样本的最小距离要更大一些。\n\n\n\n下面的大间距分类器是在常数C被设的非常大情况下得出的，平常情况下会得到黑色线，但是如果在一侧加入异常样本，那么就可能会是粉色的线。如果C不是很大，那么就算是加入异常点也会是黑色线。\n\n\n03 大间隔分类器的数学原理\n向量内积\n\n\n\n支持向量机的优化目标函数，当n&#x3D;2时我们只有两个特征量（也就是只有两个参数sita）。因此对于优化目标函数来说支持向量机做的是最小化参数向量sita的范数的平方。（为了简便都令sita0&#x3D;0）\n\n\n\n将sita转置x(i)替换后的结果写入我们的优化目标函数。令sita0&#x3D;0意味着决策边界必须通过原点(0,0)。下图是支持向量机选择不同的决策边界的情况。（向量sita一定是垂直于决策边界的），支持向量机通过让间距变大，使得p(i)变大，以至于输出一个较小的sita的范数。（为了简便都令sita0&#x3D;0，即使不为0，效果也不变。支持向量机仍然会找出正样本和负样本之间大间距分隔）\n\n\n04 核函数1改造支持向量机算法来构造复杂的非线性分类器。\n\n\n希望拟合一个非线性的判别边界来区分正负实例。一种方法是构造一个复杂多项式特征的集合，在这里我们用f1、f2、f3来表示这些我们将要计算的新的特征变量。\n\n\n\n构造新特征f1、f2、f3的方法：首先手动选取三个点（标记），接着将新特征定义为一种相似度的度量即度量训练样本x与标记的相似度（用下面公式表达）。相似度函数就是一个核函数（这里是高斯核函数）。\n\n\n\n对于这个核函数取两种情况：一种是x与标记点很近，一种是x与标记点很远。\n\n\n\n下面是核函数参数大小不同时的表现：\n\n\n\n选择不同的点，来预测y值是1还是0。可以看出离l_1和l_2近的点预测y值为1（带入下面的预测函数中如果&gt;&#x3D;0说明y&#x3D;1;&lt;0说明y&#x3D;0)。\n\n\n05 核函数2\n特征函数基本上是在描述每一个样本距离样本集中其他样本的距离，下面是这个过程的大纲。\n\n\n\n当已知参数sita时，怎样做出预测的过程。因为标记点的个数等于训练点的个数（m），所以参数向量sita为m+1维\n\n\n\n但是怎样得到参数sita？通过解决最小化的问题，你就得到了支持向量机的参数sita。\n\n\n\n在使用支持向量机时，怎么选择支持向量机中的参数C？–C相当于正则化参数的倒数，根据需求选择C。高斯核函数中的参数？–当高斯核函数中的参数相对较大时，图像将会倾向于变得相对平滑，可能会带来较高的偏差和较低的方差；当高斯核函数中的参数相对较小时，图像弧度将会相对大，可能会带来低偏差和较高的方差。（图像跟第四节倒数第二个相配套）\n\n\n06 使用SVM高度优化好的软件库：liblinear、libsvm\n\n\n我们虽然不用自己写SVM优化库，但是还是有几件事需要我们做：\n参数C的选择\n选择内核参数或者想要使用的相似函数\n\n\n对于内核函数其中第一个选择是不需要任何内核参数，没有内核参数的理念又叫线性核函数。为什么想要做这件事呢？如果有大量的特征n，而训练集m很小，也许就想拟合一条线性的判定边界，而不去拟合一条复杂的非线性函数。因此选择线性核函数可能很合适。\n对于内核函数其中第二个选择是可以构造个高斯内核函数。n很少，m很多，使用高斯内核函数可能很合适。\n\n\n\n如果选择要用高斯核函数，接下来要做的事：\n根据使用的支持向量机软件包可能需要实现一个核函数或者相似函数。因此如果使用Octave来实现支持向量机的话，那么就需要提供一个函数来计算核函数的特征值，它将自动的生成所有特征变量。因此对应一个i需要计算f_i。\n如果有大小很不一样的特征变量，要在使用高斯核函数之前，将这些特征变量的大小按比例归一化。下面以计算x与l之间的范数为例，如果第一特征房子面积特别大，第二特征房间个数在1到5之间，那么间距可能都是由特征一所决定，所以需要归一化。\n\n\n\n\n\n默塞尔定理是确保所有的SVM包能够用大类的优化方法并可以快速得到参数sita。其他核函数也都满足默塞尔定理，如下所示：多项式核函数（一个是自己添加的值可以是0、1、3…，还有一个是指数可以修改）。\n\n\n\n在多类分类中，输出在多个类别中恰当的判定边界。如果有k个类别用以将每个类别从其他的类别中区分开来。例如第一个参数sita_1,y&#x3D;1作为正类别，其他作为负类别得到的，以此类推。\n\n\n\n逻辑回归开始构造了SVM，然后更改下代价函数。如果n相对于m足够大，那么我通常使用逻辑回归或者线性核函数；如果n很小，m适中，通常使用高斯核函数的SVM比较好；当n很小m很大，建议手动地创建拥有更多的特征变量，然后用逻辑回归或者不带核函数的支持向量机。这种情况不适用神经网络，因为运行会很慢，而且SVM不用去考虑局部最优的问题。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day13无监督学习","url":"/2021/07/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day13%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/","content":"01 无监督学习\n无监督学习：训练集没有标签，也就是图上的点没有任何标签信息。我们要将这系列无标签的数据，输入到算法中，然后我们要让算法找到一些隐含在数据中的结构，这个图中数据集中的点两组分开的簇，这种能够找到这些簇的算法叫做聚类算法。\n\n\n02 K-Means算法K均值算法是现在最为广泛运用的聚类算法\n\n\n通过K均值算法将下图分为两个簇的具体操作：\n随机生成两点（聚类中心），选取两点的原因是想将数据聚成两类。\n\n\nK均值算法是个迭代算法，可以做两件事：簇分配和移动聚类中心。\nK均值算法每次内循环的第一步是要进行簇分配，观察图中的绿点，是接近哪个聚类中心，距离哪个近就分配给哪个。\n\n\n\n根据离红色或者蓝色聚类中心的远近，将每个点染成红色或者蓝色。\n\n\n\nK均值算法每次内循环的第二步是移动聚类中心，将两个聚类中心移动到同色点的均值处。\n\n\n\n接着我们进入下一个簇分配步骤：再次检查所有的无标签样本，然后根据这些点离红色或者蓝色聚类中心的远近，将其染成红色或者蓝色。\n\n\n\n再一次移动聚类中心，将两个聚类中心移动到同色点的均值处。\n\n\n\n以此类推，不断重复上面操作，得到最终结果。\n\n\n\nX^(i)是一个n维实数向量，这也就是训练样本是n维向量而不是n+1维向量的原因。\n\n\n\n以更加规范的格式写出K均值算法。\n\n\n\n假设u_k是某个簇的均值，那么如果存在一个没有点的聚类中心，会怎么样？–直接移除那个聚类中心，这样会得到k-1个簇而不是k个簇；如果你确实必须要k个簇，那么就随机初始化这个聚类中心。\nK均值算法最常还应用在分离不佳的簇的问题（右图），如果想把衣服根据体重身高分为小中大三个号，这时就可以使用k均值算法。\n\n\n03 优化目标\n当运行k均值算法时，我们会对两组变量进行跟踪。\n\nc^(i)代表的是当前样本x^(i)所属的那个簇的索引。\n用u_k表示第k个聚类中心的位置（K表示聚类中心的数量，k表示聚类中心的下标）。\n\n\nk均值算法的优化目标即最小化代价函数，代价函数有时也叫失真代价函数或者K均值算法的失真：\n\n\n\n\n簇分配实际上就是，不改变聚类中心的位置，而是选出c^(1)到c^(m)来最小化这个代价函数；而移动聚类中心实际上就是选择u值来最小化J。然后保持迭代。\n\n\n04 随机初始化如何初始化K均值聚类算法？引导讨论如何使算法避开局部最优。\n\n\n初始化聚类中心的比较好的方法，通常随机挑选K个训练样本，然后设定u_1到u_k，由于随机初始化状态不同，所以K均值最后可能会得到不同的结果。（最好使用这种方法）\n\n\n\n随机化得到结果比较好（右上图），也可能得到不好的局部最优值（右下图）。局部最优值指的是畸变函数J的局部最优，相对来说左下角图的这些局部最优所对应的情况，其实是K均值算法落在了局部最优，因而不能很好的最小化J。如果想要K均值算法找到最有可能的聚类（右上图），我们可以尝试多次随机初始化，并且运行多次。\n\n\n\n具体步骤如下：典型运行K均值算法的次数在50到1000次，需要在最后选取代价最小的一个。如果你运行K均值算法时，所用的聚类数相当小（2到10之间），那么多次随机初始化通常能保证找到较好的局部最优解，保证能找到更好的聚类，很好的最小化J；如果K非常大的话，多次初始化也不会有太大的改善。更有可能第一次初始化就会有很好的结果。\n\n\n05 选取聚类数量K均值如何去选择聚类数量？–最常用还是根据观察可视化的图，或通过观察聚类算法的输出去手动选择。\n\n\n当谈到选择聚类数量的方法时，可能谈到的一种方法叫“肘部法则”。我们所要做的是改变K，我们先用一个类来聚类，然后计算代价函数，接着用两个、三个…..（其中可能会多次初始化），可能会得到一个图像（随着K增多J下降），选择K&#x3D;3可能是正确的，因为K&#x3D;3之前下降很快，而之后就下降很慢。但是实际上好多时候都是右图，比较平滑没有拐点，从而不能准确选择K。不能期望它能解决任何问题。\n\n\n\n如果后续目的如市场分割能给一个评估标准，那么决定K更好的方法是看哪个聚类数量能更好地应用于后续目的。从商业角度看，例如如果K&#x3D;5是否我的衣服能够很好的满足顾客需求，还是K&#x3D;3时更加符合利益。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day14降维","url":"/2021/07/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day14%E9%99%8D%E7%BB%B4/","content":"01 目标 I：数据压缩\n想要使用降维的的原因：\n数据压缩，数据压缩不仅能使数据占用少量的内存或硬盘空间，还能对算法进行加速。\n\n\n如果特征高度相关，那么真的可能需要降低维数。\n将二维降到一维：两个特征变成一个特征，把每个样本都保持为一个数字，这样就能把内存需求（数据空间需求）减半。\n\n\n\n从三维降到二维：\n\n\n02 目标 II：可视化\n想要使用降维的的原因：\n\n可视化数据：将数据从50维或者更高维降到三维或者两维，这样就可以将其在图中画出来更好的理解他。\n\n\n50维数据：\n\n\n\n\n从50维降到2维，通常我们要了解z特征大致意味着什么。\n\n\n\n并画出2维图像\n\n\n03 主成分分析问题规划1对于降维问题最常用的一种算法叫主成分分析方法(PCA)的算法，本节课会试着用公式准确的表述PCA的用途。\n\n\nPCA所做的就是试图寻找一个投影平面对数据进行投影，使得能最小化这个距离。（PCA所作的是找到一个低维平面也就是图中的线，然后将数据投影到上面，使得蓝色的小线段（投影误差）长度平方最小）。对比可得选择橘色的而不选择粉色的。\n\n\n\n在应用PCA之前最常规的做法是先进行均值归一化和特征规范化使得特征量x_1和x_2其均值为0，并且其数值在可比较的范围之内。\n\nPCA与线性回归的区别：左图为线性回归，右图为PCA。线性回归的点是垂直横轴的（最小化蓝线之和的平方），而PCA的点是垂直那条线的（最小化蓝线的长度）。线性回归是通过输入x来预测y，PCA的特征值x之间都是平级关系。\n\n\n\n04 主成分分析问题规划2\n在使用PCA之前首先要做的的就是对数据进行预处理。\n给定一个训练集一定要做的是执行均值标准化：我们首先计算每个特征的均值，我们用减去它的均值取代每个特征x，这将使每个特征的均值正好为0\n根据数据也有可能需要进行特征缩放，缩放每个特征到一个相对的价值范围。\n\n\n\n\n\nPCA要做的是：计算这些向量例如u^(1)（即投影平面）；计算这些数字z\n\n\n\n用公式求解的过程：我们想把n维数据降到k维度，我们首先要做的是计算协方差（通常用大写的Sigma表示，是表示矩阵而不是求和），然后运用Octave中的svd()(奇异值分解)，也可以用eig()，不过svd()在数值上更加稳定。输出的将是三个U,S,V矩阵，我们真正需要的是U矩阵，可以发现U矩阵的列正是我们想要的u^(1)、u^()….。把n维数据降到k维度，就提取前k个向量。\n\n\n\n接下来我们要做的是获取我们的原始实数域数据集x找到一个低维的表示z。然后运用公式求解z\n\n\n\n协方差矩阵sigma的一个向量化实现：sigma &#x3D; (1&#x2F;m)X^TX,类似于K均值这里的X_0不能为1.\n\n\n05 主成分数量选择n维特征减少为k维特征，k为PCA算法的一个参数，也被称为主成分的数字，人们如何考虑选取k？\n\n\nPCA试图去减小投影误差平方的平均值，也就是试图减小x和x在低维面的投影的距离的差的平方。\n数据的总方差为样本x的平方和的平均值，也就是我们训练集中每个样本的平均长度（我们样本距离全零向量（原点）的距离）。\n选择k一个常用的经验方法是选择较小的值，使得这两者之间的比值小于0.01：让平均投影误差平方&#x2F;数据的总方差（数据的波动程度）。我们希望这个比例小于0.01或者小于1%，用PCA语言来说就是99%的方差性会被保留。当然0.01也可以换成其他值。为了保留99%的方差可以减少数据维数，但仍保留大部分的方差。\n\n\n\n下面的算法不断尝试从1开始修改k的值，然后进行PCA运算，最终使99%的方差性会被保留。这是一种方式来选择最小的k从而使99%的方差被保留。另一种方法是：通过SVD()计算出S矩阵（只有对角才有值，剩下的值为0），然后通过公式直接将k从1开始带进去，取前k个对角线的值相加&#x2F;整个对角线的值相加，看是否大于0.99.如果大于就选择这个k。对比可以看出第二种算法效率高，因为只需调用一次SVD()，而第一种需要多次调用PCA算法，相对来说效率低。\n\n\n06 压缩重现如何从低维的z^(i)变回原来的高维x^(i)?\n\n\n原始数据的重构：从压缩之后的低维的z^(i)变回原来未压缩的高维x^(i)：应用如下公式：\n\n\n07 应用 PCA 的建议\n使用PCA算法对监督学习算法进行加速的步骤：\n检查已经被标记的训练集，并抽取输入x，我们就得到了一个无标签的训练集x^(1)….x^(m)。\n用PCA得到原始数据的低维表示z，得到新的训练集。\n我们可以把这个低维的训练集输入到一个学习算法中，可以是神经网络、逻辑回归算法进行预测。\n注意PCA运算只能在训练集拟合这些参数，而不能在验证集或者测试集。定义x到z的映射后才能应用验证集和测试集中\n\n\n\n\n\n对PCA错误的使用就是尝试使用PCA来减少数据维度去防止过拟合，正确方法就是使用正则化。PCA运算是不使用标签的，只是针对输入x^(i)变为低维z^(i)，而不关心y，如果有99%的方差得以保留可以防止过拟合，但是也可能舍弃一些重要的信息，使得方差保留过低。\n\n\n\n在写下一个包含PCA的项目计划之前，应该问一问这个问题：如果我们直接去做而不使用PCA会怎样？一般直接建议：首先使用最原始的数据x^(i)，只有这么做达不到目的的情况下才考虑使用PCA和z^(i)，不要一开始就花大量的时间去应用PCA，计算k等等。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day15异常检测","url":"/2021/07/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day15%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/","content":"01 问题动机异常检测主要用在非监督学习，但从某些角度看，跟有监督学习问题是非常相似的。\n\n\n异常检测问题就是我们希望知道新的测试数据是否有某种异常，换句话说新的测试数据是否需要进一步测试。如下面这个图（飞机引擎的例子），其中x_1、x_2是飞机引擎的特征。通过测试发现如果x_test在对应点里面，那么他就不存在异常，如果在对应的外面，那么就存在异常。\n\n\n\n我们通常认定这m个数据都是异常或者都不是异常的，我们需要一个算法告诉我们一个新的样本数据是否异常。因此我们要做的就是给定无标签训练集，我们对数据建模即p(x)，也就是对x的分布概率建模。如果测试集的概率p低于阈值那么就将其标为异常，否则正常。越中心的点概率越高。\n\n\n\n异常检测最常见的应用是欺诈检测，例如许多购物网站常用来识别异常用户。可以针对不同的用户活动计算特征变量x^(i)，于是建立一个模型来表示用户表现出各种行为的可能性。x_1也许是用户登陆的频率，x_2也许是用户访问某个页面的次数……，然后根据这些数据建立一个模型p(x),就可以用这个模型发现网站上行为可疑的人。\n另一个例子就是上面的飞机引擎例子。\n第三个是数据中心的计算机监控，这种技术被各大数据中心来监测大量的计算机可能发生的异常。\n\n\n02 高斯分布（正态分布）\n假设x是一个实数的随机变量，如果x的概率分布服从高斯分布，那么记作X~N(均值，方差（标准差的平方）)。高斯分布的概率密度绘制出来是一个钟形，均值控制中心位置，标准差控制宽度。\n\n\n\n下面是参数不同画出来的图像，不管怎么样阴影部分的积分一定是1。\n\n\n\n参数估计问题：给定数据集希望能找到能够估算出均值和方差的值。下面是公式：\n\n\n03 算法\n我们处理异常检测的方法是：我们我们要用数据集建立起模型概率p(x)，我们要试图解决出哪些特征量出现的概率较高，哪些出现的概率较低。分布项p(x)的估计问题有时也称为密度估计问题，我们列出p(x)的计算公式（x_1到x_n连乘）如下：\n\n\n\n异常检测算法：\n选择特征量（能够描述所收集数据的一般特性的特征），能够帮助我们指出那些反常的样本。\n给出m个未作标记的样本的训练集。\n进行参数拟合u_1到u_n，(sita_1)^2到(sita_n)^2,运用公式来求解这些参数。\n给一个测试样本，根据p(x)的公式来测量是否异常。\n\n\n\n\n\n如何对这些数据拟合出参数值，通过第一个图的数据求出第二个图（概率图），然后将第二个图两个数据进行相乘画出第三个图（三维图）。如果一个想要检测一个样本是否异常，可以直接看三维图，异常的都在图像下围显示（概率低），而正常都在图像上围（概率高），其中上下围以一个值（伊克塞了吗）作为分界线。\n\n\n04 开发和评估异常检测系统\n实数评估的重要思想：当你为某一个应用开发学习算法时，你需要进行一系列的选择，比如选择使用什么特征。如果有一个方法通过返回一个实数来评估算法，那么就将变得容易多。如果有一个特征要考虑该不该将其纳入，就可以将其带入算法中返回一个实数来告诉你纳入前后对算法的影响。\n能够评估异常检测算法的标准方法：用一些带标签的数据来指明哪些是异常样本，哪些是正常样本。\n我们首先假设一些训练集看作是无标签的，他们是很大的正常样本的集合，即使其中掺杂了少许的异常样本也没关系。接下来在定义一些验证集和测试集（包含了已知是异常的样本即y&#x3D;1）用来评估这个异常检测算法。\n\n\n\n举一个例子：飞机成产了一万个正常飞机，2到50个异常飞机。把这些数据分配给训练集、验证集和测试集的经典方法是：分配正常样本是6：2：2。异常样本只分给验证集和测试集一人一半。按照道理来说验证集和测试集应该是完全不同的两种数据。\n\n\n\n得到训练集、验证集和测试集后推导和评估算法：\n使用训练集拟合模型p(x)，也就是将这m个无标签（实际上都是正常的）样本都用高斯函数来拟合。\n在验证集和测试集给出x的值，算法将预测出y的值，y&#x3D;1对应异常样本，y&#x3D;0代表正常样本。\n\n\n对于这个问题如果数据是倾斜数据（绝大多数数据都是正常的），我们就应该采用原来学过的真阳性、假阳性、真阴性、假阴性来计算召回率和准确率来预测算法的好坏。\n如果有一个验证集一个选择参数（伊克塞了吗）的方法就是尝试去使用许多不同的值，然后选择一个能够最大化F_1-score这样的实数，或者有其他好表现的。\n\n\n05 异常检测 VS 监督学习\n什么情况下很可能使用异常检测算法以及什么时候使用监督学习算法？\n\n第一种–&gt;对于异常检测算法：它有很少的正样本和很多的负样本，当我们在处理估计p(x)的值来拟合所有的高斯参数的过程中，我们只需要负样本就够了；相反对于监督学习算法：在合理的范围内会有大量的正样本和负样本\n第二种–&gt;对于异常检测算法：经常会有许多不同类型的异常，因此如果是这种情况你会有很少量的正样本，对于一个算法就很难从少量的正样本去学习异常，尤其是未来可能出现的异常可能会和已有的异常截然不同。比如你在正样本中已经了解到5个或者更多发生故障的情况，但是可能到了明天你就需要检测一个全新的集合（新的异常），这种情况就可以对负样本用高斯分布模型来建模；相反对于监督学习算法：有一个足够多的正样本或者一个能识别正样本的算法（未来可能出现的正样本与你当前训练集中的正样本类似），他能观察大量的正样本和大量负样本来学习相应的特征，可以正确区分正负样本。（例如垃圾分类）\n\n\n\n下面是一些异常检测和监督学习的例子，对于欺诈行为&#x2F;飞机引擎&#x2F;计算机检测，如果有大量的欺诈行为&#x2F;引擎异常&#x2F;计算机运行异常的情况，就可以转化为监督学习，但是一般都是异常检测；对于垃圾分类，天气预报、癌症分类等问题有大量的同量级正负样本这些情况就使用监督学习。\n\n\n\n\n总结一句话就是异常检测以正常（负样本）来建模，监督学习以不正常（正样本）来训练。\n\n06 选择要使用的功能你使用什么特征来实现异常检测算法将会运用产生很大的影响\n\n\n在异常检测中我们要做的其中一件事就是使用高斯分布来对特征建模，所以我们经常做的一件事就是画出数据或者用直方图来表示数据，以确保这些数据在进入异常检测算法前看上去比较接近高斯分布。当然即使数据不是高斯分布也是可以运行的，就是运行好坏的问题。例如下图所示，图一是比较理想的，如果得到图二，我希望对数据进行一些如下不同的转换使得它看上去更接近高斯分布。\n\n\nhist(x.^0.05,50)\n\n\n你如何得到异常检测算法的特征：通常用的方法就是通过一个误差分析步骤（跟我们之前讨论监督学习算法时误差分析的步骤是类似的）。我们先完整地训练出一个算法，然后在一组验证集上运行算法，然后找出那些预测出错的样本，并看看我们能否找到一些其他的特征来帮助学习算法，让那些在验证集中判断出错的样本表现得更好。下面通过一个例子来解释这个过程。一些大众的问题就是正负样本的概率都很高，以一个特征为例，x&#x3D;2.5时的一个测试样本是异常的，但是混在了正常样本里，这时就需要找到一个新的特征来使算法可以很好的将x&#x3D;2.5的测试样本进行分离。（绿色的代表异常）。\n\n\n\n下面是一些对异常检测算法选择特征变量时的一些思考：对于那些可能异常的样本即不选择那些特别特别大，也不选择特别特别小的特征。以监控数据中心的计算机的例子，如果一个计算机出现了故障，下面给出了一些可选的特征包括占用内存、磁盘每秒访问的次数、CPU负载和网络流量，现在假如说我怀疑某个出错的情况，在我的数据集中我的CPU负载和网络流量应该是线性关系，比如说检测服务器，一个服务器在运行多台电脑，这时x_3和x_4都很高；如果在运行任务时出现了死循环（x_3升高，x_4正常），这时要检测就可以建立一个新的特征x_5或者x_6。通过建立新的特征就可以捕捉到这些特殊的特征组合所出现的异常值。\n\n\n07 多变量高斯分布这节课将会学习目前为止学习的异常检测算法的一种可能的延伸，这个延伸会用到多元高斯分布。他有一些优势也有一些劣势，他能捕捉到之前的算法检测不出来的异常。\n\n\n异常检测算法给x_1和x_2建模的方法如下，给出一个样本(绿色的)，可以从大体上看出x_1和x_2是线性的，而绿色的可以看出x_1很少，而x_2很多是不符合线性的。该图认为同一个圈的概率是一样的，但是实际上从图可以看出其实是不一样的。\n\n\n\n为了解决这个问题，我们要开发一个改良版的异常检测算法，要用到多元高斯分布或者叫多元正态分布。有一个特征向量x，我们不要对x_1和x_2分别建模，而是要建立一个整体的p(x)模型。它的参数是n维向量(u)和n×n的协方差矩阵。\ndet(Sigma)--&gt;用来计算行列式\n\n\n\n我们来看下这里的p(x)是什么样的。其中Sigma衡量的是方差或者说是x_1和x_2的变化量。缩小方差相当于缩小(Sigma)^2，下面是同时改变Sigma的两个值。\n\n\n\n\n接下来我们只改变特征向量x_1的方差，展示如下：\n\n\n\n同样的们只改变特征向量x_2的方差，展示如下：\n\n\n\n多元高斯分布一件很棒的事是你可以用它给数据的相关性建立模型（可以用它来给x_1和x_2高度相关的情况建立模型），如果改变非对角线上的元素你会得到一种不同的高斯分布，随着非对角线上的值不断增加可以看出x接近y（大部分数据落到了x_1&#x3D;x_2），变得更窄。当把其设为正值时如下：\n\n\n\n当把其设为负值时（x_1&#x3D;-x_2）如下：\n\n\n\n当然还可以改变平均参数u，即中心点所在位置。\n\n\n08 使用多变量高斯分布的异常检测\n给定参数集来进行参数拟合或者说是参数估计问题（其中Sigma和PCA中写的是一样的）。\n\n\n\n把这些结合起来开发一个异常检测算法：\n用我们的数据集来拟合模型\n有一个测试样本，用多元高斯分布的公式来计算p(x)\n比较p(x)与伊克塞了吗的大小来得出结果。\n\n\n\n\n\n原始模型对比多元高斯模型，多元高斯模型的轮廓都是轴对齐的。其实原始的模型就是多元高斯模型的特殊形式，，当多元高斯模型Sigma的非对角线都为0的情况下，将原始的方差放入到Sigma中，这时两个模型就会完全相同，也就是说这个用了多元高斯分布的新模型，比起之前的旧模型，这个新模型对应的分布方程的轮廓就是轴对齐的，所以不能用不同的特征之间的关系进行建模。\n\n\n\n那么什么时候用原始模型（比较常用），什么时候用多元高斯模型呢？比如之前计算机检测的例子，原始模型可能就需要建立一个新的特征，而多元高斯模型就能自动捕捉这种不同特征值之间的关系。\n原始模型的一个巨大的优势就是计算成本比较低（能适应数量巨大的特征），而多元高斯模型需要计算Sigma的逆矩阵也就意味着计算成本非常高。原始模型还有个优势是即使你有一个较小的有一定相关性的训练集也能顺利运行，而多元高斯分布模型需要样本的数量大于特征的数量（因为需要求逆矩阵）。我们使用多元高斯分布模型当且仅当m&gt;&gt;n（如果不满足这一点那么多元高斯分布模型就会有很多参数，因为协方差矩阵是一个n*n的，所以协方差矩阵有n^2个参数，同样因为是一个对称矩阵所以更接近n^2&#x2F;2），所以需要确保有一个很大的m值，确保有足够的数据来拟合变量。\n如果你需要捕捉一些具有相关性的特征，通常是手动设计新的特征，但是当m很大或者是n不是很大时这时多元高斯模型更好。\n如果在实际操作中发现Sigma是奇异的不可逆的那么有两种情况：\n没有满足m大于n的条件\n存在冗余特征（比如x_1&#x3D;x_2、x_3&#x3D;x_4+x_5）\n\n\n\n\n\n总结下使用多元高斯分布来做异常检测，可以自动地捕捉正负样本各特征之间地关系。如果发现某些特征的组合值是异常的他就会标为异常样本。\n\n","tags":["机器学习"]},{"title":"机器学习 day16推荐系统","url":"/2021/07/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day16%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/","content":"01 问题规划特征对于机器学习来说是十分重要的，机器学习领域有一个伟大的想法，对于某些问题有一些算法可以自动的学习一系列合适的特征。\n\n\n我们为什么要谈论推荐系统？\n它是机器学习中的一个重要的应用，比如说亚马逊会根据你之前所买的书来给你推荐一些书。\n有一些环境能让你开发某个算法来学习使用哪些特征，而推荐系统就是那些环境中的一个例子，通过推荐系统我们能领悟一些特征学习的思想。\n\n\n推荐系统问题的组成：以电影评分为例，先说下这些符号的意思。n_u表示用户的数量、n_m表示电影的数量、r(i,j)代表用户j是否对电影i进行评价（&#x3D;1代表评价了），当用户对电影进行评分后会得到一个值y(i,j)，它代表用户j对电影i所给出的评分（0~5星表示）。\n因此推荐系统的问题是给出r(i,j)和y(i,j)数据然后去查找那些没有评分的电影，并试图预测这些电影的评价星级。\n\n\n\n总结：如果我们想开发一个推荐系统，那我们应该想出一个学习算法，一个能自动为我们填补那些缺失值的算法，这样就可以知道用户还有哪些电影没看过并推荐新电影给用户。\n\n02 基于内容的推荐算法\n我们用x_1（一部电影为爱情片的程度）和x_2（一部电影为动作片的程度）来表示电影的特征。为了做出预测我们把每个用户的评价预测值看做成一个线性回归问题。预测值就是用户j所学参数的转置与电影特征的内积。\n\n\n\n我们要m^(j)表示评价了电影j的用户数量，为了学习用户参数向量（sita）^(j)我们应该怎么做呢？这是一个基本的线性回归问题，我们可以直接选择一个参数向量，那么这里的预测值会尽可能接近我们在训练集中观察的值。为了学习参数向量我们来最小化参数向量（我们对所有用户j评价的所有电影的(预测值-实际观测值)的平方求和）再除以m。这就像是线性回归我们选择参数向量来最小化这种方差项，并且也可以加入正则化项。如果将这个公式最小化，你可以得到一个很好的对参数向量的估计值，用来对用户j的电影评价做预测。\n\n\n\n当构建推荐系统时，我们不仅是要学习单个用户的参数，我们要学习的是所有用户的参数向量，这时就要用到下面这个式子：\n\n\n\n总结一下：图片上面是我们的优化目标函数，换一种写法J依旧是优化目标函数也是我们试图最小化的项。如果去推到梯度下降更新的话，将会得到下面公式（分别是k&#x3D;0和k!&#x3D;0的情况，因为上面的公式k是不等于0的），用梯度下降算法进行参数更新，最小化J来学习所有的参数。\n\n\n\n基于内容的推荐算法，因为我们假设变量是已有的即我们有描述电影内容的特征量（电影中爱情成分和动作成分有多少），同时用这些特征量来进行预测。\n\n03 协同过滤\n协同过滤有一个很有意思的特性叫特征学习，这种算法能自行学习所要使用的特征。\n我们假设已经知道了每个用户的参数，那么通过每个用户的评分就可以算出一个电影包含爱情和动作的程度。（右下角)\n\n\n\n我们将这一学习问题标准化到任意特征x^(i)，求出x^(i)让预测值尽可能的接近真实值。\n\n\n\n基于内容的推荐算法是给特征求参数，第二个是给参数求特征。实际上我们可以随机地猜取一些参数，然后就能得到特征，再根据特征求参数不断地迭代得到更好地参数和特征，最终将会收敛到一组合理的特征和参数。这个过程就是协同过滤算法。\n\n\n\n对于推荐系统问题，仅建立在每位用户都对数个电影进行了评价，并且每部电影都经过数位用户评价的情况下，这样才能重复这个迭代过程，才能求出参数和特征。\n总结下：协同过滤算法是指当你执行算法时，要观察大量的用户及用户的实际行为来协同得到每个人对电影更佳的评分值。协同的另一层的意思就是说每一位用户都在帮助算法更好的进行特征学习。如果每一个用户都对一部分电影做出了评价，那么每个用户都在帮助算法学习出更适合的特征，然后这些被学习出来的特征又可以更好的预测其他用户的评分。\n\n04 协同过滤算法\n存在一种算法不需要不停的计算特征和参数，而是能够将特征和参数同时计算出来。下面就是这种算法，需要将前两个优化目标函数结合为一个。第一个平方误差项（所有用户j的总和及所有被该用户评分过的电影总和）和第二个平方误差项（与上面那个是相反的运算：对每部电影i，将所有对它评分过的用户j求和）相加得到新的平方误差项（对所有有评分的用户和电影进行求和），剩下两项拖下来。\n新的优化目标函数J有一个特性，你将x作为常数并关于参数（sita）最优化其实就是在计算第一个式子，反过来你将参数（sita）作为常数并关于x求J的最小值的话，其实就是在计算第二个式子。\n当我们以这样的方法学习特征量时我们不再遵循原来的惯例（x_0&#x3D;1），理由是我们现在是在学习所有的特征，没有必要将一个特征值硬编码为1，因为如果算法真的需要一个特征值为1，那么它可以选择靠自己去获取1这个数值，比如将x_1设为1.\n\n\n\n协同过滤算法步骤：\n将特征和参数初始为小的随机值（这有点像神经网络）\n用梯度下降或者其他的高级优化算法将代价函数最小化（这里没有分出k&#x3D;0的情况是因为不存在x_0&#x3D;1这一项了）\n如果给你参数和特征，就可以预测评分了\n\n\n\n\n\n这个算法可以学习几乎所有电影的特征和所有用户参数，能对不同用户会如何对他们尚未评分的电影做出评价，给出相当准确的预测。\n\n05 矢量化：低轶矩阵分解将介绍协同过滤算法向量化的实现及使用算法可以实现的一些功能（比如说给定一个商品，可以找到与之相关的一些产品）。\n\n\n将数据的预测值写成矩阵形式：\n\n\n\n用另一种方法低轶矩阵分解（矩阵X乘以sita的转置）写出这个算法的所有预测评分：\n\n\n\n利用学习到的属性来找到相关的电影，通常算法会学到一些有意义的特征。我们可以衡量两个电影的相似度（两个电影的特征距离很接近）来找到相关影片。\n\n\n06 实施细节：均值规范化\n下面增加了一个用户，这个用户之前没有给任何电影评过分，将其带入协同过滤算法中。因为用户对电影没有评分，所以算法的第一项对用户参数的选择是没有影响的，只有最后一项可以影响参数的选择，又因为最后一项是正则化，所以说得出来的参数是二维的零向量。二维零向量与哪个二维向量内积都为0，这样的结果不是我们想要的。\n\n\n\n均值归一化的思想可以帮助我们解决这个问题，下面介绍它是如何工作的：把每个电影评分都归一化使得均分为0\n\n将所有的评分都放到Y矩阵中\n计算每个电影所得评分的均值，并将其存放在一个叫u的向量中\n将Y中所有元素-均值\n对新的评分数据集使用协同过滤算法来学习用户参数及电影特征\n最后来计算电影评分：用户参数的转置与电影特征的内积+u（因为训练集中减去了均值，因此在这里需要加上）\n\n\n之前用户参数为二维零向量的问题依然存在，但是第五个用户的预测评分变了，变成了电影评分的均值。选择一个大众比较喜欢的推荐给第五个用户，当然如果一个电影没有评分（就不应该推荐，因为关心没有评价电影的人比关系没有被评价过电影更有意义），也可以对Y的每一列进行均值归一化。\n\n\n\n\n总结一下：均值归一化的实现作为协同过滤算法的预处理步骤，根据不同的数据集，有时可以让你的算法表现得更好一些。\n\n","tags":["机器学习"]},{"title":"机器学习 day17大规模机器学习","url":"/2021/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day17%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","content":"01 学习大数据集大规模机器学习就是处理大数据集的算法\n\n\n一种获取高性能的机器学习系统的途径是采用低偏差的学习算法并用大数据进行训练。\n大数据集学习的特有问题是计算问题。\n在训练一亿个样本之前，我们可以随机选择一亿个样本中的一千个样本，然后用这一千个样本来训练我们的算法。如果用一千个样本训练效果也是一样的话，在训练大量的模型前预先检查往往也是一个明智的选择。如果效果相同的话，可以根据这一千个样本绘制学习曲线，如果画出左图高方差的曲线那么增加训练集还是有作用的，如果是右边高偏差的算法，样本也不会比训练1000个更好了，如果是右图那么自然而然地会添加额外地特征项或在神经网络中添加额外地隐藏单元，这样最终可能得到左边的图。\n\n\n02 随机梯度下降当我们训练集很大时，梯度下降算法的计算量会变得非常大，因此对普通的梯度下降法进行改良为随机梯度下降法，使得算法能够应用于大规模的数据训练。\n\n\n先来回顾下线性回归：第一个式子是假设函数，第二个式子是代价函数，第三个式子是不断地更新参数sita来使得代价函数趋于最小，右图是构建的三维函数可以看出是弓形。\n\n\n\n在参数初始值，运行梯度下降算法，将会不断迭代，最终得到参数的全局最小值。如果m的值非常的大，那么单单是计算微分项就需要很大的计算量，更何况还要一次次的迭代。这个梯度下降算法又叫批量梯度下降，其中批量是指每次都需要同时考虑全部的训练样本。\n\n\n\n随机梯度下降算法每次迭代不需要每次都同时考虑全部的训练样本，仅仅只考虑一个训练样本。为了更好的描述随机梯度下降算法，我们将代价函数定义为右侧的第一个式子，这个代价函数实际上是衡量我的假设函数在某个样本(x(i),y(i))上的表现。而左图第一个总体代价函数可以写成右图第二个式子（假设函数在m个训练样本中每一个样本(x(i),y(i))上的代价函数的平均值），随机梯度下降的步骤如下：\n将所有的m个训练样本重新随机排列。(这保证了遍历时对训练集样本的访问是以随机顺序排列的，这一步能让随机梯度下降在收敛时能够更快一点)\n对所有的训练样本进行遍历，然后做如下参数更新.（就是不断地对参数进行调整来依次适应第一个参数、第二个参数……..）\n\n\n随机梯度下降和批量梯度下降相比不需要对全部的m个样本求和来得到梯度项，而只需要对单个样本就可求出梯度项（黄色框画出来的就是梯度项）。在随机梯度下降过程中我们已经开始一点点把参数向全局最小值的方向进行修改了。\n\n\n\n随机梯度下降每一次迭代都会更快，因此我们不需要对所有训练样本进行求和，每一次迭代只要保证能拟合某一个训练样本即可。虽然它的参数走的线不是一条曲线，但是它是随机而迂回的路径朝着全局最小值的方向移动的。随机梯度下降和批量梯度下降相比收敛形式是不同的，他就是连续不断的在某个区域中朝着全局最小值的方向徘徊，而不是直接打到全局最小值（在实际应用中，只要能接近全局最小值就能得到一个很好的效果）。\n在随机梯度下降法中其实还有一个外层循环（1到10次，通常一次就可，还是取决于数据集m的大小）来决定内层循环的次数\n\n\n\n总结下：批量梯度下降算法是一次就需要遍历全部的训练集，然后在进行迭代（迭代一次就相当于遍历两次全部训练集）才有可能得到全局最小值，而随机梯度下降算法有可能只需要遍历一次就可以的到全局最小值。所以说将随机梯度下降法的思想应用到学习算法中来适应更大的数据集从而提升算法的性能。\n\n03 Mini-Batch 梯度下降Mini-Batch 梯度下降有时甚至比随机梯度下降还要快一些。\n\n\n总结下我们迄今为止学的梯度下降算法：\n批量梯度下降算法每次迭代都要用到所有的m个样本\n随机梯度下降算法每次迭代只需要使用一个样本\n而Mini-Batch 梯度下降算法每次迭代会使用b个样本（b是一个称为Mini-Batch大小的参数，通常选择b&#x3D;10，b的范围是2~100），它是介于批量梯度下降算法和随机梯度下降算法之间的算法。\n\n\n\n\n\nMini-Batch 梯度下降完整算法如下：以步长为10增长为例，仅用前十个样本就能运行算法来更新参数，这也是为什么Mini-Batch 梯度下降比批量梯度下降算法要快的原因。为什么Mini-Batch 梯度下降不像随机梯度下降算法一样每次只使用一个样本呢？–&gt;因为在向量化过程中Mini-Batch 梯度下降比随机梯度下降更快（仅当有好的向量化方法）。\nMini-Batch 梯度下降算法的缺点之一是当有一个额外的参数b时，你需要确定Mini-Batch大小，这需要额外的时间，当然如果有好的向量化算法Mini-Batch 梯度下降比随机梯度下降更快。\n\n\n\n如果有一个合适的向量化的方法，蓝框的求和公式将在10个样本中实现部分并行计算，换句话来说通过合适的向量化方法计算余下的样本，可以部分使用好的数值代数库，然后对b个样本并行进行梯度计算，随机梯度下降算法每次只针对一个样本肯定没有太多的并行计算。\n\n04 随机梯度下降收敛当你运行随机梯度下降算法时如何确保调试过程已经完成，并且已收敛到合适的位置呢？怎样调整随机梯度下降算法中的学习速率a的值呢？\n\n\n批量梯度下降算法确保梯度下降已经收敛的一个标准方法就是绘制优化代价函数（关于迭代次数的函数），我们要确保代价函数J每一次迭代都是下降的。当m教小时使用这个还算可以，但是当训练集m特别大时，你肯定不希望得定期的暂停这个算法来计算蓝色框中的式子，因为每次计算都会遍历整个数据集。\n对于随机梯度下降算法为了检查算法是否收敛可以进行下面的工作：当随机梯度下降法对训练集进行扫描时，在我们使用某个样本(x(i),y(i))来更新参数sita之前，让我们来计算出这个训练样本假设的表现有多好即cost()函数。最后为了检查是否收敛，每1000次迭代就画出前一步骤所计算出来的cost()函数前一千个样本的的平均值，这样通过观察图就可以看是否下降收敛，可以看出算法在你前一千个样本中表现得有多好。\n\n\n\n下面第一个图中红色线代表更小的学习速率a，可以看出更加得平缓但是能得到更好的效果。（因为随机梯度下降不是直接达到全局最小值，而是在这个区域不断震荡，学习速率越小震荡幅度也就越小。）第二个图中得红色线代表样本从一千增加到五千，可以看出得到的曲线比较平滑，但是得到的关于算法表现有多好的反馈就有一点延迟，因为图中每一个数据点是从五千个样本中得到，而不是从之前的1000个样本得到。第三个图由于样本太少所以表现得好像没有下降收敛一样，红线代表样本增加到5000，可以看出比最开始显得下降了。而粉色线也代表样本增加到了五千但是没有啥变化，这就说明算法基本就没有学习，这时需要调整学习速率或者特征或者其他东西。第四个图是上升的趋势，这时算法发散了，这时就需要更小的学习速率。\n\n\n\n总结：如果出现噪声太大或者图像老是上下振动，就可以试着增加求均值的样本的数量，如果图像上升那么就用一个更小的学习速率。\n如果你想要将随机梯度下降到更好的收敛到全局最小值（也是接近哈），那么就需要让学习速率的值随时间变化而逐渐减小。经典的做法就是让a&#x3D;某个常数1&#x2F;（迭代次数+某个常数2），但是很少用，原因有二：一是收敛得到的值已经很满意了，二是还需要确定两个常数，无形中又增加了算法的复杂性还有计算量。\n\n\n05 在线学习在线学习机制可以让我们模型化一些问题，就是我们有连续一波数据，想要用算法从中学习的这类问题。\n\n\n以提供运输服务为例，y&#x3D;1是购买运输服务，y&#x3D;0是不购买，我们想要用（出发地、目的地、我们提供的价格等）特征来学习他们选择我们来运输包裹的概率。如果我们可以估计出每种价格下用户选择使用服务的概率，我们就可以选择一个价格即可能使用户选择我们，我们还会有回报。算法如下：当用户访问我们时，我们会得到与其对应的（x，y）对，在线学习算法就会利用刚得到的（x，y）(因为我们不使用固定的训练集，所以这里不是（x^(i),y^(i)）)来更新参数theta。我们使用完这个样本就会将其丢弃不在使用，这也就是为什么一次只处理一个样本。\n\n\n\n在比如说搜索的例子（又叫点击率预测学习问题 -CTR），当你搜索手机时，他会从100个手机里给你推送10个，提供了特征x(与你搜索的手机关联度)，y&#x3D;1是点击进入。运行此类网站的一个方法就是不停的给用户展示你对他们可能会喜欢的十个手机的预测，每一次用户访问你将会得到十个样本即十个对应的（x，y）对，然后运行在线学习算法来更新参数，对这十个样本利用10步梯度下降法来更新参数。\n\n\n\n在线学习的一个优点就是如果有一个变化的用户群又或者是你在预测的事情在缓慢的变化，在线学习算法可以慢慢地调试你所学习到的假设，将其调节到最新的用户行为。\n总结：在线学习算法与随机梯度下降算法的唯一的区别就是我们不会使用一个固定的数据集，而是获取一个用户样本从那个样本中学习，然后丢弃那个样本继续处理下一个。如果某一个应用有一个连续的数据流，这样的算法是非常值得考虑的。\n\n06 减少映射与数据并行MapReduce思想可以将学习算法应用于随机梯度下降不能解决的规模更大的问题。\n\n\n根据MapReduce思想我们把训练集分为不同的子集，有几台电脑或者机器并行处理训练集数据就分为几个子集。每台机器使用相对应的子集来处理梯度下降算法中的求和部分，这样每个机器都进行工作，效率就提高了好几倍。最后我们将这些temp变量发送给一个中心服务器，中心服务器会整合这些结果，尤其是将更新我的参数theta。可以说这个公式完全等同于批量梯度下降法，只是不需要在一台机器上处理这400个数据。\n\n\n\n就例子而言，四台电脑各自承担四分之一的计算量，你可以加速到四倍速，如果没有网络延迟和忽略传输数据所有时间，那么就是四倍的速度，当然现实中的网络延迟及汇总所需要额外的时间，实际速度比四倍小。\n\n\n\n使用MapReduce思想还需要考虑学习算法是否可以表示成对训练集的一种求和。如果可以就能将学习算法的适用范围扩充到非常非常大的数据集。下面一个例子：高级优化算法需要计算优化目标的代价函数的计算过程和这些偏导项的计算过程，电脑把他们发送给中心服务器，然后将各部分和（temp^(i)_j）加起来，获得总的代价函数获得总的偏导项，接着将这两个值发送给高级优化算法。\n\n\n\n现在也可以在单机上使用MapReduce，因为电脑有多个处理核心CPU，CPU又有多个核心。这样的好处是可以不用担心网络延迟问题。如果你有一个多核机器，同时你有某些线性代数库（可以自动在一台电脑不同核心上进行并行代数运算），并且你的学习算法有非常好的向量化表示，你就可以直接以向量化的形式应用标准学习算法，不用担心并行（线性代数库就可以处理好）。\n\n\n","tags":["机器学习"]},{"title":"机器学习 day18应用举例：照片OCR（光学字符识别）","url":"/2021/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%20day18%E5%BA%94%E7%94%A8%E4%B8%BE%E4%BE%8B%EF%BC%9A%E7%85%A7%E7%89%87OCR%EF%BC%88%E5%85%89%E5%AD%A6%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%EF%BC%89/","content":"01 问题描述与 OCR pipeline照片OCR问题注重的是如何让计算机读出照片中的文字信息（照片OCR对于读取文档来说很简单，但是对于数码照片来说还是很难的）\n\n\n照片OCR当你输入文字时，计算机就能自动的帮你找到相册里带有这些文字的照片，它有如下几个步骤：\n给定某个照片，将其图像扫描一遍。\n找出照片中的文字信息\n找出照片中的文字信息之后，将重点关注这些文字区域，并对区域中的文字进行识别，当它正确读出这些文字之后，他会将这些文字内容显示并记录下来。\n\n\n\n\n\n总体来说步骤分为三类：文字检测、字符分割以及字符分类（其实还有个拼写校正）。\n\n\n\n像这样的系统，我们把它称为机器学习流水线：首先有一个照片，然后把它传给文字检测系统，识别出文字区域后，将文字区域中的单个字符分割出来，最后对这些单个字母进行识别。\n\n\n02 滑动窗口关于流水线中每个独立的组件的工作原理，主要讲一个叫滑动窗口分类器。\n\n\n照片OCR问题难在文字区域对应的矩形具有不同的长宽比例，而对于行人检测来说，人们的长宽比基本相同。\n\n\n\n建立一个行人检测系统，我们可以这么做：假如决定要把比例标准定为82 * 36（当然其他比例也可以），然后从数据集中收集一些正样本和负样本（都是82 * 36的照片），在你的网络中训练或者使用其他学习算法向其中输入一个82 * 36的图块来对y进行分类，来划分每个图块是否包括一个行人\n\n\n\n下图相当于一个训练集，首先在图片中选取一个矩形块（比如是左上角绿框），然后将图块传送给我们的分类器，来检查图块中是否有行人，然后每次以一定的步长（也称滑动参数）来移动图块，传送给分类器不断地判断图块中是否有行人。然后再以更大窗口移动来判断是否有行人，这样算法便能检测出图中各个地方是否出现行人。这就是一个监督学习分类器，然后使用一个滑动窗口分类器来找出图中所有行人。\n\n\n\n接下来看一下在图片OCR中如何找出图中的文字区域：\n\n首先也是拿出一系列的包括正样本和负样本的训练集。\n\n\n\n训练完后将其应用在一个新的测试集中的图片，在此使用固定比例的滑动窗口，会得到左下角的图片（白色表示文本检查系统发现了文本，而深浅不同的灰色对应的是分类器认为该处有文字的概率），然后将分类器的输出应用到一种叫放大算子（就是扩大白色区域，如何扩大呢？就是通过检查像素附近是否存在白色像素，然后把这一范围内都变成白色）的东西上得到右下角的图，然后需要在右下角图中白色周围绘制边框，文本周围的框宽度应该远大于高度，通过这个特性就可以筛选出正常的文字区域。\n\n\n\n接下来进入识别文本阶段也就是字符分割，在此我们再次使用监督学习算法用一些正样本（可以进行分割）和负样本（不可以进行分割），对分类器进行训练完就可以将其运行在文字检测系统输出的这些文本中，最终可以将图像全部分成单独的字符。\n\n\n\n\n03 获取大量数据和人工数据一个最可靠得到高性能机器学习系统的方法是使用一个低偏差机器学习算法并且使用庞大的训练集去训练他。其中人工数据合成可以为合适的机器学习问题轻松得到大规模的训练集。\n\n\n人工数据合成主要有两种形式：\n\n自己创造数据（从0开始创造新数据）\n已经有小的标签训练集，然后以某种方法扩充训练集（引入失真）\n\n\n假如我们收集到了一个大的标签数据集如左图所示，我们的目标是输入一个图像块然后识别出图像块中央的字符。为了简化操作我们将图片处理成灰度图像而不是彩色图像。如果想要更多的训练样本一个方法就是用不同的字体生成字符，然后将其粘贴到任意不同的背景中，然后可以应用一点模糊算子或者仿射变换（仿射的意思是进行等分、缩放和一些旋转操作），完成这些操作就会得到一个人工合成训练集如右图所示。这个就是自己创造数据。\n\n\n\n\n使用现有的样本生成训练集。可以对图片进行人工拉伸或者人工扭曲（必须要合理的，具有代表性），这样就可以将一个样本变成16个新样本了。通过这种方法就能将一个小的标签训练集扩充为一个更大的训练集。当然不同的机器学习应用，可能其他类型的失真将更合理。以语音识别为例，目的是从对话中获取内容，可以通过人工添加失真引入不同背景音乐，得到大量的训练集。生成的新样本一定要具有代表性是有可能在测试集中见到的样本。\n\n\n\n\n在生成大量人工训练集之前最好画一个学习曲线保证你有一个低偏差高方差的分类器。如果你的偏差太高，可以尝试持续增加分类器的特征数量或者增加神经网络隐藏单元的数量，然后在花精力在生成大量人工训练集，这样就避免了花费大量的时间来收集数据却发现没有多大作用。用学习曲线做一个合理的检验看更多的数据是否真的有用。\n\n获得目前训练集十倍的量需要花费多少工作量（方法）？\n\n人工合成数据\n自己收集数量或者添加标签\n众包数据标记：从花钱网上找人来帮你标记训练集\n\n\n\n\n04 天花板分析：下一步工作的 pipeline上线分析：当你自己或者跟你的团队在设计某个机器学习系统工作流时，这种方法能够提供一个很有价值的信号，知道你工作流中哪一部分最值得花费时间去研究。\n\n\n为了决定如何开发系统一个有效的方法就是对学习系统使用一个数值评价量度，假如我们用字符准确度作为这个量度，给定一个测试样本图像，那么这个数值就表示我们对测试图像中的文本识别正确的比例。如图所示：不管你用什么度量值来度量，整个系统的总的准确率为72%。\n下面是上线分析的主要思想：还是以图片OCR流水线为例，首先我们先关注文本检测，对于每一个测试样本都给一个正确的文本检测结果，换句话说就是要100%正确检测出图片中的文本信息。只需要找到对应图像，然后人为的识别出测试集图像中出现文本的区域，让这个模块人为的输出正确的结果，将结果传送给字符分割模块，然后运行后面两个模块，使用之前一样的评价量度指标算出整个系统总的准确率89%，同样的在上一个处理的基础上，字符分割模块也用全部正确的结果去输出，得到了90%的准确率，字符分类也一样（全都是正确的当然是100%）。\n使用上限分析就可以看出每个模块进行改善后各自的成长空间是多少，可以看出完美的文本检测得到的增益最大。\n\n\n\n人脸识别也是一样：\n\n\n","tags":["机器学习"]},{"title":"机器学习总结","url":"/2021/07/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/","content":"\n监督学习算法：线性回归、逻辑回归、神经网络、支持向量机（在这些问题中会有带标签的数据和样本）\n无监督学习：K-均值聚类算法、主成分分析法（进行降维）、异常检测算法（对算法进行评估）\n特定的应用和话题：推荐系统、大规模机器学习系统（包括并行和映射-化简算法）\n其他的应用：滑动窗口分类器（计算机视觉问题）\n从各个不同的方面给出了如何构建机器学习系统的建议：偏差和方差（尝试了是什么使得机器学习算法工作或者是不工作）、正则化（解决一些方差问题）、学习算法的评估方法：召回率和F1分数这样的评价指标和实践方面的评测方法：训练集-交叉验证集-测试集（当你开发一个机器学习系统时如何合理分配你的时间）、诊断方法：学习曲线和误差分析及上限分析（如何调试算法确保学习算法能够正常工作）。所有这些工具都能帮助你决定下一步该做什么以及怎么分配时间。\n\n\n","tags":["机器学习"]},{"title":"当你的浏览器中地址栏输入地址并回车的一瞬间到页面能够展示回来，经历了什么？","url":"/2022/04/12/%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E5%BD%93%E4%BD%A0%E7%9A%84%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%AD%E5%9C%B0%E5%9D%80%E6%A0%8F%E8%BE%93%E5%85%A5%E5%9C%B0%E5%9D%80%E5%B9%B6%E5%9B%9E%E8%BD%A6%E7%9A%84%E4%B8%80%E7%9E%AC%E9%97%B4%E5%88%B0%E9%A1%B5%E9%9D%A2%E8%83%BD%E5%A4%9F%E5%B1%95%E7%A4%BA%E5%9B%9E%E6%9D%A5%EF%BC%8C%E7%BB%8F%E5%8E%86%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/","content":"（1）浏览器本身是一个客户端，当你输入URL的时候，首先浏览器会去请求DNS服务器，通过DNS获取相应的域名对应的IP（2）然后通过IP地址找到IP对应的服务器后，要求建立TCP连接（3）浏览器发送完HTTP Request（请求）包后，服务器接收到请求包之后才开始处理请求包（4）在服务器收到请求之后，服务器调用自身服务，返回HTTP Response（响应）包（5）客户端收到来自服务器的响应后开始渲染这个Response包里的主体（body），等收到全部的内容随后断开与该服务器之间的TCP连接。\n","tags":["面试题"]},{"title":"请你谈谈网站是如何进行访问的","url":"/2022/04/12/%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E8%AF%B7%E4%BD%A0%E8%B0%88%E8%B0%88%E7%BD%91%E7%AB%99%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E8%AE%BF%E9%97%AE%E7%9A%84/","content":"\n输入一个域名；回车 \n检查本机的 C:\\Windows\\System32\\drivers\\etc\\hosts配置文件下有没有这个域名映射；\n\n\n有：直接返回对应的ip地址，这个地址中，有我们需要访问的web程序，可以直接访问\n没有：去DNS服务器找，找到的话就返回，找不到就返回找不到；\n\n\n","tags":["面试题"]},{"title":"改善深层神经网络：超参数调试、正则化以及优化第一周检测","url":"/2021/08/10/%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AC%AC%E4%B8%80%E5%91%A8%E6%A3%80%E6%B5%8B/","content":"答案见下方\n1.如果你有10,000,000个例子，你会如何划分训练&#x2F;开发&#x2F;测试集？A.33%训练，33%开发，33%测试\nB.60%训练，20%开发，20%测试\nC.98%训练，1%开发，1%测试\n2.开发和测试集应该：A.来自同一分布\nB.来自不同分布\nC.完全相同（一样的(x, y)对）\nD.数据数量应该相同\n3.如果你的神经网络方差很高，下列哪个尝试是可能解决问题的？A.添加正则项\nB.获取更多测试数据\nC.增加每个隐藏层的神经元数量\nD.用更深的神经网络\nE.用更多的训练数据\n4.你正在为苹果，香蕉和橘子制作分类器。 假设您的分类器在训练集上有0.5％的错误，以及开发集上有7％的错误。 以下哪项尝试是有希望改善你的分类器的分类效果的？A.增大正则化参数λ\nB.减小正则化参数λ\nC.获取更多训练数据\nD.用更大的神经网络\n5.什么是权重衰减？A.正则化技术（例如L2正则化）导致梯度下降在每次迭代时权重收缩\nB.在训练过程中逐渐降低学习率的过程\nC.如果神经网络是在噪声数据下训练的，那么神经网络的权值会逐渐损坏\nD.通过对权重值设置上限来避免梯度消失的技术\n6.当你增大正则化的超参数λ时会发生什么？A.权重变小（接近0）\nB.权重变大（远离0）\nC.2倍的λ导致2倍的权重\nD.每次迭代，梯度下降采取更大的步距（与λ成正比）\n7.在测试时候使用dropout：A.不随机关闭神经元，但保留1&#x2F;keep_brob因子\nB.随机关闭神经元，保留1&#x2F;keep_brob因子\nC.随机关闭神经元，但不保留1&#x2F;keep_brob因子\nD.不随机关闭神经元，也不保留1&#x2F;keep_brob因子\n8.将参数keep_prob从（比如说）0.5增加到0.6可能会导致以下情况（选出所有正确项）：A.正则化效应被增强\nB.正则化效应被减弱\nC.训练集的误差会增加\nD.训练集的误差会减小\n9.以下哪些技术可用于减少方差（减少过拟合）？（选出所有正确项）A.梯度消失\nB.数据扩充\nC.Dropout\nD.梯度检查\nE.Xavier初始化\nF.L2正则化\nG.梯度爆炸\n10.为什么要对输入x进行归一化？A.让参数初始化更快\nB.让代价函数更快地优化\nC.更容易做数据可视化\nD.是另一种正则化——有助减少方差\n\n答案：\nC\nA\nAE\nAC\nA\nA\nD(dropout只用在训练集上，目的是在每层添加噪声，降低对权重的依赖，从而防止过拟合。但是测试的时候不能用dropout，否则会影响评估.)\nBD(在编写tensorflow程序的时候，会发现训练的时候dropout的参数keep_prob&#x3D;0.8（0.5,0.9等等），在测试的时候keep_prob&#x3D;1.0，即不进行dropout。)\nBCF\nB\n\n","tags":["深度学习"]},{"title":"改善深层神经网络：超参数调试、正则化以及优化第二周检测","url":"/2021/08/10/%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%AC%AC%E4%BA%8C%E5%91%A8%E6%A3%80%E6%B5%8B/","content":"答案见下方\n1.当输入从第8个mini-batch的第7个的例子的时候，你会用哪种符号表示第3层的激活？A.a^ [3]{8}(7)\nB.a^ [8]{7}(3)\nC.a^ [8]{3}(7)\nD.a^ [3]{7}(8)\n2. 关于mini-batch的说法哪个是正确的？A.mini-batch迭代一次（计算1个mini-batch），要比批量梯度下降迭代一次快\nB.用mini-batch训练完整个数据集一次，要比批量梯度下降训练完整个数据集一次快\nC.在不同的mini-batch下，不需要显式地进行循环，就可以实现mini-batch梯度下降，从而使算法同时处理所有的数据（矢量化）\n3.为什么最好的mini-batch的大小通常不是1也不是m，而是介于两者之间？A.如果mini-batch的大小是1，那么在你取得进展前，你需要遍历整个训练集\nB.如果mini-batch的大小是m，就会变成批量梯度下降。在你取得进展前，你需要遍历整个训练集\nC.如果mini-batch的大小是1，那么你将失去mini-batch将数据矢量化带来的的好处\nD.如果mini-batch的大小是m，就会变成随机梯度下降，而这样做经常会比mini-batch慢\n4.如果你的模型的成本J随着迭代次数的增加，绘制出来的图如下，那么：\nA.如果你正在使用mini-batch梯度下降，那可能有问题；而如果你在使用批量梯度下降，那是合理的\nB.如果你正在使用mini-batch梯度下降，那看上去是合理的；而如果你在使用批量梯度下降，那可能有问题\nC.无论你在使用mini-batch还是批量梯度下降，看上去都是合理的\nD.无论你在使用mini-batch还是批量梯度下降，都可能有问题\n5.假设一月的前三天卡萨布兰卡的气温是一样的：一月第一天: θ1&#x3D;10一月第二天: θ2&#x3D;10,假设您使用β&#x3D;0.5的指数加权平均来跟踪温度：v0&#x3D;0,vt&#x3D;βv_t−1+(1−β)θ_t。如果v2是在没有偏差修正的情况下计算第2天后的值，并且v2corrected是您使用偏差修正计算的值。 这些下面的值是正确的是？\nA.v2&#x3D;10,v2corrected&#x3D;10\nB.v2&#x3D;10,v2corrected&#x3D;7.5\nC.v2&#x3D;7.5,v2corrected&#x3D;7.5\nD.v2&#x3D;7.5,v2corrected&#x3D;10\n6.下面哪一个不是比较好的学习率衰减方法？A.α&#x3D;1&#x2F;(1+2∗t) α0\nB.α&#x3D;1&#x2F;sqrt(t) α0\nC.α&#x3D;0.95^ t α0\nD.α&#x3D;e^ t α0\n7.您在伦敦温度数据集上使用指数加权平均， 使用以下公式来追踪温度：vt&#x3D;βv_t−1+(1−β)θt。下图中红线使用的是β&#x3D;0.9来计算的。当你改变β时，你的红色曲线会怎样变化？（选出所有正确项）\nA.减小β，红色线会略微右移B.增加β，红色线会略微右移C.减小β，红线会更加震荡D.增加β，红线会更加震荡\n8.下图中的曲线是由：梯度下降，动量梯度下降（β&#x3D;0.5）和动量梯度下降（β&#x3D;0.9）。哪条曲线对应哪种算法？\nA.(1)是梯度下降；(2)是动量梯度下降（β&#x3D;0.9）；(3)是动量梯度下降（β&#x3D;0.5）\nB.(1)是梯度下降；(2)是动量梯度下降（β&#x3D;0.5）；(3)是动量梯度下降（β&#x3D;0.9）\nC.(1)是动量梯度下降（β&#x3D;0.5）；(2)是动量梯度下降（β&#x3D;0.9）；(3)是梯度下降\nD.(1)是动量梯度下降（β&#x3D;0.5）；(2)是梯度下降；(3)是动量梯度下降（β&#x3D;0.9）\n9.假设在一个深度学习网络中，批量梯度下降花费了大量时间时来找到一组参数值，使成本函数J(W[1],b[1],…,W[L],b[L])小。以下哪些方法可以帮助找到J值较小的参数值？A.令所有权重值初始化为0\nB.尝试调整学习率\nC.尝试mini-batch梯度下降\nD.尝试对权重进行更好的随机初始化\nE.尝试使用 Adam 算法\n10.关于Adam算法，下列哪一个陈述是错误的？A.Adam结合了Rmsprop和动量的优点\nB.Adam中的学习率超参数α通常需要调整\nC.我们经常使用超参数的“默认”值β1&#x3D;0,9,β2&#x3D;0.999,ϵ&#x3D;10−8\nD.Adam应该用于批梯度计算，而不是用于mini-batch\n\n答案：\nA\nC\nBC\nB\nD\nD\nBC\nB\nBCDE\nD\n\n","tags":["深度学习"]},{"title":"深度学习 day01 深度学习概论","url":"/2021/07/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day01%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/","content":"01 什么是神经网络深度学习指的是训练神经网络\n\n\nReLU（修正线性单元）函数：修正指的是取不小于0的值。下图就是根据这个函数画的单神经元网络。\n\n\n\n下面是有更多特征时的神经网络：神经网络的一部分神奇之处在于不管训练集多大，只要输入x就能得到输出y，所有的中间过程都是自己完成的。神经网络你自己决定中间这个节点是什么，我们只给你四个输入特征随便你怎么计算，因此在神经网络中，输入层在中间层连接数是很高的。\n\n\n02 用神经网络进行监督学习\n下面是神经网络创造价值的一些案例：对于图像领域一般使用CNN（卷积神经网络）；对于序列数据经常使用RNN（循环神经网络），其中语言最自然的表示方式也是序列；而对于复杂的应用就需要更加复杂的混合神经网络结构\n\n\n\n下图分别是：标准神经网络、卷积神经网络、循环神经网络\n\n\n\n机器学习被应用于结构化数据和非结构化数据：结构化数据是数据的数据库；非结构化数据就好比语音、图像、自然语言。\n\n\n03 为什么深度学习会兴起？\n下面是训练带有标签样本的不同的算法，随着数据量的增加各个算法的表现变化。可以看出神经网络比其他算法要好得多。\n\n\n\n提升计算速度：左图通过改变算法使得代码运行更快。比如说下图机器学习中的sigma函数在两端的区域梯度会接近于0，这样学习将会变得特别缓慢（梯度下降算法中参数更新的慢当然学习也就慢）。通过改变激活函数，神经网络用ReLU函数，它的梯度对于所有为正值的输入，输出都为1。右图通过加快计算速度从而加快迭代的速度（转一圈需要的时间）来使效率提升。\n\n\n","tags":["深度学习"]},{"title":"深度学习 day02 03 神经网络基础","url":"/2021/07/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day02%2003%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/","content":"01 二分分类\n逻辑回归是一个用于二分分类的算法\n计算机保存一张图片就需要保存三个独立矩阵，分别对应图片中的红、绿、蓝三个颜色通道，如果照片是64×64像素的就有三个64×64的矩阵。然后需要将这三个矩阵所有元素都存放在特征x向量中（x向量就是64×64×3&#x3D;12288维）。\n\n\n\n输入X用矩阵表示：python中用来输出矩阵的维度代码是X.shape&#x3D;(n,m)，表示X是一个n×m的矩阵。\n\n02 逻辑回归\n当你实现逻辑回归时，你要做的就是学习参数w和b。因为要求输出y帽是在0到1之间，所以我们将输入x的线性函数w^T+b带入到sigma函数中，得到sigma函数。当z很大时输出接近于1，当z很小时输出接近于0。\n\n\n03 逻辑回归损失函数\n损失函数又叫误差函数可以用来衡量算法在单个训练样本运行情况，在这里我们不用第一个式子，我们用第二个损失函数，因为在逻辑回归中如果使用第一个式子，最终会得到很多个局部最优解，梯度下降法可能找不到局部最优值（非凸），而使用第二个就会给我们一个凸的优化问题。\n\n\n\n成本函数基于参数的总成本，衡量的是w和b在全体训练样本上的表现\n\n\n04 梯度下降法\n我们想要找到参数w和b来使成本函数最小，我们可以随机初始化参数，梯度下降法就是从初始点开始沿着最陡的下坡方向走一步，不断地进行迭代最终达到全局最小点。\n\n\n\n下面是参数更新的过程，无论参数w在哪一边，他都会向成本函数最小值方向前进，并且可以看出随着w的的变化，函数的斜率也是不断地减小，随着斜率的减小，w变化幅度也就随之减小（也就是朝着成本函数最小值方向移动的越慢）。\n\n\n05 计算图\n一个神经网络的计算都是按照前向或者反向传播过程来实现的，首先计算出神将网络的输出，紧接着进行一个反向传输操作（我们用来计算出对应的梯度或者导数）。\n从左到右的过程，可以计算出J的值。\n\n\n06 计算图的导数计算\n当计算所有这些导数时，最有效率的办法就是从右到左计算，跟着红色的箭头走，我们第一次计算对v的导数在之后计算对a的导数就可以用到，同样的对u的导数的计算在之后计算b的导数时就可以用到。他这个计算导数是，计算哪个导数就对那个值进行一些增加，看看他对J是如何影响的，使用微积分的链式法则就可以算出其导数。\n\n\n\n07 逻辑回归中的梯度下降法\n该样本的偏导数流程图：\n\n\n\n单个样本实例的一次梯度更新步骤：想要计算损失函数L的导数，首先我们要向前一步先计算损失函数关于变量a的导数（da），再向后一步计算出损失函数关于z的导数（dz），最后就是计算出dw、db了，就可以进行更新参数更新了。（更新w&#x2F;b为b减去学习率乘以dw&#x2F;db）\n\n\n08 m个样本的梯度下降\n全局成本函数是从1到m项损失函数和的平均&#x3D;&#x3D;&gt;根据这个我们可以推导出全局成本函数对w1的导数也同样是各项损失函数对w1导数的平均。所以真正需要做的就是计算这些导数并且求平均，这样会得到全局梯度值，能够直接将其应用到梯度下降算法中。\n\n\n\n首先让我们初始化，接着我们要使用for循环来遍历训练集，并计算相应的每个训练样本的导数，然后将他们加起来。（这里有两个循环：第一个是遍历训练集，第二个是遍历所有特征）\n\n\n09 向量化\n向量化技术可以使代码摆脱这些显式的for循环，会帮助处理更大的数据集。\n可扩展深度学习实现是在GPU（图像处理单元）上做的，但是课程是在Jupyter Notebook做的，仅用CPU。CPU和GPU都有并行化的指令有时候也叫做SIMD指令（单指令流多数据流，这个意思是如果你使用了能去掉显式for循环的函数，这样python的numpy能充分利用并行化去更快的计算）\n下图是一个非向量化与向量化实现的对比：\n\n\n\n下面是通过python来实际进行操作，对比非向量化与向量化实现：\n\n\n10 向量化更多的例子\n依旧是非向量化与向量化前后对比：往往python中一个内置函数就搞定\n\n\n\n式子进行去掉一个for循环的写法：\n\n\n11 向量化逻辑回归向量化是如何实现在逻辑回归的上面的。这样可以同时处理整个训练集来实现梯度下降法的一步迭代，不需要任何显示的for循环。\n\n\n不需要显式的for循环就可以从m个训练样本中一次性计算出z和a，这就是正向传播一步迭代的向量化实现（同时处理所有M个训练样本）。\n\n\n12 向量化逻辑回归的梯度输出用向量化同时计算m个训练数据的梯度\n\n\n不使用for循环来计算参数的更新\n\n\n\n用高度向量化实现一个逻辑回归\n\n\n13 python中的广播广播技术是一种能使python和Numpy部分代码更高效的技术\n\n\n用两行代码求出每个元素所占列的百分比：第一行代码求出列的总和，第二行代码求出百分比。其实reshape有些多余，因为已经知道了cal是一行四列的向量了，但是为了确保正确还是用了。\n\n\n\n\n在实现神经网络算法时主要用到的广播形式\n\n\n\n14 关于python&#x2F;numpy向量的说明\n当你实现神经网络的逻辑回归时就不要用这些秩为1的数组\n每次创建数组时，要将其定义为列向量或者行向量\n如果不确定一个向量的具体维度是多少，就用assert()进行声明，确保这是一个向量\n如果由于某种原因得到了一个秩为1的数组就用reshape转换成一个列向量和行向量行为的数组\n\n\n15 逻辑回归损失函数的解释\n损失函数的表达式：\n\n\n\n总体成本函数表达式：\n\n\n","tags":["深度学习"]},{"title":"深度学习 day04 浅层神经网络","url":"/2021/08/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day04%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","content":"01 神经网络概览\n在这里用[ l ]来表示神经网络的第l层，用来跟( i )表示的第几个训练样本做区分。神经网络需要反复的计算z和a。\n\n\n02 神经网络表示\n只有一个隐藏层的神经网络：分为输入层、隐藏层、输出层。其中输入层和输出层的值都是在训练集中能看到的，隐藏层的值不能看到。在计算神经网络层数时是不算输入层的，同时我们使用a^[ l ]表示符号，a也代表激活的意思，它意味着网络中不同层的值会传递给后面的层，即每一层都会产生激活值，我们将这些激活值用a^[ l ]_i表示（l表示第几层，下标i表示层中的第几个节点）。在本例中w参数是（4，3）维的，其中4代表四个隐藏单元，3代表有三个输入特征\n\n\n03 计算神经网络的输出神经网络的输出究竟是如何算出来的\n\n\n这里的圆圈代表逻辑回归计算的两个步骤，神经网络只不过是计算这些步骤很多次（隐藏层的每一个节点都计算一次）。\n\n\n\n下面把这四个等式向量化：向量化时的一条经验法则就是当我们在一层中有不同的节点，那就纵向的堆叠起来（例如a^[1]就是a^[1] _1~a^[4] _ 4这些激活值的堆叠）。\n\n\n\n计算出四个隐藏层中的逻辑回归单元使用的是前两个等式，计算出输出层的逻辑回归用的是后两个等式\n\n\n04 多个例子中的向量化\n对于新的符号a^[2] (i)：这个i表示训练样本i。下面是没有向量化的实现并且想要计算所有训练样本的预测：\n\n\n\n下面将for循环变成向量化实现：将这些向量横向堆叠起来。\n\n\n\n总结一下就是横向堆叠对应的是不同的训练样本，竖向堆叠的是不同的输入特征（也就是一层中不同的节点）。\n\n05 向量化实现的解释\n为什么z^[1]&#x3D;w^[1]x+b^[1]?\n\n\n\n如果将输入成列向量堆叠，那么在方程运算之后，也能得到成列对堆叠的输出。右上图是在单个训练样本中实现正向传播算法就是从1循环到m，右下图第一行代码可以对所有m个例子同时向量化，类似的右下图这四行代码都是上面四行代码正确的向量化形式。\n\n\n06 激活函数搭建神经网络，你可以选择在隐藏层用哪个激活函数，在输出层用哪个激活函数。\n\n\n一些其他的激活函数：【1】tanh函数（双曲正切函数）范围在-1到1之间。如果让函数g(z)&#x3D;tanh(z)，这几乎总比sigma函数效果好，因为现在函数输出介于-1和1之间，激活函数的平均值就更接近0。使用tanh也有类似数据中心化的效果，使得数据的平均值接近0而不是0.5，这使得下一层的学习更方便。几乎tanh函数在所有场合都适用，但是在输出层例外，因为如果输出层y是0或1，那么肯定要介于0和1之间，于此同时在二元分类就可以使用sigma函数作为输出层了。tanh函数和sigma函数都有一个缺点：当z特别大或者特别小时，函数的斜率可能就很小，这样会拖慢梯度下降算法。【2】ReLU函数（修正线性单元），ReLU的好处在于对很多z空间激活函数的斜率和0差很远。在实践中使用ReLU函数，你的神经网络的学习速度通常会比使用tanh或者sigma激活函数快很多，主要是ReLU没有这种斜率接近0时减慢学习速度的效应。\n\n\n\n选择激活函数的经验：如果在做二元分类，输出值是0和1，那么选择sigma函数作为输出层的激活函数，然后其他所有单元都用ReLU。一般不使用sigma函数，因为tanh函数比他更适用，ReLU是默认的激活函数，不知道选谁就选它。如果实在不知道选择哪个激活函数，就在验证集或者开发集上跑跑，看看哪个效果好就选择哪个。\n下面是四种激活函数（最后一个是ReLU的特殊形式叫做带泄露的ReLU）\n\n\n07 为什么需要非线性激活函数？要让你的神经网络能够计算出有趣的函数就必须使用非线性激活函数。\n\n\n如果使用线性激活函数或者叫恒等激活函数，那么神经网络只是把输入线性组合再输出。线性隐层一点用都没有，只有一个地方可以使用线性激活函数g(z)&#x3D;z，就是你的机器学习是回归问题的输出层。\n\n\n08 激活函数的导数当对神经网络使用反向传播的时候，你需要计算激活函数的斜率或者说导数\n\n\nsigma激活函数的导数\n\n\n\ntanh激活函数的导数\n\n\n\nReLU和带泄露的ReLU激活函数的导数\n\n\n09 神经网络的梯度下降法\n输入层有n^[0]个，隐层有n^[1]个，输出层有n^[2]个，还有一个神经网络的成本函数，在二元分类的情况下，成本函数就是1&#x2F;m对损失函数求平均。要训练参数，算法就需要做梯度下降，在训练神经网络时随机初始化参数很重要，而不是全部初始化为0。\n\n\n\n针对于所有样本的前向传播和后向传播：keepdims就是防止python直接输出秩为1的数组（(n,)），确保python输出的是矩阵（(n,1)）。*代表逐个元素乘积。\n\n\n10 直观理解反向传播\n单层神经网络：\n\n\n\n双层神经网络：实现后向传播算法有个技巧，你必须确保矩阵的维度互相匹配。\n\n\n\n反向传播公式小总结：单个样本 | 总样本\n\n\n11 随机初始化对于逻辑回归可以将权重初始化为0，但是如果将神经网络的各参数数组全部初始化为0，再使用梯度下降算法将会完全无效\n\n\n如果将w所有值初始化为0，那么因为两个隐藏单元最开始就在做同样的计算，对输出单元的影响也一样大。那么一次迭代之后，同样的对称性依然存在，两个隐藏单元依然是对称的。无论你神经网络训练多久，两个隐藏单元依然在计算完全一样的函数，所以这种情况多个隐藏单元是没有意义的。当然对多个隐藏单元也适用。\n\n\n\n因此解决这个问题就要随机初始化，通常喜欢将权重初始化成很小的数，因此乘一个0.01（深层就要乘一个0.01以外的数）。因为当使用tanh和sigma激活函数时，如果权重过大就会落到斜率平缓处，导致学习缓慢。\n\n\n","tags":["深度学习"]},{"title":"深度学习 day05 深层神经网络","url":"/2021/08/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day05%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","content":"01 深度神经网络\nL代表的深度神经网络的层数，n^ [l]代表的是l层有多少个节点，a^ [l]代表l层的激活函数，w^ [l]表示在a^ [l]中计算z^ [l]值的权重。\n\n\n02 深层网络中的前向传播\n在深层网络中应用前向传播，图中左侧是针对单个样本的，左侧最后一行a的上标应该是3；右上角就是前向传播的总结公式，右下角是用向量化的方法训练整个训练集。在我们实现前向传播时用for循环，没有比它更好的方法，可以计算1到L层的激活函数。\n\n\n03 核对矩阵的维度\n图的右上角的公式可以帮助检查w和b的维度，反向传播时dw和w具有相同的维度，db和b的维度一样。因为a^ [l] &#x3D; g^ [l] (z^ [l])，所以z和a的维度应该相等。（只针对于没有向量化的）\n\n\n\n向量化后的dw和w，db和b的维度同向量化前的一样，但是Z、A、X的维度会发生变化，右侧是发生的变化。\n\n\n04 为什么使用深层表示\n例如人脸识别，将第一层当成一个特征探测器（边缘探测器），然后将探测到的边缘组合成面部的不同部分（第二层），然后将这些部分组合到一起就可以识别或者探测不同的人脸了。边缘探测器相对来说都是针对照片中非常小块的面积，面部探测器就会针对于大一些的区域，就是从简单到复杂。这种从简单到复杂的金字塔状网络还可以应用于语音识别等领域。\n\n\n\n电路理论：在非正式情况下，能够用电路元件计算的函数可以用相对较小但很深的神经网络来计算（小指的是隐藏单元的数量相对比较少），但是如果用浅一些的神经网络计算同样的函数，会需要呈指数增长的单元数量才能到到同样的计算结果。如下图所示右侧就是单层神经网络，而左侧就是相对较小但很深的神经网络。\n\n\n05 搭建深层网络块\n用作前向传播的正向函数，输入是a^ [l-1]，输出是a^ [l]以及输出到缓存的z^ [l]，用作反向传播的反向函数，输入da^ [l]及之前缓存的z^ [l]，输出da^ [l-1]和dw^ [l]和db^ [l]。\n\n\n\n下面是前向传播和后向传播的流程图，在编程过程中缓存z、w、b可以将这些参数复制到计算反向传播所需要的地方。\n\n\n06 前向和反向传播\n前向传播的步骤：非向量化 | 向量化\n\n\n\n反向传播的步骤：非向量化 | 向量化，右侧第二个不是l-1是l\n\n\n\n总结：初始一个向量化反向传播的方法（右下角那个）\n\n\n07 参数 VS 超参数\n超参数是实际上控制了最后的参数w和b的值，比如说：学习率a、梯度下降法循环的数量、隐层数L、隐藏单元数n^ [l]、以及各种激活函数。这些超参数某种程度上决定了最终得到的w和b。\n\n\n\n不断地尝试超参数的设置，这样才能找到个好的值来完成学习。随着时间的推移，一些电脑硬件或者其他的改变，之前设置好的超参数的值到现在不一定适用，因此一定要勤快点，多试试。\n\n\n08 这和大脑有什么关系\n没啥关系\n\n\n","tags":["深度学习"]},{"title":"深度学习 day06 深度学习的实用层面","url":"/2021/08/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day06%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2/","content":"01 训练 &#x2F; 开发 &#x2F; 测试集\n应用型机器学习是一个高度迭代的过程（想法-&gt;代码-&gt;实现），循环该过程的效率是决定项目进展速度的一个关键因素，创建高质量的训练集、验证集、测试集也有助于提高循环效率。\n\n\n\n随着数据量的不断增加（从1000个样本到1000000个样本），那么验证集和测试集占数据总量的比例会趋向于变得更小。如果数据有一百万，那么就可以选择一万条作验证集，一万条作测试集。因为验证集的目的就是验证不同的算法，检验哪种算法最有效，同样的根据最终选择的分类器，测试集的主要目的是正确评估分类器的性能，选择这么多数据就足够了。（训练集98%，验证集1%，测试集1%）\n\n\n\n总结：现代深度学习的一个趋势：在训练和测试集分布不匹配的情况下进行训练（比如说训练集数据是从网上整下来的，验证集和测试集是用户上传的），针对于这种情况要确保验证集和测试集的数据来自同一分布。最后一点就是没有测试集也没关系（如果不需要无偏估计），如果只有验证集没有测试集，就应该在训练集上训练尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出合适的模型 。\n\n\n02 偏差 &#x2F; 方差关于深度学习的误差问题就是要对偏差、方差的权衡。\n\n\n分为欠拟合（高偏差） | 适度拟合 | 过度拟合（高方差）\n\n\n\n理解偏差和方差的两个关键数据是训练集误差和验证集误差。下面分别是基于人眼误差为0的情况下，高方差 | 高偏差 | 高偏差+高方差 | 低偏差+低方差。（以上分析的前提都是假设基本误差很小，训练集和验证集来自相同分布）如果最优误差（贝叶斯误差）为15%，那么第二组数据就是低偏差+低方差。\n\n\n\n下面用紫色线画出的分类器具有高偏差和高方差，高偏差是因为它几乎是一条线性分类器，并未拟合数据，高方差是因为采用曲线函数或二次函数，灵活性太高以致拟合了这两个错误样本。\n\n\n\n总结：通过分析训练集和验证集验证算法产生的误差来诊断算法是否存在高偏差或者高方差，以此来决定接下来你要做什么\n\n03 机器学习基础\n首先检查偏差，如果偏差过高，甚至无法拟合训练集，那么就需要选择一个新网络（含有更多的隐层或者隐藏单元）；或者花费更多的时间来训练网络（花费更多的时间训练算法或者尝试更先进的优化算法）；或者从多种神经网络架构中选择一种，通常采用规模更大的网络都会有所帮助。不断地重复这些步骤，直到偏差降低到可接受范围。\n一旦偏差降低到可接受的范围，检查下方差有没有问题（评估方差要查看验证集性能），如果方差过高，需要采用更多的数据也许会有帮助；或者通过正则化来减少过拟合；找到更合适的网络架构。\n\n\n04 正则化\n逻辑回归函数中的正则化：L2正则化是最常见的，还有L1正则化，如果使用L1正则化，w最终会是稀疏的（w向量中有很多0）。在python中我们使用lambd来代替lambda正则化参数。\n\n\n\n神经网络实现L2正则化：字母L代表神经网络的层数\n\n\n05 为什么正则化可以减少过拟合？\n直观的理解就是lambda增加到足够大，w会接近于0，在这个过程中她会出现拟合正合适的情况，逐渐的会变成高偏差。直觉上我们会认为大量的隐藏单元被完全消除了，实际上依然存在，只是他们的影响变得更小了。\n\n\n\n假设我们用的是tanh()函数，z在很小的范围内，图像是呈线性的，如果z变得更大或者更小，图像将呈非线性。如果神经网络每层都是线性的，那么整个网络就是线性网络，最终我们只能计算线性函数，因此它不适合非常复杂的决策。总结：如果正则化参数变得很大，参数w很小，z也会相对变小，整个神经网络会计算离线性函数近的值，这个线性函数非常简单不会发生过拟合。\n还有一点值得注意：为了调试梯度下降，一定要使用新定义的J函数，它包含了第二个正则化项，否则函数J可能不会在所有调幅范围内都单调递减。\n\n\n06 Dropout正则化\nDropout（随机失活）工作流程：假设左图存在过拟合，dropout会遍历网络的每一层，并设置消除神经网络中节点的概率（每一个节点都以抛硬币的方式设置概率即每个节点得以保留和消除的概率都是0.5），我们在消除一些节点的同时也会删除该节点进出的连线，最后得到一个节点更少、规模更小的网络。\n\n\n\n如何实施dropout：inverted dropout（反向随机失活）-&gt;首先定义一个向量d，d^ 3表示一个三层的dropout向量；然后看它是否小于某个数（keep-prob），keep-prob表示保留某个隐藏单元的概率，它的作用就是生成随机矩阵，这个d3就是个布尔类型的数组，值为1或者0；接下来是从第三层中获取激活函数（a3），a3等于上面的a3与d3元素相乘，它的作用就是过滤d3中所有等于0的元素，而各个元素等于0的概率只有20%；最后向外扩展a3，通过除以keep-prob来确保a3的期望值不变，假设预期a^ [3]预期减少20%，为了不影响z^ [4]的期望值，就需要用w^ [4]*a^ [3]除以0.8，它将会修正我们所需的那20%。\n\n\n\n我们在测试阶段不使用dropout，因为在测试阶段我们不期望输出的结果是随机的。测试阶段不同于训练阶段，即使在测试阶段不执行dropout来调整数值范围，激活函数的预期结果也不会发生变化。\n\n\n07 理解Dropout\n左图中用紫色圈起来的单元，它不能依靠任何特征，因为特征（该单元的输入）都有可能被随机清除。通过为单元的四个输入增加一点权重，Dropout将产生收缩权重的平方范数的效果。实施Dropout的结果是会压缩权重并完成一些预防过拟合的外层正则化。Dropout的功能类似于L2正则化，与L2正则化不同的是：被应用的方式不同，Dropout也会有所不同，甚至更适用于不同的输入范围。为了预防矩阵的过拟合，对权重最大的矩阵（例如右图的w^ [2]&#x3D;7×7）的那一层，keep-prob值应该相对较低，而且每一层的keep-prob值都有可能不同，如果某一层keep-prob为1，那么就不对这层使用Dropout。\n在计算机视觉领域由于通常没有足够的数据，所以一直存在过拟合，所以Dropout在这是很热门的。Dropout的一个大缺点就是代价函数J不被明确定义，为了绘制学习曲线确保每次迭代都是呈下降趋势，通常会关闭Dropout函数，然后运行代码确保J函数单调递减，最后在打开Dropout。\n\n\n\n总结：如果你担心某些层比其他层更加容易过拟合，那么就将某些层的keep-prob值设置相对较低，缺点是为了使用交叉验证，需要搜索更多的超级参数。另一种方案是一些层用Dropout，一些层不用，应用的层只含有一个超级参数就是keep-prob\n\n08 其他正则化方法\n数据扩增可以作为正则化方法使用：对图片进行水平翻转，扩大裁剪，对数字进行扭曲等操作。\n\n\n\nearly stopping代表提前停止训练神经网络。我们在绘制验证集误差时会发现。验证集误差通常会呈下降趋势，然后在某一节点开始上升，因此在迭代的过程中选择中间w的值（就是那个拐点），early stopping的优点是只运行一次坡度下降，就可以找到w的较小值、中间值和较大值，而无需尝试L2正则化超级参数lambda的很多值。\n\n\n09 正则化输入训练神经网络，其中一个加速训练的方法就是归一化输入：归一化的目的就是让特征值保持在相似的范围内\n\n\n归一化输入有两个步骤：第一步是零均值化（左下公式）变为第二个图，第二步是归一化方差（右下公式）变为第三个图，第二个图的x_1的方差明显比x_2的方差要大-&gt;第三个图x_1的方差和x_2的方差一样大。我们希望不论是训练数据还是测试数据都是通过相同的u和sita^ 2定义的相同数据转换，其中u和sita^ 2是由训练集数据计算得出的。\n\n\n\n如果使用非归一化特征（特征值不在一个相似的范围内），会得到一个非常细长狭窄的代价函数（左图）并且需要的学习率也要小，如果归一化特征后（特征值处于相似范围内），代价函数看起来更加的对称（右图）而且设置的学习率可以较大。如果特征的范围都很相似，那么将对优化算法很有利（下方x的取值），否则不利（上方x的取值）。\n\n\n\n总结：如果特征值不在一个相似的范围内，那么归一化将会显得格外重要，如果特征值处于相似范围内，那么归一化就不是很重要了。\n\n10 梯度消失与梯度爆炸当你训练神经网络时，导数或者坡度有时会变得非常大或者非常小，甚至以指数方式变小，这加大了训练难度。我们应更加明智的选择随机初始化权重，从而避免这个问题。\n\n\n该例子中g（z）&#x3D;z，b^ [l]&#x3D;0。当权重w只比1略大一点或者说比单位矩阵大一点，深度神经网络的激活函数将爆炸式增长，如果w比1略小一点，在神经网络中激活函数将以指数级递减。\n\n\n11 神经网络的权重初始化\n神经单元权重初始化：为了防止z值过大或过小，当n越大你希望w_i越小，最合理的方法就是设置w_i&#x3D;1&#x2F;n，其中这里的n代表神经元的输入特征数量，实际上就是设置某层权重矩阵w。如果用的是Relu激活函数而不是1&#x2F;n，方差设置为2&#x2F;n更好。这里用n^ [l-1]是因为一般情况下l层的每个神经元都有n^ [l-1]个输入。\n其他变体函数的公式：Tanh激活函数为右边第一个式子；Relu激活函数是左边画框的；有时也用右边第二个\n\n\n12 梯度的数值逼近梯度检验的作用是确保backprop正确实施\n\n\n单边计算：\n\n\n\n使用双边误差的方法更逼近导数，双边计算出来是3.0001，而单边计算出来是3.0301，可以看出双边更加接近3。\n\n\n13 梯度检验\n首先做些处理：\n\n\n\n为了实施梯度检验，要做的就是循环执行。先将J展开，然后进行循环，我们要验证的就是dsita_approx与dsita这两个向量是否真的接近，一般做下列运算：计算这两个向量的距离（dsita_approx-dsita的欧几里得范数，注意没有平方，它是误差平方之和，然后求平方根得到欧式距离），然后用向量长度做归一化，结果为||dsita_approx-dsita||&#x2F;||dsita_approx||+||dsita||。分母只是用来预防这些向量太小或太大，分母使这个方程式变成比率。如果计算方程式得到的值为10的-7次方甚至更小，这就很好；如果在10的-5次方就要小心了，检查这个向量所有的项确保没有一项误差过大；如果是10的-3那么就要担心是否存在bug了，看看是否有个具体的i值使得dsita_approx与dsita大不相同。\n\n\n14 关于梯度检验实现的注记如何在神经网络实现梯度检验的适用技巧和注意事项\n\n\n不要在训练中适用梯度检验，它只用于调试\n如果算法的梯度检验失败，要检查所有项，并试图找出bug：如果两个向量的值相差很大 ，我们要查找不同的i值，看看是哪个导致的。\n在实施梯度检验时，如果使用正则化，请注意正则项\n梯度检验不能与dropout同时使用：因为每次迭代过程中dropout会随机消除隐层单元的不同子集，难以计算dropout在梯度下降上的代价函数J\n在随机初始化过程中，当w和b接近0时，梯度下降&#x2F;backprop的实施是正确的；但在运行梯度下降时w和b变得更大，也就越来越不准确。这时要做的就是在随机初始化过程中运行梯度检验，然后训练网络，w和b会有一段时间远离0，如果随机初始化值比较小，反复训练网络之后再重新运行梯度检验。\n\n\n","tags":["深度学习"]},{"title":"深度学习 day07 08 优化算法","url":"/2021/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day07%2008%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/","content":"01 Mini-batch 梯度下降法\nX代表训练样本的集合，向量化能够相对较快地处理所有m个样本，但是如果m过大，处理速度仍然缓慢。在对整个训练集执行梯度下降法时，原本是需要处理完所有样本，才能进行一步梯度下降法，然后再重新处理所有样本，才能进行下一步梯度下降，但是如果在处理完所有样本之前，先让梯度下降法处理一部分，那么算法速度将会更快。因此我们可以将训练集分割为小一点地子集（子集就叫Mini-batch ），我们用X^ {t}代表第t个子集，当然Y也需要分割。\n\n\n\n在使用Mini-batch 梯度下降法时，同样要设有一个循环，这个循环是遍历所有的子训练集，同样的也要计算前向传播、代价函数J及执行后向传播来计算J^ {t}的梯度，只使用X^ {t}和Y^ {t}，然后更新权值。这只是遍历了一次训练集，如果还想多次遍历需要使用for或者while。\n\n\n02 理解 mini-batch 梯度下降法\nBatch梯度下降法：成本函数J会随着每次迭代而减小；mini-batch 梯度下降法：由于每次迭代都在训练不同的样本集（X^ {t}和Y^ {t}），所以成本函数J会产生波动，但是总体趋势是下降的。\n\n\n\n决定mini-batch的大小有两种极端的情况：\n\nmini-batch &#x3D; m（整个训练集）–&gt;Batch梯度下降法（如果m很大，则单次迭代耗时太长）\nmini-batch &#x3D; 1–&gt;随机梯度下降法（会失去所有向量化带来的加速，效率过于低下，并且结果永远都不会收敛，会一直在最小值附近徘徊）\n\n\n在这两种极端情况下，成本函数的优化情况：蓝色（Batch梯度下降法），紫色（随机梯度下降法）\n\n所以要选择不大不小的mini-batch尺寸，实际上学习速率达到最快：一方面得到大量向量化，另一方面不需要等待整个训练集被处理完，就可以开始进行后续工作了。当然mini-batch 梯度下降法的结果也都不会收敛，会一直在最小值附近徘徊，这时可以慢慢减小学习率。\n\n\n\n\n那么该如何选择mini-batch尺寸呢：如果训练集较小，直接使用batch梯度下降（m&lt;2000）；如果训练集较大，mini-batch尺寸一般选择在64~512，经常将mini-batch尺寸设成2次方，这样代码会运行的比较快。最后要注意的是在mini-batch中X^ {t}和Y^ {t}要符合CPU&#x2F;GPU内存，如果不相符无论使用什么方法，算法都会表现得急转直下。\n\n\n03 指数加权平均\n计算下面温度散点图的趋势或者是温度的局部平均值或者说移动平均值：首先V_0&#x3D;0，然后运用公式：某天的V等于前一天的V的0.9倍加上当日温度的0.1倍，这样计算后用红线作图就得到了移动平均值&#x2F;每日温度的指数加权平均值。\n\n\n\n大体公式如下所示：在计算平均多少天温度时用1&#x2F;(1-b)来计算，如果b&#x3D;0.9将其带入该式子，可得10也就是十天的平均值，如果b为0.98就是绿色的线为50（平均过去50天的温度），如果b为0.5得到黄色线。b这个参数的大小决定了上一个值得权重。\n\n\n04 理解指数加权平均\n我们首先画一个每天温度得图（右上第一个），然后构建一个指数衰减函数（右上第二个）看sita的系数，sita99就是0.1×0.9、sita98就是0.1×(0.9)^ 2，以此类推画出图。计算V_100就是讲两个图对应的元素相乘然后求和。sita的系数加起来为1或者逼近1，我们称之为偏差修正，正是因为有偏差修正，这才是指数加权平均数。\n\n那么到底需要平均多少天数呢：就是看几天后权重下降到不到当日权重的三分之一（设b等于一个数，他需要多少次方才能达到1&#x2F;e，多少次方用1&#x2F;(1-b)来计算）\n\n\n\n\n如何在实际中执行：看右图就是初始化v，然后直接讲这个v带入公式来更新新的v，不断地更新。注意：左图是&#x3D;，右图是：&#x3D;\n\n\n05 指数加权平均的偏差修正\n如果你在设置b为0.98时不是绿色的线而是起点低的紫色的曲线，那么我们就不要用V_t，而是用V_t&#x2F;(1-b^t)。假如t&#x3D;2，经过计算就是1号和2号数据的加权平均数并除去偏差，随着t的增加，b的t次方接近0，所以当t很大时，偏差修正几乎没有作用，因此当t很大时紫色线基本和绿色线重合了。如果关心初始时期的偏差，那么在刚开始计算指数加权移动平均数的时候，偏差修正能帮助在早期获得更好的估测。\n\n\n06 动量梯度下降法还有一种算法叫Momentum梯度下降法，运行速度几乎总是快于标准的梯度下降算法。基本思想是：计算梯度的指数加权平均数，并用该梯度更新权重。\n\n\nMomentum梯度下降法在第t次迭代过程中，用现有的Mini-batch计算dW、db 。然后通过指数加权平均计算得到dw及db的移动平均数，最后重新赋值权重，这样就可以减缓梯度下降的幅度（即纵轴方向的摆动小了），也可以增加横轴方向的运动速度（红色线）。如果要最小化碗装函数，其中dW、db相当于为你从山上往下滚的球提供了加速度，V_dW、V_db相当于速度。由于β稍小于1，相当于有摩擦力，所以球不会无限的加速下去。\n\n\n\n最后我们看看具体如何计算：就用左边的公式包含1-β，因为右边的公式，如果你最后要调整超参数β，那么就会影响V_dW、V_db，也许还要修改学习率α（α要根据1&#x2F;(1-β)相应变化）。\n\n\n07 RMSprop（均方根）RMSprop也可以加速梯度下降，因为将微分进行平方，最后还使用了平方根所以叫均方根\n\n\n分析这个纵轴幅度大，横轴向前推进的例子，假设纵轴代表参数b，横轴代表参数w，想要减缓b方向的学习同时推进横轴方向的学习，RMSprop算法可以将其实现。同样的RMSprop也会在第t次迭代中计算当下mini-batch的微分dW、db，接着通过计算得到(dw)^ 2及(db)^ 2的加权平均数，在更新参数时也做了些许改动，公式如下：从斜率可以看出纵轴的斜率比横轴的大（dW&gt;db）结果就变为绿色线。同样还可以用一个较大的学习率α来加快学习，而无须在纵轴上垂直方向偏离。为了保证数值能稳定一些，需要确保分母不为0，就要在分母上加一个很小很小的ε。\n\n\n08 Adam算法Adam算法基本就是将Momentum和RMSprop结合在一起\n\n\n使用Adam算法，首先要初始化，接着在第t次迭代中用当前的mini-batch计算dW、db，接下来计算momentum指数加权平均数，然后用RMSprop进行更新，相当于momentum更新了超参数β_1，RMSprop更新了β_2。一般使用Adam算法时要计算偏差修正，最后就可以更新权重了。\n\n\n\n其中有几个超参数：\n学习率α可以尝试一系列的值看哪个有效\nβ_1常用值为0.9，这是dW &#x2F; db的移动平均值也就是加权平均数\nβ_2常用值为0.999，这是(dW)^ 2 &#x2F; (db)^ 2的移动平均值也就是加权平均数\nε建议是10^ -8，但是没有必要设置\n\n\n\n\n09 学习率衰退加快学习算法的一个办法就是随着时间慢慢减小学习率，我们称之为学习率衰退\n\n\n蓝色的是使用同一学习率，而绿色的是随着时间慢慢减小学习率。慢慢减小学习率的本质在于：在学习初期你能承受较大的步伐，但当开始收敛时，小的学习率能让步伐小一些，不必在最小值范围内大幅度摆动。\n\n\n\n可以这样来进行学习率衰退：第一次遍历训练集叫做一代，第二次就是二代。可以将学习率设为（1&#x2F;(1+衰退率* 第几代）*α_0，α_0为初始学习率。如果想使用学习率衰退就需要不断地尝试参数α及超参数衰退率，找到合适的值。\n\n\n\n除了学习率衰减的公式，人们还使用指数衰减等其他公式：其中t代表mini-batch的数字。还会用离散下降，学习率一会减一半一会减一半。当然还可以手动调试学习率（在训练集小的时候）\n\n\n10 局部最优的问题\n在高维度空间更有可能碰到右图的鞍点（导数为0的点），而不会碰到局部最优。\n\n\n\n平稳段会减缓学习。慢慢下降到平稳段，然后在走出平稳段。\n在训练较大的神经网络存在大量参数并且成本函数J被定义在较高的维度空间时，不大可能困在极差的局部最优中。\n平稳段是一个问题，这样使得学习十分缓慢，这也是像Momentum或者是RMSprop或者是Adam这样的算法加快学习算法的地方，让你尽早走出平稳段。\n\n\n","tags":["深度学习"]},{"title":"深度学习 day09 超参数调试、Batch 正则化和程序框架","url":"/2021/08/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day09%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81Batch%20%E6%AD%A3%E5%88%99%E5%8C%96%E5%92%8C%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6/","content":"01 调试处理系统地组织超参调试过程的技巧\n\n\n学习速率是需要调试的最重要的超参数（红色），其次是momentum、mini-batch的大小及隐藏单元（黄色），重要性拍第三位的就是层数、学习率衰减、Adam算法（其余都是）\n\n\n\n如果要调整一些超参数，该如何选择调试值呢？\n在早一代的机器学习算法中（左图），如果有两个超参数，常见的作法是在网格中取样点，然后系统的研究这些数值，然后选择哪个参数效果最好。（参数的数量相对较少时）\n在深度学习领域中（右图）推荐下面做法：随机选择点，然后用随机取的点试验超参数的效果，之所以这么做是因为你 很难提前知道哪个超参数最重要。\n\n\n就举两个极端的超参数，α和ε，无论ε取何值，结果基本都是一样的。对于左边的图来说25个样点，但是α只能尝试五个值，而对于右图，每个样点都是独立的也就是α可以取25个值。\n\n\n\n当你给超参数取值时，另一个惯例就是采用由粗糙到精细的策略，也就是在整个的方格中进行粗略搜索后，发现某个点的效果最好，周围的点效果也不错，这时就可以聚集到这个点周围更小的方格中，在更小的方格中，更加密集的随机取点。\n\n\n02 为超参数选择合适的范围随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺用于探究这些超参数。\n\n\n假设选取隐藏单元的数量n^ [l]，选择范围是从50到100中某点；如果要选取神经网络的层数L，选择范围是从2到4。\n\n\n\n假设你在搜索超参数学习率α，取值范围是0.0001到1，如果沿其随机均匀取值那么90%的数值会落在0.1到1，这样看起来不对，反而用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，而是分别依次取0.0001、0.001、0.01、0.1、1，在对数轴上随机均匀取点，这样每个数值之间都有更多的搜索资源可用。用python实现如下：将超参数设置为10^ r，r取值在a到b之间，其中a与b是通过对最小值和最大值进行对数运算得出。\n\n\n\n另一个棘手的例子就是给β取值，用来计算指数的加权平均值，取0.9就相当于在10个值中取平均值，取0.999相当于在1000个值中取平均，如果想要在0.9到0.999之间进行搜索就不能用线性轴取值，我们要探究的应该是1-β，值在0.001到0.1区间，要做的就是在[-3,-1]里随即均匀的给r取值，就相当于给β取值。为什么不能用线性轴呢？因为β接近1时，任何细微的变化都会产生大影响（1-β），所以在β趋近于1的范围内需要密集的取值。\n\n\n\n即使标尺没有选对也没关系，只要数据足够就影响不大。\n\n03 超参数训练的实践：Pandas VS Caviar组织超参数搜索过程的建议和技巧\n\n\n由于某些情况你的原来设定的超参数不好用了，建议就是每隔几个月至少一次重新测试或评估你的超参数来确保你对数值依然很满意。\n关于如何搜索超参数的问题：\n照看一个模型，对其细心照料（通常是有庞大的数据组，但是没有许多计算资源或者足够的CPU和GPU的情况下），即使它在试验时也可以进行改良。因为没有足够的计算能力，不能在同一时间试验大量的模型，所以要观察它的表现，不断调整学习率。\n同时试验多种模型，一视同仁：你设置一些超参数，就让他自己运行（蓝线），也可以开始一个有着不同超参数设定的不同模型，第二个模型（紫线），第三个模型（红色）等等，最后选择工作效果最好的那个。\n\n\n\n\n04 正则化网络的激活函数Batch归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更稳定，超参数的范围会更庞大，工作效果也很好，也会很容易的训练深层网络。\n\n\n对于逻辑回归和神经网络的归一化输入特征值来说，归一化输入特征是可以加速学习过程的。\n对于深层网络来说：Batch归一化的作用是：对于任何一个隐藏层而言，能够归一化a值以更快速的训练w和b。严格的来说，我们真正归一化的不是a而是z。\n\n\n\n单一隐含层Batch归一化的使用方法：网络中已知有些中间值，如假设有一些隐藏单元值z^ (1)到z^ (m)，接下来要计算平均值，然后计算方差，然后取每个z^ (i)规范化，化为含平均值0和方差1（**(z^ (i)-均值)&#x2F;标准偏差**），为了确保数值稳定这里我们依旧加一个ε。因为隐藏单元有不同的分布可能会有意义（例如在sigmoid激活函数，我们不希望值都集中在线性那），因此我们不想隐藏单元总是含有平均值0和方差1，所以我们开始接下来计算ztilde，其中这里的γ和β是模型的学习参数，然后使用梯度下降算法等方法更新γ和β。如果γ&#x3D;z的分母、β&#x3D;u，那么他就可以精准的转化公式使得z&#x3D;ztilde。\n\n\n\nBatch归一化的作用是它适用的归一化过程不只是输入层，也适用于神经网络中的深度隐藏层。\n\n05 将Batch Norm拟合进神经网络\nBatch归一化是发生在计算z和a之间的，与其应用没有规范过的z^ [i]，不如用经方差和均值归一后的ztilde^ [i]。而且这里的β与用在momentum、Adam、RMSprop里的β不同。可以用任何优化算法来更新参数β和γ，在TensorFlow框架中可以用右下角的函数来实现Batch归一化。\n\n\n\n在实践中，Batch归一化通常和训练集的mini-batch一起使用，应用Batch归一化的方式就是：用第一个mini-batch计算z^ [1]，然后在经Batch归一化得到ztilde^ [1]，再应用激活函数得到a^ [1]，然后再一直运行下去。再用第二个mini-batch，直到用完。值得注意的一点：使用Batch归一化可以消除参数b，因为mini-batch中增加任何常数，数值都不会变，加上的任何常数都会被均值减法所抵消。\n\n\n\n用Batch归一化来应用梯度下降法-&gt;假设你在使用mini-batch梯度下降法：\n\n\n06 Batch Norm为什么奏效？\nbatch归一化有效的第一个原因是它不仅仅针对输入值，还针对隐藏单元的值，将那一层所有的值通过归一化得到类似范围的值，可加速学习。第二个原因是它可以使权重比你的神经网络更滞后或者更深层（比如第十层相比于第一层的权重更能经受得住变化）。即使存在运行都很好的同一个函数，但你不会希望你的学习算法去发现绿色的决策边界，只看左边的数据的话，可能使得你产生数据改变分布的想法（covariate shift），正如x到y的映射一样，改变下，y也随之改变。\n\n\n\nbatch归一化做的是它减小了这些隐藏值分布变化的数量，就以z^ [2] _1与z^ [2] _1为例，即使它的值改变了，至少他们的均值和方差也会是均值0和方差1，亦或者是由β和γ决定的其他均值与方差。直观来说batch归一化减弱了前层参数的作用与后层参数的作用之间的联系，它使得网络每层都可以自己学习，稍稍独立于其他层，有利于加速整个网络的学习。\n\n\n\nbatch归一化另一个作用就是他有轻微的正则化效果，因为在mini-batch上计算的均值和方差，均值和方差都会有一些小噪音；缩放过程从z^ [l]到ztilde^ [l]也会有些噪音，因为它是用有噪音的均值和方差计算得出的，所以和dropout相似，他往每个隐藏层的激活值上增加了噪音，dropout含几重噪音是因为它以一定概率乘以0或1，batch归一化含几重噪音是因为标准差的缩放和减去均值带来的额外噪音。因为给隐藏单元添加了噪音，迫使后面单元不过分依赖任何一个隐藏单元，因为噪音很小，所以不是巨大的正则化效果，可以将batch归一化和dropout一块使用；dropout的一个特性是mini-batch越大，正则化效果越弱。\n\n\n\n注意：batch归一化一次只能处理一个mini-batch数据\n\n07 测试时的 Batch NormBatch归一化将数据以mini-batch的形式逐一处理，但是在测试时，需要对每一个样本逐一处理\n\n\n我们用m来表示一个mini-batch中的样本数量，在测试过程中不可能将一个mini-batch中所有样本同时处理，所以需要用其他方法得到u和σ^ 2。为了将神经网络应用于测试就需要单独估算u和σ^ 2。在这里我们用指数加权平均来估算（这个平均数涵盖了所有mini-batch），训练l层的每一个mini-batch都会得到一个u值。可以用指数加权平均来追踪在这一层所有mini-batch中所见的σ^ 2的值，也可以用来追踪均值向量的最新平均值，因此在用不同的mini-batch训练神经网络的同时，能够得到你所查看的每一层的u和σ^ 2的平均数的实时数值。\n\n\n\n总结：在训练时u和σ^ 2是在整个mini-batch上计算出来的，但在测试时需要逐一处理样本，方法是根据你的训练集通过运用指数加权平均估算出u和σ^ 2，然后用测试中的u和σ^ 2来进行你所需的隐藏单元z值得调整。\n\n08 Softmax回归Softmax回归能让你在试图识别某一分类时做出预测（识别多种分类）\n\n\n我们用C来表示有几个种类，我们想要输出层单元的数字告诉我们这四种类型中每一个的概率有多大，最后输出一个4*1矩阵。\n\n\n\n让网络做到这一点的标准模型要用到Softmax层以及输出层来生成输出。算出z之后就需要应用Softmax激活函数（这个激活函数对于Softmax层而言有些不同）：首先计算一个适用于每个元素的临时变量t&#x3D;e的z^ [l]次方,然后经过计算得到a^ [l]（t经过归一化使和为1），举例右边：之前我们的激活函数都是接受单行数值输入（例如Sigmoid和ReLU激活函数输入一个实数输出一个实数），Softmax激活函数因为需要将所有可能的输出归一化，所以就需要输入一个向量，最后再输出一个向量。\n\n\n\nSoftmax分类器在没有隐藏层的情况下能后做到的事–线性决策边界，更深层的网络可以学习更复杂的非线性决策边界。\n\n\n09 训练一个Softmax分类器\nhard max函数将概率最大的变为1，其他变为0。soft max函数相对比较柔和，该是多少概率就是多少。值得注意的是：如果C&#x3D;2，那么Softmax实际就变回了逻辑回归。\n\n\n\n怎样训练带有Softmax输出层的神经网络？我们应首先定义损失函数（左边是单个训练样本的损失，右边是整个训练集的损失J），下方是使用向量化实现矩阵大写Y。\n\n\n\n在有Softmax输出层时实现梯度下降法：输出层会计算出z^ [l] ( C * 1维)，然后用Softmax激活函数得到a^ [l]，然后由此算出损失。初始化反向传播所需的关键步骤或者说关键方程是dz那个表达式\n\n\n10 深度学习框架\n深度学习的一些框架及选择框架的标准：一个重要的标准就是便于编程（神经网络的开发、迭代、为产品进行配置），第二个标准是运行速度（特别是训练大数据集），第三个标准是这个框架是否真的开放(长时间开源)。\n\n\n11 TensorFlow\n假设有一个J需要最小化，来使用TensorFlow将其最小化：第一行和第二行是引入库，接下来是将w初始化为0，然后定义损失函数，然后定义train为学习算法（用梯度下降优化器使损失函数最小化），下面的两行是惯用的表达，开启了一个TensorFlow session，接下来是初始化全局变量，然后用TensorFlow评估一个变量，然后运行梯度下降法再输出w。\n\n\n\n现在我们运行梯度下降1000次迭代，然后输出w\n\n\n\nTensorFlow中的placeholder是之后会赋值的变量，这种方法便于将训练数据加入损失方程（feed_dict函数）\n\n\n\nTensorFlow已经内置了所有必要的反向函数，通过内置函数来计算前向函数，它就能自动用反向函数实现反向传播。\n\n\n","tags":["深度学习"]},{"title":"深度学习 day10 机器学习（ML）策略","url":"/2021/08/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day10%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/","content":"01 为什么是ML策略\n当你尝试优化一个深度学习系统时，通常有很多想法可以去试。一些策略或者一些分析机器学习问题的方法可以指引你朝着最有希望的方向前进。\n\n\n02 正交化搭建机器学习系统的挑战之一是可以尝试和改变的东西太多太多（比如：有那么多超参数需要调整）\n\n\n以左边电视为例，正交化指的是电视设计师设置不同的旋钮，使得每个旋钮只能调整一个性质，这样就可以将画面调整到合适的位置。又如右边的车，有方向盘、油门、刹车来分别控制性质，正交化就是这些控制互不影响，能够相互独立。\n\n\n\n要弄好一个监督学习系统，通常需要调节系统的旋钮来确保四件事：\n系统在训练集上得到的结果不错，训练集上 的表现必须通过某种评估达到能接受的程度。（如果你的算法在成本函数上不能很好的拟合训练集，你需要一个旋钮来确保可以调整你的算法，让他更好的拟合训练集，用来调试的旋钮可以训练更大的网络，或者切换到更好的优化算法。）\n系统在开发集上有好的表现（如果发现算法对训练集很好，对开发集的拟合很差，那么就需要一个旋钮，在不影响训练集的同时，使算法更好的拟合开发集，增大训练集可以是另一个可用旋钮。）\n系统在测试集上有好的表现（如果算法对开发集很好，对测试集很差，这就可能意味着对开发集过拟合了，需要往回退一步使用更大的开发集，增大开发集可以是另一个可用旋钮。）\n系统在测试集上系统的成本函数在实际使用中表现令人满意（如果在测试集做的很好，但是无法给客户好的体验，这需要回去改变开发集或成本函数）\n\n\n\n\n03 单一数字评估标准无论是调整超参数或者是尝试不同的学习算法亦或者是在搭建机器学习系统时尝试不同的手段，如果有一个单实数评估标准，它可以快速的告诉你新尝试的手段比之前的手段是好还是坏。\n\n\n比如说识别猫的例子：如果我们用查准率和查全率来评估分类器（查准率：就是这个图是猫的可能性，查全率：实际为猫的图片中有多少被系统识别出来），那么将很难选择出哪个好，哪个不好，因此需要找到一个结合了查准率和查全率新的评估指标F1调和平均数。\n\n\n\n在有个例子就是各个地方的上传误差，最终使用一个平均值来衡量多个分类器，误差越小越好。\n\n\n04 满足和优化指标\n在该例子中，即看重查准率也看重运行时间，这时就可以将查准率和运行时间组合成一个整体评估指标；你也可以选择一个分类器，能够最大限度提升准确度，但必须满足运行时间小于等于100ms，在这种情况下我们说准确度是一个优化指标（想让准确度最大化），运行时间是满足指标（只要达到要求就行，要求以内都一样），这时B就是很好的分类器；如果你要考虑N个指标，有时候选择其中一个指标作为优化指标是合理的，剩下的均为满足指标。右边就是个例子懂了就不用看。\n\n\n05 训练 &#x2F; 开发 &#x2F; 测试集划分\ndev集也叫开发集有时称为保留交叉验证集。机器学习的工作流程是：你尝试很多思路，用训练集训练不同的模型，然后使用开发集来评估不同的思路，然后选择一个去不断地迭代来改善开发集的性能，得到一个满意的成本，然后用测试集去评估。开发集和优化指标构成了靶心，训练的目的就是向靶心靠拢，而设立训练集是加速靠近靶心的速度。\n以一个猫分类器为例，在下面这些区域内运营：\n不推荐：你选择其中4个区域（可随机选取）的数据构成开发集，其他四个区域的数据构成测试集，因为开发集和测试集不在一个分布\n推荐：让二者来源一个分布，将所有数据随机洗牌将其放入开发集和测试集，这样开发集和测试集都有来自八个地区的数据。\n\n\n\n\n\n在设置开发集和测试集，要选择能够反映你未来会得到的数据、认为很重要的数据、必须得到好结果的数据这样的。\n\n06 开发集合测试集的大小\n前两个是早期数据少的时候划分，最后一个是现在数据多的时候划分。\n\n\n\n测试集的目的是完成系统开发之后，测试集可以帮你评估投产系统的性能。方针就是令你的测试集足够大以至于能够以高置信度评估系统整体性能。对于某些应用也许不需要对系统性能有置信度很高的评估，这时不单独分出一个测试集也是可以的，但是不建议，因为你可以使用这组不带偏差的数据来测量系统的性能。\n\n\n07 什么时候该改变开发 &#x2F; 测试集和指标设置开发集和评估指标就像把目标定在某个位置，让你的团队瞄准\n\n\n假设在构建一个猫分类器，使用的指标是分类误差，从图中看是A效果比较好，但是如果A会将色情图片看成猫的图片，用户是不接受的，而B不会将色情图片看成猫的图片，用户比较倾向于B，在这种情况下（原本的错误指标错误的预测算法A是更好的算法）就应该改变评估指标了或者改变开发集和测试集。可以将分类误差指标写成下面Error的形式，这个评估指标的问题是他对色情图片和非色情图片一视同仁，其中修改评估指标的方法是添加个权重w，图片x不是的话w为1，否则为10甚至100，如果希望归一化常数就是w(i)对所有i求和，这样误差仍然在0和1之间。在开发集和测试集中需要你自己将色情图片标记才能使用这个加权函数。评估指标的意义在于准确告诉你已知两个分类器哪一个更适合你的应用。\n\n\n\n这实际上就是个正交化的例子，你想处理机器学习问题时，应该把它切分成独立的步骤：第一步是弄清楚如何定义一个指标来衡量你想要做的事情的表现（就是设置目标），第二步也许就是学习算法针对某个成本函数优化，加入权重还可能要修改归一化常数（如何精确瞄准，命中目标）。\n\n\n\n如果你当前的指标和当前用来评估数据和你真正关心必须做好的事情关系不大，那就应该改变指标或者你的开发测试集。（就好比下面这个图，你一直用网上下载下来的高质量图片训练，结果使用用户上传的质量层次不齐的图片，实际测试你就发现B比A效果好）\n\n\n\n总结：不建议在没有评估指标和开发集时跑太久\n\n08 为什么是人的表现\n当你开始往人类水平努力时，进展很快；但过了一段时间，这个算法表现比人类更好时，那么进展和精确度的提升就变得更慢了，也许它还会越来越好，但是斜率也就越来越平缓。\n\n贝叶斯最优误差一般认为理论上可能达到的最优误差：随着时间的推移，当您继续训练算法时，可能模型越来越大、数据越来越多，但性能无法超过某个理论上限。就是说没有任何办法设计出一个x到y的函数，让他能够超过一定的准确度。\n\n为什么当超越人类表现后，进展就缓慢了？\n\n当超越人类表现后没有太多的空间继续改善了。\n没超越之前可以使用一些工具提升性能，超越之后就没那么好用了。\n\n\n\n\n\n对于人类擅长的任务，只要你的机器学习算法比人类差，你就可以：让人帮助你标记数据，这样就有更多的数据可以给学习算法；人工误差分析：让人类看算法处理的例子，知道错误出在哪，并尝试了解为什么人能作对，算法做错；更好分析偏差和误差。\n\n\n09 可避免偏差可避免偏差：贝叶斯误差或者对贝叶斯误差的估计和训练误差之间的差值\n\n\n你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好，所以从减小偏差和方差的工具来看，重点是减小偏差，你需要做的是比如训练更大的神经网络或者跑久一点梯度下降。你的算法在训练集上的表现和人类水平的表现相近的话，但是开发集和训练集相差较大，就将重心放到减小方差上。\n\n\n10 理解人的表现人类水平误差用来估计贝叶斯误差也就是理论上最低的误差，任何函数不管是现在还是将来能够到达的最低值。\n\n\n医学图像分类的例子：下面是四个不同人的观察的误差值，那么应该如何界定人类水平误差呢？就是那个到达最低的值0.5。\n在定义人类水平误差时，要弄清楚你的目标所在，如果要表明你可以超越单个人类，那么就有理由在某些场合使用1%部署你的系统，如果你的目标是代替贝叶斯误差，那么就使用0.5的比较合适。\n\n\n\n误差分析的例子：第一个无论以哪个为目标，都要减少偏差，技术可以培训更大的网络；第二个无论以哪个为目标，都要减少方差，技术可以使用正则化或者去获得更大的训练集；第三个就是接近人类水平误差，改善空间就比较小了。\n\n\n11 超过人的表现\n如果你的误差已经比一群充分讨论辩论后的人类专家更低，那么依靠人类直觉来判断你的算法还能往什么方向优化就很难了（比如右边的，如果都已经过拟合了，这咋判断）。\n\n\n\n下面的结构化数据都是系统比人做的好的，都有一个数据库。\n\n\n12  改善模型表现\n提高学习算法性能的指导方针：想让一个监督学习算法达到适用要做到：\n你的算法对训练集的拟合很好（可避免偏差很低），可以训练更大的网络或者训练更长时间、使用更好的优化算法、寻找更好的新神经网络架构或者更好的超参数、改变激活函数或者层数或者隐藏单位数。\n在训练集做的好推广到开发集和测试集也要好（方差不是太大），可以正则化或者收集更多训练数据、寻找更好的新神经网络架构\n\n\n\n\n\n","tags":["深度学习"]},{"title":"深度学习 day11 机器学习（ML）策略","url":"/2021/08/19/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day11%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88ML%EF%BC%89%E7%AD%96%E7%95%A5/","content":"01 进行误差分析人工检查你的算法错误，也许可以让你了解接下来应该做什么，这个过程就叫误差分析\n\n\n同样是一个猫分类器，但是它的准确度只有90%，它会将一些狗的图片识别成猫，如果花费几个月的时间来开发专门研究狗的项目，那是大可不必，因为可能取不到效果。所以我们推荐使用误差分析：我们自己手动的观察100个错误标记的开发集例子，如果只有其中5个是狗的图片，那么就算把识别狗做的很好，误差也高达9.5%，如果其中有50个是狗的图片，这时我们在对识别狗进行完善就可以将误差减半到5%。\n\n\n\n有时在做误差分析时，也可以同时并行评估几个想法，例如猫分类器：\n\n改善针对狗图的性能\n解决针对于猫科动物看做成家猫的错误\n提高画质\n\n\n针对于上面这三个想法我们可以将其记录成下面的表，统计出每个想法占的百分比，在以此判断是否应该提升哪个的性能，提升哪个性能上限比较高。\n\n\n\n\n总结：进行误差分析应该找一组错误标记的例子，可能在开发集或者测试集里，观察错误标记的例子，看看假阳性和假阴性，统计属于不同错误类型的错误数量，可以帮助你发现哪些问题需要优先处理。\n\n02 清楚标注错误的数据  监督学习问题的数据是由输入x和输出标签y组成，通过发现，得知有些输出标签y是错误的，是否值得花时间去修正这些标签呢？\n\n\ny为1是猫，为0不是猫，这时发现倒数第二个是错误标签，该怎么办？\n\n如果是训练集，深度学习算法对于训练集中的随机误差是很宽容的，只要这些错误例子离随机误差不太远，误差足够随机，那么放着这些误差不管可能也没问题。只要总数据集足够大，实际误差可能不会太高。\n如果担心开发集和测试集上标记出错的例子带来的影响，一般建议在误差分析的时候，添加一个额外的列来统计标签y错误的例子数。是否值得修正这6%标记出错的例子呢？如果这些错误标签严重影响了你在开发集上评估算法的能力，那么就应该花费时间去修正错误标签，反之不用。\n建议看三个数字来确定是否值得去人工修正标记出错的数据：整体的开发集误差10%；错误标记引起的错误的数量或者百分比0.6%（10%的6%）；其他原因导致错误的百分比9.4%（10%-0.6%）。对于左边的错误标签没有严重影响了你在开发集上评估算法的能力，而左边的错误标签严重影响了你在开发集上评估算法的能力。\n\n\n\n\n\n\n修正的建议：首先无论使用什么修正手段，都要同时作用到开发集和测试集上（开发集和测试集必须来自相同的分布，因为开发集确定了你的目标，当你击中目标后将算法推广到测试集中，这样你的团队才能更高效）来确保他们继续来自同一分布；其次要同时检验算法判断正确和判断错误的例子，如果你只修正算法出错的例子，你对算法的偏差估计可能会变大，修正错误的例子之后，一些改变可能使原本正确的例子也变成错误的了。但是我们通常不会这么做，因为如果你的分类器很准确，那么判断错的次数比判断正确的次数要小得多；如果你进入到一个开发集和测试集去修正部分标签，你不大可能去修正训练集的，因为训练集数据比开发集和测试集多的多，需要花费的时间也就多。\n\n\n\n总结：在构造实际系统时，通常需要更多的人工误差分析和人类见解，我们要看下犯错误的例子，这样可以帮助找到需要优先处理的任务。\n\n03 快速搭建你的第一个系统，并进行迭代\n一般来说，对于几乎所有的机器学习程序，可能会有50个不同的方向可以前进，并且都是相对合理的可以改善系统，但挑战在于你如何选择一个方向集中精力处理。\n如果你像搭建一个全新的机器学习程序，建议：首先快速设立开发集和测试集还有指标，决定了你的目标所在，如果错了可以在改，但是一定要设立；然后建议马上搭好一个机器学习系统原型（初始系统的全部意义在于有一个训练过的系统可以让你确定偏差和方差的范围，就知道下一步应该优先做什么，能够进行误差分析），然后找训练集进行训练，看效果。开始理解你的算法表现如何，在开发集测试集你的评估指标上表现如何；当你建立第一个系统后，你就可以马上用到偏差方差分析和误差分析。\n\n\n04 在不同的划分上进行训练并测试\n如果你有两个数据来源，一个较小，一个较大，那么该怎么分布？\n第一条路：我们可以将来自互联网和用户的图片结合到一块，然后随机分配到训练、开发和测试集中，这样三个集的数据都来自同一分布，但是坏处在于，对于2500个开发集数据，其中很多图片都是来自网页下载，并不是真正关心的数据分布，真正要处理的是用户上传的，这样设立开发集导致团队针对不同于你实际关心的数据分布去优化。（不要用）\n推荐第二条路：我们训练集是来自互联网的图片，如果需要的话，再加上5000张来自手机上传的图片，对于开发集和测试集都是手机图片，这样的好处在于你现在瞄准的目标就是你想要处理的目标。开发集全部数据都来自用户，可以告诉你的团队这是你真正关心的图片分布，试着搭建一个学习系统，让系统在处理用户图片分布时效果良好。缺点在于你的训练集和开发集、测试集不在一个分布\n\n\n\n以语音激活后视镜为例，对于训练集你可以使用你所拥有的所有语音数据；对于开发集和测试集来说可能要小的多，比如实际上来自语音激活后视镜的数据。按照上面推荐第二条路进行分配。\n\n\n05 不匹配数据划分的偏差和方差当你的训练集和你的开发集、测试集来自不同的分布时，分析偏差和方差的方式可能不一样\n\n\n训练集误差为1，开发集误差为10。如果训练集和开发集来自同一分布，这就存在很大的方差问题，算法不能很好的从训练集出发泛化；但如果你的训练集和开发集来自不同的分布，这时就不能轻易下结论，可能没有方差问题，只不过反映了开发集包括更难准确分类的图片。\n分析的问题在于当你看训练误差再看开发误差有有两件事变了：\n算法只见过训练集数据，没见过开发集数据\n开发集数据来自不同的分布\n\n\n我们设置一个新的数据子集叫训练-开发集，从训练集的分布里随机打散训练集，但是不会用来训练网络。为了进行误差分析，你应该做的是看看分类器在训练集上的误差1%、训练-开发集上的误差9%还有开发集上的误差10%。而训练集和训练-开发集上的差异在于你的神经网络能看到第一部分数据（红色部分）并在上面做训练，但没有在训练-开发集上直接训练，这就告诉算法存在方差。因为训练集上和训练-开发集来自同一分布的数据测得，所以尽管你的神经网络在训练集中表现良好，但无法泛化到来自相同分布的训练-开发集中；又如这三个误差分别是1%、1.5%、10%，这时方差问题就很小了。因为从训练集到训练-开发集误差只上升了一点点，但转到开发集时误差就大了很多，所以这是数据不匹配问题；又如这三个误差分别是10%、11%、12%，这时就存在偏差问题了；又如这三个误差分别是10%、11%、20%，这就有两个问题了：可避免偏差相当高还有数据不匹配问题很大。\n\n\n\n一般的原则，我们要看的关键数据是人类水平误差、训练集误差、训练开发集误差、开发集误差。如果再加一个测试误差，那么测试误差和开发集误差的间距就是你对开发集过拟合的程度。当然也可能出现右边的情况，是因为开发测试集分布比你应用实际处理的数据要容易得多，那么误差可能真的就下降。\n\n\n\n我们以语音激活后视镜为例子，横轴是不同的数据集，竖轴是我们要标记处理数据不同的方式或算法，最后一行放不开了，所以放到了右边。\n\n\n06 定位数据不匹配\n如果发现数据不匹配问题，通常会做误差分析。还是以语音激活后视镜为例，可能要听一下来自开发集的样本，尝试弄清楚开发集和训练集到底有什么不同（比如说开发集的噪音很多）。你可以尝试把训练数据变得更像开发集一点，或者也可以收集更多类似开发集和测试集的数据（比如说发现车辆背景噪音是主要的误差来源，那么就有意识的收集这些数据加到训练集中）。\n\n\n\n如果你的目的是把训练数据变得更像开发集一点，可以使用人工合成数据技术，通过人工合成你可以快速制造更多的训练集。但是人工合成有一个潜在的问题，比如说你在安静的环境下录制了1000小时音频，在移动的车上只录制了1一个小时，当你重复的将这1小时的音频叠加到1000小时音频时，可能你的学习算法对这一小时汽车噪声过拟合。人工数据合成的挑战在于人耳对于1000小时听起来和1小时噪音听起来没什么区别，所以最后可能制造出这个原始数据很少的，在一个小得多的空间子集合成的训练数据。\n\n\n\n总结：如果你认为存在数据不匹配问题，建议做误差分析或者看看训练集和开发集，这两个数据分布到底有什么不同，然后尝试收集看起来像开发集数据做训练。当使用人工合成数据一定要谨慎，你有可能从所有可能性的空间只选了很小一部分去模拟数据。\n\n07 迁移学习深度学习中最强大的理念之一就是有时候神经网络可以从一个任务习得知识，并将这些知识应用到另一个独立的任务中，这就是迁移学习。\n\n\n假设你已经训练好一个图像识别神经网络，然后将这个神经网络拿来让他适应不同的任务（比如放射科诊断），可以做的就是把神经网络最后的输出层和进入到最后一层的权重删掉，然后加上一层或者几层新层，然后为最后一层或几层重新赋予随机权重，然后让它在放射诊断数据上训练。在进行图像识别的训练阶段，可以训练神经网络的所有常用参数、所有权重、所有层，然后就得到了一个能够做图像识别的神经网络，这时要实现迁移学习你要做的就是把数据集换成放射科的（x,y）训练集，而y就是你想要预测的诊断。然后我们随机初始化最后一层的权重w和b。已有语音识别系统神经网络，然后搭建一个触发词（可以唤醒智能设备）的神经网络，过程都同上。\n要用新的数据集重新训练神经网络有几种做法：\n如果你有一个小的数据集，就只训练输出层前的最后一层或者最后两层。\n如果你有很多数据集，那么也许你可以重新训练网络中的所有参数。在图像识别数据的初期训练阶段（预训练），你在用图像识别数据预初始化，然后以后更新所有权重，在放射科数据上训练，有时这个过程叫微调。\n\n\n迁移学习起作用的场合是：迁移来源问题你有很多数据，但迁移目标问题你没有那么多数据。（例如图像识别有一百万样本，可以学习低层次特征，可以在神经网络的前几层学到如何识别有用的特征，放射科数据有一万样本，在已经学习特征的基础上加以训练）数据量反着来的话（例如图像识别有50样本，放射科数据有300样本），就没有太大的意义了。\n\n\n\n假设从任务A学习并迁移一些知识到任务B，那么什么时候迁移学习有意义？\n当任务A和任务B都有同样的输入x（例如A和B输入都为图像）\n当任务A数据比任务B数据多得多的时候\n任务A的低层次特征可以帮助任务B的学习\n\n\n\n\n08 多任务学习在迁移学习中，你的步骤是串行的（从A到B）；在多任务学习中，你可以同时开始学习，试图让单个神经网络同时做几件事，然后希望每个任务都能帮到其他所有任务\n\n\n以无人驾驶为例，需要同时识别多个不同的物体，比如行人、车辆、停车标志还有交通灯，以这四个为例设计出Y。\n\n\n\n现在就可以训练一个神经网络来预测这些y值，输入x，输出的是一个四维向量y。要训练这个神经网络，需要定义神经网络的损失函数，和之前分类猫的例子主要区别在于需要对j&#x3D;1到4求和；这与softmax回归的主要区别在于softmax将单个标签分配给单个样本，而这个例子一张图可以有很多不同标签（行人、车辆、停车标志还有交通灯），所以在该例中你不是只给图片一个标签，而是需要遍历不同类型，然后看看每个类型是否出现在图中。\n如果你训练一个神经网络，并试图最小化这个成本函数，你做的就是多任务学习，由于神经网络早期的一些特征，在识别不同物体时都会用到，你发现训练一个神经网络做四件事会比训练四个完全独立的神经网络分别做四件事性能要更好。\n多任务学习也可以处理图像只有部分物体被标记的情况（右下角Y的情况，不清楚标记？），你就只对带0和1标签的j值求和，如果有？你就在求和时忽略那个项。\n\n\n\n多任务学习什么时候有意义？当三件事为真时，他就是有意义的：\n如果你训练的一组任务可以共用低层次特征，比如无人驾驶例子，同时识别四个标签，因为这些都是道路上的特征。\n不一定对哈，如果你专注于单项任务，想要从多任务学习得到很大性能提升，那么其他任务加起来必须要有比单个任务大得多的数据量或者每个任务的数据量很接近。\n当你可以训练一个足够大的神经网络，同时做好所有的工作。多任务学习的替代方法是训练四个完全独立的神经网络，一个任务对应一个神经网络，如果神经网络足够大，就不用替代。\n\n\n\n\n\n总结：迁移学习用的多\n\n09 什么是端对端的深度学习深度学习中最令人振奋的最新动态之一就是端对端深度学习的兴起，以前有一些数据处理系统或者学习系统，他们需要多个阶段的处理，那么端对端深度学习就是忽略所有这些不同的阶段，用单个神经网络替代它\n\n\n以语音识别为例，需要很多阶段的处理，首先会提取一些特征（MFCC用来从音频中提取一组特定的人工设计的特征），提取完低层次的特征后就可以应用机器学习算法在音频片段中找到音位，然后将音位串在一起构成独立的词，然后将这些词串起来构成音频片段的听写文本；端对端深度学习就是训练一个巨大的神经网络，输入一段音频，输出直接是听写文本。\n端对端深度学习的挑战之一是你可能需要大量数据才能让系统表现良好。小数据集用传统的比较好（3000h）；大的数据集用端对端才好（10000h）；数据量适中也可以用中间件方法。\n\n\n\n搭建人脸识别门禁系统：第一件事是看看相机拍到的照片，你可以直接学习图像x到人物y身份的函数映射（这不是最好的方法，因为人可以从很多不同的角度接近门禁）；迄今为止最好的方法是多步方法，首先运行一个软件来检查人脸，所以第一个检测器找的是人脸位置，找到后裁剪图像使人脸居中，再喂到神经网络里去学习，将现拍的图片跟已存的图片进行对比。为什么两步法更好呢？一是你解决的两个问题，每个问题实际上要简单得多，二是两个子任务的训练数据都很多\n\n\n\n更多的例子：机器翻译，X扫描\n\n\n10 是否要使用端对端的深度学习\n端对端学习的好处：\n只是让数据说话，让你的学习算法学习它想学习的任意表示方法，而不是强迫它使用特定的某种(音位)作为表示方法，其整体表现可能会更好。\n所需手工设计的组件更少，不需要花太多时间去手工设计功能。\n\n\n端对端学习的缺点：\n要直接学x到y的映射，它可能需要大量的数据。\n排除了可能有用的手工设计组件，当没办法从很小的训练集数据中获得洞察力，这时手工设计组件就可以把人类知识直接注入到算法。\n\n\n学习算法有两个主要知识来源：如果数据少就需要用组件，如果数据多就可能不需要\n数据\n手工设计的任何东西（也可能强迫学习算法使用特定的某种(音位)作为表示方法）\n\n\n\n\n\n决定是否使用端对端的深度学习关键的问题是你有足够的数据能够直接学从x映射到y足够复杂的函数吗？\n\n\n\n总之需要大量数据\n\n","tags":["深度学习"]},{"title":"深度学习 day13深度卷积网络：实例探究","url":"/2021/08/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day13%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%EF%BC%9A%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/","content":"01 为什么要进行实例探究？如果有人训练出擅长识别猫狗人的神经网络或者神经网络框架，而你的计算机视觉识别任务是构建一个自动驾驶汽车，你完全可以借鉴别人的神经网络框架来解决自己问题。\n\n\n非常有效的神经网络范例：\n\n\n02 经典网络\nLeNet - 5的网络结构：大约有6万个参数\n\n\n\nAlexNet网络结构：大约有6000万个参数，AlexNet表现出色的原因有两个：一是当用于训练图像和数据集时，AlexNet能够处理非常相似的基本构造模块，这些模块往往包含大量的隐藏单元或数据；二是它使用了ReLU激活函数。\n\n\n\nVGG - 16的网络结构：没有那么多超参数，这是一种只需要专注于卷积层的简单网络。16这个数字代表这个网络包含16个卷积层和全连接层，是个很大的网络，总共包含约1.38亿个参数\n\n\n03 残差网络非常深的网络是很难训练的，因为存在梯度消失和梯度爆炸问题。跳远连接，它可以从某一网络层获取激活，然后迅速反馈给另外一层，甚至是神经网络的更深层，可以用跳远连接构建能够训练深度网络的ResNets。\n\n\nResNets是由残差块构建的。信息流从a[l]到a[l+2]需要经过线性激活-&gt;非线性ReLU激活-&gt;性激活-&gt;非线性ReLU激活这组神经网络的主路径。而在残差网络中有一点变化，我们将a[l]直接向后拷贝到神经网络深层（在线性激活之后，非线性ReLU激活前），这就意味这原来主路经的最后的等式去掉，用另一个ReLU非线性函数来代替。\n\n\n\n把下面普通网络变成ResNets的方法是加上所有的跳远连接，每两层增加一个捷径构成一个残差块。该图就是5个残差块。我们用一个优化算法来训练普通网络的话，训练误差实际上是先减小后增加，随着深度的增加用优化算法越难训练；但是有ResNets的话训练误差就是不断减小。对于x的激活或者这些中间的激活，能够达到网络的更深层，这种方法能有助于解决梯度消失和梯度爆炸问题。\n\n\n04 残差网络为什么有用？通常一个网络深度越深，它在训练集上训练网络的效率会有所减弱\n\n\n如果使用L2正则化或权重衰减，那么它会压缩W[l+2]的值，同样对b应用权重衰退也一样。如果W[l+2]和b都为0，那么a[l+2] &#x3D; a[l]，所以给大型神经网络增加两层，无论是把残差块添加到神经网络的中间还是末端位置，都不会影响网络的表现。\n残差网络起作用的主要原因是这些残差块学习恒等函数非常容易，能确定网络性能不会受到影响，甚至有时还会提高效率。\n假设z[l+2]与a[l]具有相同维度，所以ResNets使用了许多相同卷积，使得a[l]的维度等于输出层的维度，因而实现了这个跳远连接，因为同一卷积保留了维度，所以很容易得出这个短连接，并输出这两个相同维度的向量；如果输入和输出有不同维度，假设输入是128维度，输出是256维度，就需要增加一个Ws（256×128），不需要对Ws做任何操作，它是网络通过学习得到的矩阵或参数，是一个固定矩阵，p&#x3D;0，用0填充a[l]，其维度为256。\n\n\n\n图片识别的普通和ResNet神经网络：\n\n\n\nResNet类似于其他很多神经网络，也会有很多卷积层，其中偶尔会有池化层或者类似池化层的层，不论这些层是什么类型，都需要调整矩阵Ws的维度。\n\n05 网络中的网络以及1 × 1卷积\n从图中可以看出对6×6×1的图使用1×1过滤器进行卷积效果不是很好，就是乘一个数；但是对6×6×32的使用1×1的过滤器进行卷积效果更好，具体来说1×1的过滤器的作用是遍历这36个单元格，计算左图中32个数字和过滤器中32个数字的元素智能乘积，然后应用ReLU非线性函数。\n\n\n\n1×1的卷积层实现一些重要功能：它给神经网络添加了一个非线性函数从而减小或保持输入层中的信道数量不变，当然也可以增加信道。\n\n\n06 谷歌 Inception 网络简介Inception 网络的作用就是代替你来做决定：构建卷积层时，过滤器的大小或者要不要添加池化层\n\n\nInception 网络的核心内容：\n5×5过滤器在该块中的计算成本：乘法运算的总次数为每个输出值所需的乘法运算次数乘以输出值的个数&#x3D;1.2亿。\n1×1卷积的应用：为了降低计算成本，我们用计算成本除以因子10，将它从1.2亿减小到原来的十分之一\n\n","tags":["深度学习"]},{"title":"神经网络和深度学习第一周检测","url":"/2021/07/31/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E5%91%A8%E6%A3%80%E6%B5%8B/","content":"第一周测验 - 深度学习简介\n1.和“AI是新电力”相类似的说法是什么？A: AI为我们的家庭和办公室的个人设备供电，类似于电力。B: 通过“智能电网”，AI提供新的电能。C: AI在计算机上运行，并由电力驱动，但是它正在让以前的计算机不能做的事情变为可能。D: 就像100年前产生电能一样，AI正在改变很多的行业。\n2.哪些是深度学习快速发展的原因？ (两个选项)A:  现在我们有了更好更快的计算能力。B: 神经网络是一个全新的领域。C: 我们现在可以获得更多的数据。D: 深度学习已经取得了重大的进展，比如在在线广告、语音识别和图像识别方面有了很多的应用。\n3.回想一下关于不同的机器学习思想的迭代图。下面哪些陈述是正确的？A: 能够让深度学习工程师快速地实现自己的想法。B: 在更好更快的计算机上能够帮助一个团队减少迭代(训练)的时间。C:在数据量很多的数据集上训练上的时间要快于小数据集。D:使用更新的深度学习算法可以使我们能够更快地训练好模型（即使更换CPU &#x2F; GPU硬件）。\n4.当一个经验丰富的深度学习工程师在处理一个新的问题的时候，他们通常可以利用先前的经验来在第一次尝试中训练一个表现很好的模型，而不需要通过不同的模型迭代多次从而选择一个较好的模型，这个说法是正确的吗？A. 正确B. 错误\n5.用于识别猫的图像是“结构化”数据的一个例子，因为它在计算机中被表示为结构化矩阵，是真的吗？A. 正确B. 错误\n6.统计不同城市人口、人均GDP、经济增长的人口统计数据集是“非结构化”数据的一个例子，因为它包含来自不同来源的数据，是真的吗？A. 正确B. 错误\n7.为什么在RNN（循环神经网络）可以应用机器翻译将英语翻译成法语？A. 因为它可以被用做监督学习。B. 严格意义上它比卷积神经网络（CNN）效果更好。C. 它比较适合用于当输入&#x2F;输出是一个序列的时候（例如：一个单词序列）D. RNN代表递归过程：想法-&gt;编码-&gt;实验-&gt;想法-&gt;…\n8.在我们手绘的这张图中，横轴（x轴）和纵轴（y轴）代表什么?\nx轴是:                       y轴是:\n9.假设上一个问题图中描述的是准确的（并且希望您的轴标签正确），以下哪一项是正确的?A. 增加训练集的大小通常不会影响算法的性能，这可能会有很大的帮助。B. 增加神经网络的大小通常不会影响算法的性能，这可能会有很大的帮助。C. 减小训练集的大小通常不会影响算法的性能，这可能会有很大的帮助。D. 减小神经网络的大小通常不会影响算法的性能，这可能会有很大的帮助。\n答案 1. D 2. AC 3. ACD 4. B(不可能每次都很准确呀) 5. B（看过都知道图片、语音、自然语言都是非结构化的数据） 6. B（注意关键词数据集，可以看出是结构化数据） 7.AC 8. 数据量 算法的性能 9.AB(A是针对一个算法来说，B是针对所有算法并且在同一训练集上而言)\n","tags":["深度学习"]},{"title":"神经网络和深度学习第三周检测","url":"/2021/08/02/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%89%E5%91%A8%E6%A3%80%E6%B5%8B/","content":"答案见下方\n1.以下哪一项是正确的？A. X是一个矩阵，其中每个列都是一个训练示例。B. a^[2]_4 是第二层第四层神经元的激活的输出。C. a^[2] (12)表示第二层的第12个样本的激活向量。D. a^[2] 表示第二层的激活向量。\n2.tanh激活函数通常比隐藏层单元的sigmoid激活函数效果更好，因为其输出的平均值更接近于零，因此它将数据集中在下一层是更好的选择，请问正确吗？A. TrueB. False\n3.其中哪一个是第l层向前传播的正确向量化实现，其中1≤ l ≤LA. Z^ [l]&#x3D;W^ [l]A^ [l−1]+b[l]B. A^ [l]&#x3D;g^ [l] (Z^ [l])\n4.您正在构建一个识别黄瓜（y &#x3D; 1）与西瓜（y &#x3D; 0）的二元分类器。 你会推荐哪一种激活函数用于输出层？A. ReLUB. Leaky ReLUC. sigmoidD. tanh\n5.看一下下面的代码：请问B.shape的值是多少?A = np.random.randn(4,3)B = np.sum(A, axis = 1, keepdims = True)\n\n6.假设你已经建立了一个神经网络。 您决定将权重和偏差初始化为零。 以下哪项陈述是正确的？A. 第一个隐藏层中的每个神经元节点将执行相同的计算。 所以即使经过多次梯度下降迭代后，层中的每个神经元节点都会计算出与其他神经元节点相同的东西。B. 第一个隐藏层中的每个神经元将在第一次迭代中执行相同的计算。 但经过一次梯度下降迭代后，他们将学会计算不同的东西，因为我们已经“破坏了对称性”。C. 第一个隐藏层中的每一个神经元都会计算出相同的东西，但是不同层的神经元会计算不同的东西，因此我们已经完成了“对称破坏”。D. 即使在第一次迭代中，第一个隐藏层的神经元也会执行不同的计算， 他们的参数将以自己的方式不断发展。\n7.Logistic回归的权重w应该随机初始化，而不是全零，因为如果初始化为全零，那么逻辑回归将无法学习到有用的决策边界，因为它将无法“破坏对称性”，是正确的吗？A. TrueB. False\n8.您已经为所有隐藏单元使用tanh激活建立了一个网络。 使用np.random.randn（..，..）* 1000将权重初始化为相对较大的值。 会发生什么？A. 这没关系。只要随机初始化权重，梯度下降不受权重大小的影响。B. 这将导致tanh的输入也非常大，因此导致梯度也变大。因此，您必须将α设置得非常小以防止发散; 这会减慢学习速度。C. 这会导致tanh的输入也非常大，导致单位被“高度激活”，从而加快了学习速度，而权重必须从小数值开始。D. 这将导致tanh的输入也很大，因此导致梯度接近于零， 优化算法将因此变得缓慢。\n9.看一下下面的单隐层神经网络：\nA. b^[1] 的维度是(4, 1)B. W^[1] 的维度是 (4, 2)C. W^[2] 的维度是 (1, 4)D. b^[2] 的维度是 (1, 1)\n10.I在和上一个相同的网络中，Z^ [1] 和 A^ [1]的维度是多少？答：\n\n答案：\nABCD\n\nA\n\nAD\n\nC\n\nB.shape = (4, 1) #keepdims = True）来确保A.shape是（4,1）\n\n\nA\n\nA\n\nD\n\nACD（B应该是（4，3））\n\nZ^ [1] 和 A^ [1]的维度都是 (4,m)(注意z和Z的区别：z表示单个样本，Z表示所有样本)\n\n\n","tags":["深度学习"]},{"title":"神经网络和深度学习第二周检测","url":"/2021/08/01/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%BA%8C%E5%91%A8%E6%A3%80%E6%B5%8B/","content":"1.神经元节点计算什么？A. 神经元节点先计算激活函数，再计算线性函数(z &#x3D; Wx + b)\nB. 神经元节点先计算线性函数（z &#x3D; Wx + b），再计算激活。\nC. 神经元节点计算函数g，函数g计算(Wx + b)。\nD. 在 将输出应用于激活函数之前，神经元节点计算所有特征的平均值\n2.Logistic损失函数表达式的形式？答：\n3.假设img是一个（32,32,3）数组，具有3个颜色通道：红色、绿色和蓝色的32x32像素的图像。 如何将其重新转换为列向量？代码答：\n4.看一下下面的这两个随机数组“a”和“b”：请问数组c的维度是多少？a = np.random.randn(2, 3) # a.shape = (2, 3)b = np.random.randn(2, 1) # b.shape = (2, 1)c = a + b\n\n答： \n5.看一下下面的这两个随机数组“a”和“b”：请问数组“c”的维度是多少？a = np.random.randn(4, 3) # a.shape = (4, 3)b = np.random.randn(3, 2) # b.shape = (3, 2)c = a * b\n\n答： \n6.假设你的每一个实例有n_x个输入特征，想一下在X&#x3D;[x^(1), x^(2)…x^(m)]中，X的维度是多少？答：\n7.看一下下面的这两个随机数组“a”和“b”：请问c的维度是多少？a = np.random.randn(12288, 150) # a.shape = (12288, 150)b = np.random.randn(150, 45) # b.shape = (150, 45)c = np.dot(a, b)\n\n答： \n8.看一下下面的这个代码片段：请问要怎么把它们向量化？# a.shape = (3,4)# b.shape = (4,1)for i in range(3):  for j in range(4):    c[i][j] = a[i][j] + b[j]\n\n答：\n9.看一下下面的代码：请问c的维度会是多少？a = np.random.randn(3, 3)b = np.random.randn(3, 1)c = a * b\n\n答：\n\n答案：\nB（神经元输出的是g(Wx + b)，根据前向传播应该是先计算(Wx + b)，再将其带入到激活函数g中）\n针对于单个训练集的：（误差函数）\n\n![image-20210730152607594](C:\\Users\\1\\Desktop\\深度学习\\深度学习 day02神经网络基础\\image-20210730152607594.png)\n针对于整个训练集的：（成本函数）\n![image-20210730152655792](C:\\Users\\1\\Desktop\\深度学习\\深度学习 day02神经网络基础\\image-20210730152655792.png)3. &#96;&#96;&#96;python   x &#x3D; img.reshape((32323,1))#reshape的作用是重塑数组      4. ```python   c.shape = (2, 3)#根据python的广播原理（B的列向量复制三次与A相加）\n\n直接报错，想广播都广播不了，行和列向量都没有办法复制\n\nX.shape = (n_x,m)\n#这个形式的\nX=[[x_1^(1), x_1^(2)…x_1^(m)]\n   [x_2^(1), x_2^(2)…x_2^(m)]\n   ........................\n   [x_n^(1), x_n^(2)…x_n^(m)]]\n7. ```python   c.shape = (12288, 45)#就是简单的矩阵乘法，dot(n×m , m×v) = n×v \n\n\n&#96;&#96;&#96;pythonc&#x3D; a+b.T#这个就相当于是a的所有元素加上b转置的广播\n9. ```python   c.shape = (3, 3)#这题跟第五题一样，但是这题中b的行数跟a的行数一样，就可以将b的列广播\n\n","tags":["深度学习"]},{"title":"神经网络和深度学习第四周检测","url":"/2021/08/03/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E5%9B%9B%E5%91%A8%E6%A3%80%E6%B5%8B/","content":"答案见下方\n1.在实现前向传播和反向传播中使用的“cache”是什么？A. 用于在训练期间缓存成本函数的中间值。B. 我们用它传递前向传播中计算的变量到相应的反向传播步骤，它包含用于计算导数的反向传播的有用值。C. 它用于跟踪我们正在搜索的超参数，以加速计算。D. 我们使用它将向后传播计算的变量传递给相应的正向传播步骤，它包含用于计算计算激活的正向传播的有用值。\n2.以下哪些是“超参数”？A. 隐藏层的大小n^ [l]B. 学习率αC. 迭代次数D. 神经网络中的层数L\n3.下列哪个说法是正确的？A. 神经网络的更深层通常比前面的层计算更复杂的输入特征。B. 神经网络的前面的层通常比更深层计算输入的更复杂的特性。\n4.向量化允许您在L层神经网络中计算前向传播，而不需要在层(l &#x3D; 1,2，…，L)上显式的使用for-loop（或任何其他显式迭代循环），正确吗？A. 正确B.  错误\n5. 假设我们将n^ [l]的值存储在名为layers的数组中，如下所示：layer_dims &#x3D; [n_x,4,3,2,1]。 因此，第1层有四个隐藏单元，第2层有三个隐藏单元，依此类推。 您可以使用哪个for循环初始化模型参数？答：\n6.下面关于神经网络的说法正确的是：A. 层数L为4，隐藏层数为3\n7.在前向传播期间，在层l的前向传播函数中，您需要知道层l中的激活函数（Sigmoid，tanh，ReLU等）是什么， 在反向传播期间，相应的反向传播函数也需要知道第l层的激活函数是什么，因为梯度是根据它来计算的，正确吗？A. 正确B. 错误\n8.有一些功能具有以下属性：(i) 使用浅网络电路计算函数时，需要一个大网络（我们通过网络中的逻辑门数量来度量大小），但是（ii）使用深网络电路来计算它，只需要一个指数较小的网络。真&#x2F;假？A. 正确B. 错误\n9.前面的问题使用了一个特定的网络，与层l有关的权重矩阵在一般情况下，W^ [l]的维数是多少?答：\n\n答案：\nB\n\nABCD\n\nA\n\nB\n\nfor(i in range(1, len(layer_dims))):\n    parameter[‘W’ + str(i)] = np.random.randn(layers[i], layers[i - 1])) * 0.01\n    parameter[‘b’ + str(i)] = np.random.randn(layers[i], 1) * 0.01\n\n\nA\n\nA(在反向传播期间，您需要知道正向传播中使用哪种激活函数才能计算正确的导数。)\n\nA\n\nw^ [l]的维度是（n^ [l]，n^ [l-1]）\n\n\n","tags":["深度学习"]},{"title":"深度学习 day12卷积神经网络","url":"/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day12%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","content":"01 计算机视觉即使你在计算机视觉方面没有做出成果，希望你可以将所学的知识应用到其他算法和结构\n\n\n计算机视觉的一些例子：图片识别（给出一张图片让计算机去分辨出这是一只猫）、目标检测（首先算出有哪些物体，然后用一些技术识别出他们在图片的位置）、图片风格迁移（就是你有一张满意的图片和一张风格图，你可以用神经网络将他们融合在一起，描绘出一张新的图片，整体轮廓来自左边，风格却是右边的）。\n\n\n\n在应用计算机视觉还有一个很大的挑战就是数据的输入可能会非常大，例如像素是1000×1000的，那么输入的数据就是三百万的数据量，你也许会有1000个隐藏单元，而所有的权值W，如果你使用的是标准的全连接网络，矩阵的大小也是（1000，三百万）也就是会有三十亿个参数。在参数量如此之大的情况下难以获取足够的数据来防止过拟合。如果想要也能计算大型图片就可以使用卷积运算。\n\n\n02 边缘检测示例卷积运算是卷积神经网络最基本的组成部分\n\n\n给一张图片让电脑检测是什么物体，可能做的第一件事是检测图片中的垂直边缘，也可能想检测水平边缘。\n\n\n\n那么如何在图像中检测这些边缘呢？下面是一个6×6的灰度图像，为了检测一个图像的垂直边缘可以构造一个3×3的矩阵（过滤器），卷积运算用*表示，该例中用3×3的过滤器对其进行卷积，输出4×4的矩阵（另一张图片）。4×4的矩阵的元素是将3×3的过滤器覆盖到6×6的灰度图像中，不断地平移得到。不同的语言使用不同的函数代表卷积。\n\n\n\n在下面例子中输出图像中间区域的亮处，表示在图像中间有一个很明显的垂直边缘。\n\n\n03 更多边缘检测内容\n通过不同的过滤器可以找出垂直或者水平的边缘。之前的图里面30是由10过渡到0得到的，所以就是由亮转暗；之前的 30 翻转成了-30，表明是由暗向亮过渡， 而不是由亮向暗过渡，因为看原图是从0到10，所以是从暗到亮的转化。\n\n\n\n水平边缘过滤器如下：\n\n\n\n有多种过滤器：Sobel过滤器（增加了中间一行元素的权重）、Scharr过滤器、还有一种将九个数字都当成参数的思想（已经成为计算机视觉最为有效的思想之一）。\n\n\n04 Padding为了构建深度神经网络，需要学会使用卷积的基本操作Padding\n\n\n可以用公式计算为什么输出是4×4，公式为（n-f+1）×（n-f+1），其中n×n代表原图大小，f×f代表过滤器大小。这样的话会有两个缺点：一是每次做卷积操作，你的图像就会缩小，二是那些在角落或者边缘区域的像素点在输出中采用较少，意味着丢掉了图像边缘位置的许多信息。为了解决这些问题，可以在卷积操作之前填充这幅画（沿着图像边缘再填充一层像素），习惯上可以用0来填充，如果p是填充的数量（该例中p&#x3D;1，因为周围都填充了一个像素点），输出就变成了（n+2p-f+1）×（n+2p-f+1）。\n\n\n\n填充多少像素通常有两个选择：分别叫Valid卷积（不填充）和Same卷积（填充后你的输出大小和输入大小是一样的）。在计算机视觉中过滤器一般都是奇数维，因为如果f为偶数，那么你只能使用一些不对称填充，只有f为奇数时才会有自然填充；还有就是在奇数维中会有一个中心像素点，便于指出过滤器的位置。\n\n\n05 卷积步长\n步长为2，说明过滤器执行完一次后，平移两个格。输出格子公式：[(n+2p-f)&#x2F;s]+1 × [(n+2p-f)&#x2F;s]+1，如果不是一个整数的话就向下取整。按照惯例，过滤器必须完全处于图像中或者填充之后的图像区域内，才输出相应结果。\n\n\n\n总结下维度情况：\n\n\n\n在有些定义中还有镜像翻转，对着对角线翻转，咱们这不用奥。\n\n\n06 卷积为何有效\n假设我们想检测彩色图像的特征，那么对应的过滤器也应该有三层，对应红绿蓝三个通道。定义一下6×6×3这个形式：分别代表高、宽和通道数，并且图像的通道数必须和过滤器的通道数相等。\n\n\n\n下面来看下计算立体图像的细节：首先我们的过滤器画成一个三维的立方体，然后把这个过滤器放到最左上角的位置，最后把27个对应数相乘相加就得到了输出的第一个数。依次平移得到剩下的数字。通过设置过滤器每层不同的参数，就可以检测不同颜色通道里的边界（右下角那两个例子）。\n\n\n\n我们想同时检测垂直和水平边缘还有45度倾斜的边缘还有70度倾斜的边缘该怎么做？（换句话说就是想同时用多个过滤器怎么办）就是用两个不同的过滤器，然后得到的结果依次进行叠加，得到一个立方体。\n\n\n07 单层卷积网络\n通过不同的过滤器得到不同的输出后，通过python的广播机制给第一个矩阵这些元素都加上同一偏差，然后应用一个非线性激活函数ReLU；然后给第二个输出矩阵加上不同的偏差，同样也使用非线性激活函数ReLU，最后得到另一个4×4的矩阵，然后将两个矩阵叠加起来，就得到一个4×4×2的矩阵。\na[0]到a[1]的演变过程：首先执行线性函数，然后将所有元素相乘做卷积，再加上偏差，然后应用激活函数ReLU，最后通过神经网络的一层，将6×6×3的维度a[0]演化为一个4×4×2维度的a[1],这就是卷积神经网络的一层。\n\n\n\n举个例子，有十个过滤器，每个过滤器是3×3×3的，问这一层有多少参数？因为过滤器是3×3×3的，所以有27个参数，然后加一个偏差就是28个，然后是10个过滤器也就是一共280个参数。无论输入的图片有多大，参数始终是280个，这是卷积神经网络的一个特征叫做“避免过拟合”。\n\n\n\n总结下用于描述卷积神经网络中的一层的各种标记：\n\n\n08 简单卷积网络示例\n想做一个图像识别，输入x，然后判别图片中有没有猫（0&#x2F;1表示）。通过下面的不同卷积不断地进行，最终为图片提取出7×7×40个特征，然后对该卷积层进行处理处理，可以将其平滑或展开成1960个单元，平滑处理后输出一个向量，其填充内容是逻辑回归单元还是softmax回归单元完全取决于我们是想识别图片上有没有猫还是想识别K种不同对象中的一种用y^表示最终神经网络的预测输出。\n随着神经网络计算深度不断加深，通常开始时的图像也要更大一些，高度和宽度会在一段时间内保持一致，然后随着深度的加深而逐渐减小，而信道数量在增加。\n\n\n\n一个典型的卷积神经网络通常有三层：卷积层（CONV）、池化层（POOL）、全连接层（FC）\n\n\n09 池化层使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性\n\n\n在此用到的池化类型是最大池化，下面的例子相当于我们选用了一个规模为2、步幅为2的过滤器，然后选择其中最大值。最大化操作的功能就是只要在任何一个象限内提取到某个特征，他都会保留在最大池化的输出中，最大池化的实际作用就是在过滤器中提取某个特征，然后保留其最大值。\n\n\n\n再看一个有若干超级参数的例子，每个信道都独立执行最大池化计算。\n\n\n\n平均池化——就是取平均值\n\n\n\n总结：池化的超级参数包括过滤器大小f和步幅s，大部分情况下p&#x3D;0\n\n\n10 卷积神经网络示例\n在卷积文献中，卷积有两种分类，一类卷积是一个卷积层和一个池化层一起作为一层（人们在计算神经网络有多少层时，通常只是统计具有权重和参数的层，因为池化层没有权重和参数，只有一些超参数，所以将两者当着一层Layer1）；另一类卷积是把卷积层作为一层，池化层单独作为一层。\n我们针对识别数字例子，首先输入一个数字图片，通过两个神经网络的组合（卷积层+池化层），然后得到一个输出，将输出水平展开成向量，通过两个全连接层，最后用FC4的单元填充一个softmax单元，softmax会有十个输出。关于如何选定超级参数，常规做法是尽量不要自己设置，而是参考别人的文献采用了哪些超级参数，选择一个效果好的框架。在神经网络中另一种常见的模式是一个或多个卷积层后跟随一个池化层，然后一个或多个卷积层后再跟随一个池化层，然后是几个全连接层，最后是一个softmax。\n\n\n\n神经网络激活值形状、激活值大小和参数数量。有几点注意：第一池化层和最大池化层没有参数；第二卷积层的参数相对较少，许多参数都存在于神经网络中的全连接层；第三随着神经网络的加深，激活值会逐渐减小（如果下降太快也会有所影响）。\n\n\n11为什么使用卷积？\n和只用全连接层相比卷积层的两个主要优势在于参数共享和稀疏连接。两个神经元相连会得到一个非常多的参数数量3072×4704，而使用卷积的话，一共才156个参数。\n\n\n\n卷积网络映射这么少参数有两个原因：一是参数共享，一个特征检测器如垂直边缘检测器，用于检测图片左上角区域的特征，这个特征很可能也适用于右下角区域，因此在计算图片的左上和右下角区域时，不需要添加其他的特征检测器，假如有一个左上角和右下角可能有不同分布，但也可能很相似的数据集，整张图片共享特征检测器，提取效果也很好；二是稀疏连接，右图的输出单元仅与36个输入特征中的9个相连接，而其他像素值都不会对输出产生任何影响。神经网络通过这两种机制减少参数，以便我们用更小的训练集训练它，从而防止过拟合。\n\n\n\n要训练神经网络要做的就是使用梯度下降法，来优化神经网络中的所有参数，以及减小代价函数J的值。\n\n\n","tags":["深度学习"]}]