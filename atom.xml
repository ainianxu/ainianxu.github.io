<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-08-24T08:05:36.051Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>k8s之容器交付</title>
    <link href="http://example.com/2022/08/24/k8s%E4%B9%8B%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98/"/>
    <id>http://example.com/2022/08/24/k8s%E4%B9%8B%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98/</id>
    <published>2022-08-24T08:01:57.000Z</published>
    <updated>2022-08-24T08:05:36.051Z</updated>
    
    <content type="html"><![CDATA[<p>如何在k8s集群中部署Java项目</p><h2 id="容器交付流程"><a href="#容器交付流程" class="headerlink" title="容器交付流程"></a>容器交付流程</h2><ul><li>开发代码阶段<ul><li>编写代码</li><li>编写Dockerfile【打镜像做准备】</li></ul></li><li>持续交付&#x2F;集成<ul><li>代码编译打包</li><li>制作镜像</li><li>上传镜像仓库</li></ul></li><li>应用部署<ul><li>环境准备</li><li>Pod</li><li>Service</li><li>Ingress</li></ul></li><li>运维<ul><li>监控</li><li>故障排查</li><li>应用升级</li></ul></li></ul><h2 id="k8s部署Java项目流程"><a href="#k8s部署Java项目流程" class="headerlink" title="k8s部署Java项目流程"></a>k8s部署Java项目流程</h2><ul><li>制作镜像【Dockerfile】</li><li>上传到镜像仓库【Dockerhub、阿里云、网易】</li><li>控制器部署镜像【Deployment】</li><li>对外暴露应用【Service、Ingress】</li><li>运维【监控、升级】</li></ul><h2 id="k8s部署Java项目"><a href="#k8s部署Java项目" class="headerlink" title="k8s部署Java项目"></a>k8s部署Java项目</h2><h3 id="准备Java项目"><a href="#准备Java项目" class="headerlink" title="准备Java项目"></a>准备Java项目</h3><p>第一步，准备java项目，把java进行打包【jar包或者war包】</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121213239222.png"                      alt="image-20201121213239222"                ></p><h3 id="依赖环境"><a href="#依赖环境" class="headerlink" title="依赖环境"></a>依赖环境</h3><p>在打包java项目的时候，我们首先需要两个环境</p><ul><li>java环境【JDK】</li><li>maven环境</li></ul><p>然后把java项目打包成jar包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean install</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121213654216.png"                      alt="image-20201121213654216"                ></p><h3 id="编写Dockerfile文件"><a href="#编写Dockerfile文件" class="headerlink" title="编写Dockerfile文件"></a>编写Dockerfile文件</h3><p>Dockerfile 内容如下所示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM openjdk:8-jdk-alpine</span><br><span class="line">VOLUME /tmp</span><br><span class="line">ADD ./target/demojenkins.jar demojenkins.jar</span><br><span class="line">ENTRYPOINT [<span class="string">&quot;java&quot;</span>,<span class="string">&quot;-jar&quot;</span>,<span class="string">&quot;/demojenkins.jar&quot;</span>, <span class="string">&quot;&amp;&quot;</span>]</span><br></pre></td></tr></table></figure><h3 id="制作镜像"><a href="#制作镜像" class="headerlink" title="制作镜像"></a>制作镜像</h3><p>在我们创建好Dockerfile文件后，我们就可以制作镜像了</p><p>我们首先将我们的项目，放到我们的服务器上</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121214251023.png"                      alt="image-20201121214251023"                ></p><p>然后执行下面命令打包镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t java-demo-01:latest .</span><br></pre></td></tr></table></figure><p>等待一段后，即可制作完成我们的镜像</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121214701015.png"                      alt="image-20201121214701015"                ></p><p>最后通过下面命令，即可查看我们的镜像了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images;</span><br></pre></td></tr></table></figure><h3 id="启动镜像"><a href="#启动镜像" class="headerlink" title="启动镜像"></a>启动镜像</h3><p>在我们制作完成镜像后，我们就可以启动我们的镜像了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 8111:8111 java-demo-01:latest -t</span><br></pre></td></tr></table></figure><p>启动完成后，我们通过浏览器进行访问，即可看到我们的java程序</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.177.130:8111/user</span><br></pre></td></tr></table></figure><h3 id="推送镜像"><a href="#推送镜像" class="headerlink" title="推送镜像"></a>推送镜像</h3><p>下面我们需要将我们制作好的镜像，上传到镜像服务器中【阿里云、DockerHub】</p><p>首先我们需要到 阿里云 <a class="link"   href="https://cr.console.aliyun.com/cn-hangzhou/instances/repositories" >容器镜像服务<i class="fas fa-external-link-alt"></i></a>，然后开始创建镜像仓库</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121223435851.png"                      alt="image-20201121223435851"                ></p><p>然后选择本地仓库</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121223516789.png"                      alt="image-20201121223516789"                ></p><p>我们点击我们刚刚创建的镜像仓库，就能看到以下的信息</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121224233092.png"                      alt="image-20201121224233092"                ></p><h4 id="登录镜像服务器"><a href="#登录镜像服务器" class="headerlink" title="登录镜像服务器"></a>登录镜像服务器</h4><p>使用命令登录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login --username=XXXXXXX@163.com registry.cn-shenzhen.aliyuncs.com</span><br></pre></td></tr></table></figure><p>然后输入刚刚我们开放时候的注册的密码</p><h4 id="镜像添加版本号"><a href="#镜像添加版本号" class="headerlink" title="镜像添加版本号"></a>镜像添加版本号</h4><p>下面为我们的镜像添加版本号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例</span></span><br><span class="line">docker tag [ImageId] registry.cn-shenzhen.aliyuncs.com/mogublog/java-project-01:[镜像版本号]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 举例</span></span><br><span class="line">docker tag 33f11349c27d registry.cn-shenzhen.aliyuncs.com/mogublog/java-project-01:1.0.0</span><br></pre></td></tr></table></figure><p>操作完成后</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121224609890.png"                      alt="image-20201121224609890"                ></p><h4 id="推送镜像-1"><a href="#推送镜像-1" class="headerlink" title="推送镜像"></a>推送镜像</h4><p>在我们添加版本号信息后，我们就可以推送我们的镜像到阿里云了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push registry.cn-shenzhen.aliyuncs.com/mogublog/java-project-01:1.0.0</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121224714068.png"                      alt="image-20201121224714068"                ></p><p>操作完成后，我们在我们的阿里云镜像服务，就能看到推送上来的镜像了</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121224858651.png"                      alt="image-20201121224858651"                ></p><h3 id="控制器部署镜像"><a href="#控制器部署镜像" class="headerlink" title="控制器部署镜像"></a>控制器部署镜像</h3><p>在我们推送镜像到服务器后，就可以通过控制器部署镜像了</p><p>首先我们需要根据刚刚的镜像，导出yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导出yaml</span></span><br><span class="line">kubectl create deployment  javademo1 --image=registry.cn-</span><br><span class="line">shenzhen.aliyuncs.com/mogublog/java-project-01:1.0.0 --dry-run -o yaml &gt; javademo1.yaml</span><br></pre></td></tr></table></figure><p>导出后的 javademo1.yaml 如下所示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    app: javademo1</span><br><span class="line">  name: javademo1</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: javademo1</span><br><span class="line">  strategy: &#123;&#125;</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        app: javademo1</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: registry.cn-shenzhen.aliyuncs.com/mogublog/java-project-01:1.0.0</span><br><span class="line">        name: java-project-01</span><br><span class="line">        resources: &#123;&#125;</span><br><span class="line">status: &#123;&#125;</span><br></pre></td></tr></table></figure><p>然后通过下面命令，通过yaml创建我们的deployment</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">kubectl apply -f javademo1.yaml</span><br><span class="line"><span class="comment"># 查看 pods</span></span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121225413122.png"                      alt="image-20201121225413122"                ></p><p>或者我们可以进行扩容，多创建几个副本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment javademo1 --replicas=3</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121225600554.png"                      alt="image-20201121225600554"                ></p><p>然后我们还需要对外暴露端口【通过service 或者 Ingress】</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对外暴露端口</span></span><br><span class="line">kubectl expose deployment javademo1 --port=8111  --target-port=8111 --<span class="built_in">type</span>=NodePort</span><br><span class="line"><span class="comment"># 查看对外端口号</span></span><br><span class="line">kubectl get svc</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/19_Kubernetes%E5%AE%B9%E5%99%A8%E4%BA%A4%E4%BB%98%E4%BB%8B%E7%BB%8D/images/image-20201121225818003.png"                      alt="image-20201121225818003"                ></p><p>然后通过下面的地址访问</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对内访问</span></span><br><span class="line">curl http://10.106.103.242:8111/user</span><br><span class="line"><span class="comment"># 对外访问</span></span><br><span class="line">http://192.168.177.130:32190/user</span><br></pre></td></tr></table></figure><h3 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h3><p>….</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如何在k8s集群中部署Java项目&lt;/p&gt;
&lt;h2 id=&quot;容器交付流程&quot;&gt;&lt;a href=&quot;#容器交付流程&quot; class=&quot;headerlink&quot; title=&quot;容器交付流程&quot;&gt;&lt;/a&gt;容器交付流程&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;开发代码阶段&lt;ul&gt;
&lt;li&gt;编写代码&lt;/li</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之搭建高可用集群</title>
    <link href="http://example.com/2022/08/24/k8s%E4%B9%8B%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/"/>
    <id>http://example.com/2022/08/24/k8s%E4%B9%8B%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/</id>
    <published>2022-08-24T07:11:44.000Z</published>
    <updated>2022-08-24T07:13:52.119Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前我们搭建的集群，只有一个master节点，当master节点宕机的时候，通过node将无法继续访问，而master主要是管理作用，所以整个集群将无法提供服务</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/18_Kubernetes%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/images/image-20201121164522945.png"                      alt="image-20201121164522945"                ></p><h2 id="高可用集群"><a href="#高可用集群" class="headerlink" title="高可用集群"></a>高可用集群</h2><p>下面我们就需要搭建一个多master节点的高可用集群，不会存在单点故障问题</p><p>但是在node 和 master节点之间，需要存在一个 LoadBalancer组件，作用如下：</p><ul><li>负载</li><li>检查master节点的状态</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/18_Kubernetes%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/images/image-20201121164931760.png"                      alt="image-20201121164931760"                ></p><p>对外有一个统一的VIP：虚拟ip来对外进行访问</p><h2 id="高可用集群技术细节"><a href="#高可用集群技术细节" class="headerlink" title="高可用集群技术细节"></a>高可用集群技术细节</h2><p>高可用集群技术细节如下所示：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/18_Kubernetes%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/images/image-20201121165325194.png"                      alt="image-20201121165325194"                ></p><ul><li>keepalived：配置虚拟ip，检查节点的状态</li><li>haproxy：负载均衡服务【类似于nginx】</li><li>apiserver：</li><li>controller：</li><li>manager：</li><li>scheduler：</li></ul><h2 id="高可用集群步骤"><a href="#高可用集群步骤" class="headerlink" title="高可用集群步骤"></a>高可用集群步骤</h2><p>我们采用2个master节点，一个node节点来搭建高可用集群，下面给出了每个节点需要做的事情</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/18_Kubernetes%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/images/image-20201121170351461.png"                      alt="image-20201121170351461"                ></p><h2 id="初始化操作"><a href="#初始化操作" class="headerlink" title="初始化操作"></a>初始化操作</h2><p>我们需要在这三个节点上进行操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭selinux</span></span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line">sed -i <span class="string">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config  </span><br><span class="line"><span class="comment"># 临时关闭</span></span><br><span class="line">setenforce 0  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭swap</span></span><br><span class="line"><span class="comment"># 临时</span></span><br><span class="line">swapoff -a </span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line">sed -ri <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据规划设置主机名【master1节点上操作】</span></span><br><span class="line">hostnamectl set-hostname master1</span><br><span class="line"><span class="comment"># 根据规划设置主机名【master2节点上操作】</span></span><br><span class="line">hostnamectl set-hostname master1</span><br><span class="line"><span class="comment"># 根据规划设置主机名【node1节点操作】</span></span><br><span class="line">hostnamectl set-hostname node1</span><br><span class="line"></span><br><span class="line"><span class="comment"># r添加hosts</span></span><br><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">192.168.44.158  k8smaster</span></span><br><span class="line"><span class="string">192.168.44.155 master01.k8s.io master1</span></span><br><span class="line"><span class="string">192.168.44.156 master02.k8s.io master2</span></span><br><span class="line"><span class="string">192.168.44.157 node01.k8s.io node1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将桥接的IPv4流量传递到iptables的链【3个节点上都执行】</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生效</span></span><br><span class="line">sysctl --system  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间同步</span></span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate time.windows.com</span><br></pre></td></tr></table></figure><h2 id="部署keepAlived"><a href="#部署keepAlived" class="headerlink" title="部署keepAlived"></a>部署keepAlived</h2><p>下面我们需要在所有的master节点【master1和master2】上部署keepAlive</p><h3 id="安装相关包"><a href="#安装相关包" class="headerlink" title="安装相关包"></a>安装相关包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装相关工具</span></span><br><span class="line">yum install -y conntrack-tools libseccomp libtool-ltdl</span><br><span class="line"><span class="comment"># 安装keepalived</span></span><br><span class="line">yum install -y keepalived</span><br></pre></td></tr></table></figure><h3 id="配置master节点"><a href="#配置master节点" class="headerlink" title="配置master节点"></a>配置master节点</h3><p>添加master1的配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/keepalived/keepalived.conf &lt;&lt;<span class="string">EOF </span></span><br><span class="line"><span class="string">! Configuration File for keepalived</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">global_defs &#123;</span></span><br><span class="line"><span class="string">   router_id k8s</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vrrp_script check_haproxy &#123;</span></span><br><span class="line"><span class="string">    script &quot;killall -0 haproxy&quot;</span></span><br><span class="line"><span class="string">    interval 3</span></span><br><span class="line"><span class="string">    weight -2</span></span><br><span class="line"><span class="string">    fall 10</span></span><br><span class="line"><span class="string">    rise 2</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vrrp_instance VI_1 &#123;</span></span><br><span class="line"><span class="string">    state MASTER </span></span><br><span class="line"><span class="string">    interface ens33 </span></span><br><span class="line"><span class="string">    virtual_router_id 51</span></span><br><span class="line"><span class="string">    priority 250</span></span><br><span class="line"><span class="string">    advert_int 1</span></span><br><span class="line"><span class="string">    authentication &#123;</span></span><br><span class="line"><span class="string">        auth_type PASS</span></span><br><span class="line"><span class="string">        auth_pass ceb1b3ec013d66163d6ab</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    virtual_ipaddress &#123;</span></span><br><span class="line"><span class="string">        192.168.44.158</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    track_script &#123;</span></span><br><span class="line"><span class="string">        check_haproxy</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>添加master2的配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/keepalived/keepalived.conf &lt;&lt;<span class="string">EOF </span></span><br><span class="line"><span class="string">! Configuration File for keepalived</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">global_defs &#123;</span></span><br><span class="line"><span class="string">   router_id k8s</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vrrp_script check_haproxy &#123;</span></span><br><span class="line"><span class="string">    script &quot;killall -0 haproxy&quot;</span></span><br><span class="line"><span class="string">    interval 3</span></span><br><span class="line"><span class="string">    weight -2</span></span><br><span class="line"><span class="string">    fall 10</span></span><br><span class="line"><span class="string">    rise 2</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vrrp_instance VI_1 &#123;</span></span><br><span class="line"><span class="string">    state BACKUP </span></span><br><span class="line"><span class="string">    interface ens33 </span></span><br><span class="line"><span class="string">    virtual_router_id 51</span></span><br><span class="line"><span class="string">    priority 200</span></span><br><span class="line"><span class="string">    advert_int 1</span></span><br><span class="line"><span class="string">    authentication &#123;</span></span><br><span class="line"><span class="string">        auth_type PASS</span></span><br><span class="line"><span class="string">        auth_pass ceb1b3ec013d66163d6ab</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    virtual_ipaddress &#123;</span></span><br><span class="line"><span class="string">        192.168.44.158</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">    track_script &#123;</span></span><br><span class="line"><span class="string">        check_haproxy</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><h3 id="启动和检查"><a href="#启动和检查" class="headerlink" title="启动和检查"></a>启动和检查</h3><p>在两台master节点都执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动keepalived</span></span><br><span class="line">systemctl start keepalived.service</span><br><span class="line"><span class="comment"># 设置开机启动</span></span><br><span class="line">systemctl <span class="built_in">enable</span> keepalived.service</span><br><span class="line"><span class="comment"># 查看启动状态</span></span><br><span class="line">systemctl status keepalived.service</span><br></pre></td></tr></table></figure><p>启动后查看master的网卡信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip a s ens33</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/18_Kubernetes%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/images/image-20201121171619497.png"                      alt="image-20201121171619497"                ></p><h2 id="部署haproxy"><a href="#部署haproxy" class="headerlink" title="部署haproxy"></a>部署haproxy</h2><p>haproxy主要做负载的作用，将我们的请求分担到不同的node节点上</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>在两个master节点安装 haproxy</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装haproxy</span></span><br><span class="line">yum install -y haproxy</span><br><span class="line"><span class="comment"># 启动 haproxy</span></span><br><span class="line">systemctl start haproxy</span><br><span class="line"><span class="comment"># 开启自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> haproxy</span><br></pre></td></tr></table></figure><p>启动后，我们查看对应的端口是否包含 16443</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -tunlp | grep haproxy</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/18_Kubernetes%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/images/image-20201121181803128.png"                      alt="image-20201121181803128"                ></p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>两台master节点的配置均相同，配置中声明了后端代理的两个master节点服务器，指定了haproxy运行的端口为16443等，因此16443端口为集群的入口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/haproxy/haproxy.cfg &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------</span></span><br><span class="line"><span class="string"># Global settings</span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------</span></span><br><span class="line"><span class="string">global</span></span><br><span class="line"><span class="string">    # to have these messages end up in /var/log/haproxy.log you will</span></span><br><span class="line"><span class="string">    # need to:</span></span><br><span class="line"><span class="string">    # 1) configure syslog to accept network log events.  This is done</span></span><br><span class="line"><span class="string">    #    by adding the &#x27;-r&#x27; option to the SYSLOGD_OPTIONS in</span></span><br><span class="line"><span class="string">    #    /etc/sysconfig/syslog</span></span><br><span class="line"><span class="string">    # 2) configure local2 events to go to the /var/log/haproxy.log</span></span><br><span class="line"><span class="string">    #   file. A line like the following can be added to</span></span><br><span class="line"><span class="string">    #   /etc/sysconfig/syslog</span></span><br><span class="line"><span class="string">    #</span></span><br><span class="line"><span class="string">    #    local2.*                       /var/log/haproxy.log</span></span><br><span class="line"><span class="string">    #</span></span><br><span class="line"><span class="string">    log         127.0.0.1 local2</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    chroot      /var/lib/haproxy</span></span><br><span class="line"><span class="string">    pidfile     /var/run/haproxy.pid</span></span><br><span class="line"><span class="string">    maxconn     4000</span></span><br><span class="line"><span class="string">    user        haproxy</span></span><br><span class="line"><span class="string">    group       haproxy</span></span><br><span class="line"><span class="string">    daemon </span></span><br><span class="line"><span class="string">       </span></span><br><span class="line"><span class="string">    # turn on stats unix socket</span></span><br><span class="line"><span class="string">    stats socket /var/lib/haproxy/stats</span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------</span></span><br><span class="line"><span class="string"># common defaults that all the &#x27;listen&#x27; and &#x27;backend&#x27; sections will</span></span><br><span class="line"><span class="string"># use if not designated in their block</span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------  </span></span><br><span class="line"><span class="string">defaults</span></span><br><span class="line"><span class="string">    mode                    http</span></span><br><span class="line"><span class="string">    log                     global</span></span><br><span class="line"><span class="string">    option                  httplog</span></span><br><span class="line"><span class="string">    option                  dontlognull</span></span><br><span class="line"><span class="string">    option http-server-close</span></span><br><span class="line"><span class="string">    option forwardfor       except 127.0.0.0/8</span></span><br><span class="line"><span class="string">    option                  redispatch</span></span><br><span class="line"><span class="string">    retries                 3</span></span><br><span class="line"><span class="string">    timeout http-request    10s</span></span><br><span class="line"><span class="string">    timeout queue           1m</span></span><br><span class="line"><span class="string">    timeout connect         10s</span></span><br><span class="line"><span class="string">    timeout client          1m</span></span><br><span class="line"><span class="string">    timeout server          1m</span></span><br><span class="line"><span class="string">    timeout http-keep-alive 10s</span></span><br><span class="line"><span class="string">    timeout check           10s</span></span><br><span class="line"><span class="string">    maxconn                 3000</span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------</span></span><br><span class="line"><span class="string"># kubernetes apiserver frontend which proxys to the backends</span></span><br><span class="line"><span class="string">#--------------------------------------------------------------------- </span></span><br><span class="line"><span class="string">frontend kubernetes-apiserver</span></span><br><span class="line"><span class="string">    mode                 tcp</span></span><br><span class="line"><span class="string">    bind                 *:16443</span></span><br><span class="line"><span class="string">    option               tcplog</span></span><br><span class="line"><span class="string">    default_backend      kubernetes-apiserver    </span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------</span></span><br><span class="line"><span class="string"># round robin balancing between the various backends</span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------</span></span><br><span class="line"><span class="string">backend kubernetes-apiserver</span></span><br><span class="line"><span class="string">    mode        tcp</span></span><br><span class="line"><span class="string">    balance     roundrobin</span></span><br><span class="line"><span class="string">    server      master01.k8s.io   192.168.44.155:6443 check</span></span><br><span class="line"><span class="string">    server      master02.k8s.io   192.168.44.156:6443 check</span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------</span></span><br><span class="line"><span class="string"># collection haproxy statistics message</span></span><br><span class="line"><span class="string">#---------------------------------------------------------------------</span></span><br><span class="line"><span class="string">listen stats</span></span><br><span class="line"><span class="string">    bind                 *:1080</span></span><br><span class="line"><span class="string">    stats auth           admin:awesomePassword</span></span><br><span class="line"><span class="string">    stats refresh        5s</span></span><br><span class="line"><span class="string">    stats realm          HAProxy\ Statistics</span></span><br><span class="line"><span class="string">    stats uri            /admin?stats</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><h2 id="安装Docker、Kubeadm、kubectl"><a href="#安装Docker、Kubeadm、kubectl" class="headerlink" title="安装Docker、Kubeadm、kubectl"></a>安装Docker、Kubeadm、kubectl</h2><p>所有节点安装Docker&#x2F;kubeadm&#x2F;kubelet ，Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker</p><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><p>首先配置一下Docker的阿里yum源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt;/etc/yum.repos.d/docker.repo&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[docker-ce-edge]</span></span><br><span class="line"><span class="string">name=Docker CE Edge - \$basearch</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/7/\$basearch/edge</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=1</span></span><br><span class="line"><span class="string">gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>然后yum方式安装docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum安装</span></span><br><span class="line">yum -y install docker-ce</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看docker版本</span></span><br><span class="line">docker --version  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动docker</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure><p>配置docker的镜像源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/docker/daemon.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>然后重启docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h3 id="添加kubernetes软件源"><a href="#添加kubernetes软件源" class="headerlink" title="添加kubernetes软件源"></a>添加kubernetes软件源</h3><p>然后我们还需要配置一下yum的k8s软件源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[kubernetes]</span></span><br><span class="line"><span class="string">name=Kubernetes</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">repo_gpgcheck=0</span></span><br><span class="line"><span class="string">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><h3 id="安装kubeadm，kubelet和kubectl"><a href="#安装kubeadm，kubelet和kubectl" class="headerlink" title="安装kubeadm，kubelet和kubectl"></a>安装kubeadm，kubelet和kubectl</h3><p>由于版本更新频繁，这里指定版本号部署：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装kubelet、kubeadm、kubectl，同时指定版本</span></span><br><span class="line">yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0</span><br><span class="line"><span class="comment"># 设置开机启动</span></span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet</span><br></pre></td></tr></table></figure><h2 id="部署Kubernetes-Master【master节点】"><a href="#部署Kubernetes-Master【master节点】" class="headerlink" title="部署Kubernetes Master【master节点】"></a>部署Kubernetes Master【master节点】</h2><h3 id="创建kubeadm配置文件"><a href="#创建kubeadm配置文件" class="headerlink" title="创建kubeadm配置文件"></a>创建kubeadm配置文件</h3><p>在具有vip的master上进行初始化操作，这里为master1</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹</span></span><br><span class="line"><span class="built_in">mkdir</span> /usr/local/kubernetes/manifests -p</span><br><span class="line"><span class="comment"># 到manifests目录</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/kubernetes/manifests/</span><br><span class="line"><span class="comment"># 新建yaml文件</span></span><br><span class="line">vi kubeadm-config.yaml</span><br></pre></td></tr></table></figure><p>yaml内容如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">apiServer:</span><br><span class="line">  certSANs:</span><br><span class="line">    - master1</span><br><span class="line">    - master2</span><br><span class="line">    - master.k8s.io</span><br><span class="line">    - 192.168.44.158</span><br><span class="line">    - 192.168.44.155</span><br><span class="line">    - 192.168.44.156</span><br><span class="line">    - 127.0.0.1</span><br><span class="line">  extraArgs:</span><br><span class="line">    authorization-mode: Node,RBAC</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta1</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controlPlaneEndpoint: <span class="string">&quot;master.k8s.io:16443&quot;</span></span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns: </span><br><span class="line">  <span class="built_in">type</span>: CoreDNS</span><br><span class="line">etcd:</span><br><span class="line">  <span class="built_in">local</span>:    </span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.16.3</span><br><span class="line">networking: </span><br><span class="line">  dnsDomain: cluster.local  </span><br><span class="line">  podSubnet: 10.244.0.0/16</span><br><span class="line">  serviceSubnet: 10.1.0.0/16</span><br><span class="line">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure><p>然后我们在 master1 节点执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config kubeadm-config.yaml</span><br></pre></td></tr></table></figure><p>执行完成后，就会在拉取我们的进行了【需要等待…】</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/18_Kubernetes%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/images/image-20201121194928988.png"                      alt="image-20201121194928988"                ></p><p>按照提示配置环境变量，使用kubectl工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行下方命令</span></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"><span class="comment"># 查看节点</span></span><br><span class="line">kubectl get nodes</span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure><p><strong>按照提示保存以下内容，一会要使用：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm <span class="built_in">join</span> master.k8s.io:16443 --token jv5z7n.3y1zi95p952y9p65 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:403bca185c2f3a4791685013499e7ce58f9848e2213e27194b75a2e3293d8812 \</span><br><span class="line">    --control-plane </span><br></pre></td></tr></table></figure><blockquote><p>–control-plane ： 只有在添加master节点的时候才有</p></blockquote><p>查看集群状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看集群状态</span></span><br><span class="line">kubectl get cs</span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure><h2 id="安装集群网络"><a href="#安装集群网络" class="headerlink" title="安装集群网络"></a>安装集群网络</h2><p>从官方地址获取到flannel的yaml，在master1上执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹</span></span><br><span class="line"><span class="built_in">mkdir</span> flannel</span><br><span class="line"><span class="built_in">cd</span> flannel</span><br><span class="line"><span class="comment"># 下载yaml文件</span></span><br><span class="line">wget -c https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><p>安装flannel网络</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kube-flannel.yml </span><br></pre></td></tr></table></figure><p>检查</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure><h2 id="master2节点加入集群"><a href="#master2节点加入集群" class="headerlink" title="master2节点加入集群"></a>master2节点加入集群</h2><h3 id="复制密钥及相关文件"><a href="#复制密钥及相关文件" class="headerlink" title="复制密钥及相关文件"></a>复制密钥及相关文件</h3><p>从master1复制密钥及相关文件到master2</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh root@192.168.44.156 mkdir -p /etc/kubernetes/pki/etcd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># scp /etc/kubernetes/admin.conf root@192.168.44.156:/etc/kubernetes</span></span><br><span class="line">   </span><br><span class="line"><span class="comment"># scp /etc/kubernetes/pki/&#123;ca.*,sa.*,front-proxy-ca.*&#125; root@192.168.44.156:/etc/kubernetes/pki</span></span><br><span class="line">   </span><br><span class="line"><span class="comment"># scp /etc/kubernetes/pki/etcd/ca.* root@192.168.44.156:/etc/kubernetes/pki/etcd</span></span><br></pre></td></tr></table></figure><h3 id="master2加入集群"><a href="#master2加入集群" class="headerlink" title="master2加入集群"></a>master2加入集群</h3><p>执行在master1上init后输出的join命令,需要带上参数<code>--control-plane</code>表示把master控制节点加入集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm <span class="built_in">join</span> master.k8s.io:16443 --token ckf7bs.30576l0okocepg8b     --discovery-token-ca-cert-hash sha256:19afac8b11182f61073e254fb57b9f19ab4d798b70501036fc69ebef46094aba --control-plane</span><br></pre></td></tr></table></figure><p>检查状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node</span><br><span class="line"></span><br><span class="line">kubectl get pods --all-namespaces</span><br></pre></td></tr></table></figure><h2 id="加入Kubernetes-Node"><a href="#加入Kubernetes-Node" class="headerlink" title="加入Kubernetes Node"></a>加入Kubernetes Node</h2><p>在node1上执行</p><p>向集群添加新节点，执行在kubeadm init输出的kubeadm join命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm <span class="built_in">join</span> master.k8s.io:16443 --token ckf7bs.30576l0okocepg8b     --discovery-token-ca-cert-hash sha256:19afac8b11182f61073e254fb57b9f19ab4d798b70501036fc69ebef46094aba</span><br></pre></td></tr></table></figure><p><strong>集群网络重新安装，因为添加了新的node节点</strong></p><p>检查状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node</span><br><span class="line">kubectl get pods --all-namespaces</span><br></pre></td></tr></table></figure><h2 id="测试kubernetes集群"><a href="#测试kubernetes集群" class="headerlink" title="测试kubernetes集群"></a>测试kubernetes集群</h2><p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建nginx deployment</span></span><br><span class="line">kubectl create deployment nginx --image=nginx</span><br><span class="line"><span class="comment"># 暴露端口</span></span><br><span class="line">kubectl expose deployment nginx --port=80 --<span class="built_in">type</span>=NodePort</span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">kubectl get pod,svc</span><br></pre></td></tr></table></figure><p>然后我们通过任何一个节点，都能够访问我们的nginx页面</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前我们搭建的集群，只有一个master节点，当master节点宕机的时候，通过node将无法继续访问，而master主要是管理作用，所以整</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之集群资源监控</title>
    <link href="http://example.com/2022/08/24/k8s%E4%B9%8B%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/"/>
    <id>http://example.com/2022/08/24/k8s%E4%B9%8B%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/</id>
    <published>2022-08-24T02:53:12.000Z</published>
    <updated>2022-08-24T02:56:16.631Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="监控指标"><a href="#监控指标" class="headerlink" title="监控指标"></a>监控指标</h3><p>一个好的系统，主要监控以下内容</p><ul><li>集群监控<ul><li>节点资源利用率</li><li>节点数</li><li>运行Pods</li></ul></li><li>Pod监控<ul><li>容器指标</li><li>应用程序【程序占用多少CPU、内存】</li></ul></li></ul><h3 id="监控平台"><a href="#监控平台" class="headerlink" title="监控平台"></a>监控平台</h3><p>使用普罗米修斯【prometheus】 + Grafana 搭建监控平台</p><ul><li><p>prometheus【定时搜索被监控服务的状态】</p><ul><li>开源的</li><li>监控、报警、数据库</li><li>以HTTP协议周期性抓取被监控组件状态</li><li>不需要复杂的集成过程，使用http接口接入即可</li></ul></li><li><p>Grafana</p><ul><li>开源的数据分析和可视化工具</li><li>支持多种数据源</li></ul></li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120082257441.png"                      alt="image-20201120082257441"                ></p><h2 id="部署prometheus"><a href="#部署prometheus" class="headerlink" title="部署prometheus"></a>部署prometheus</h2><p>首先需要部署一个守护进程</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120083606298.png"                      alt="image-20201120083606298"                ></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: node-exporter</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: node-exporter</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: node-exporter</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: node-exporter</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: prom/node-exporter</span><br><span class="line">        name: node-exporter</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9100</span><br><span class="line">          protocol: TCP</span><br><span class="line">          name: http</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: node-exporter</span><br><span class="line">  name: node-exporter</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    port: 9100</span><br><span class="line">    nodePort: 31672</span><br><span class="line">    protocol: TCP</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: node-exporter</span><br></pre></td></tr></table></figure><p>然后执行下面命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f node-exporter.yaml</span><br></pre></td></tr></table></figure><p>执行完，发现会报错</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120084034160.png"                      alt="image-20201120084034160"                ></p><p>这是因为版本不一致的问题，因为发布的正式版本，而这个属于测试版本</p><p>所以我们找到第一行，然后把内容修改为如下所示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改前</span></span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line"><span class="comment"># 修改后 【正式版本发布后，测试版本不能使用】</span></span><br><span class="line">apiVersion: apps/v1</span><br></pre></td></tr></table></figure><p>创建完成后的效果</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120085721454.png"                      alt="image-20201120085721454"                ></p><p>然后通过yaml的方式部署prometheus</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120083107594.png"                      alt="image-20201120083107594"                ></p><ul><li>configmap：定义一个configmap：存储一些配置文件【不加密】</li><li>prometheus.deploy.yaml：部署一个deployment【包括端口号，资源限制】</li><li>prometheus.svc.yaml：对外暴露的端口</li><li>rbac-setup.yaml：分配一些角色的权限</li></ul><p>下面我们进入目录下，首先部署 rbac-setup.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f rbac-setup.yaml</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120090002150.png"                      alt="image-20201120090002150"                ></p><p>然后分别部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 部署configmap</span></span><br><span class="line">kubectl create -f configmap.yaml</span><br><span class="line"><span class="comment"># 部署deployment</span></span><br><span class="line">kubectl create -f prometheus.deploy.yml</span><br><span class="line"><span class="comment"># 部署svc</span></span><br><span class="line">kubectl create -f prometheus.svc.yml</span><br></pre></td></tr></table></figure><p>部署完成后，我们使用下面命令查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120093213576.png"                      alt="image-20201120093213576"                ></p><p>在我们部署完成后，即可看到 prometheus 的 pod了，然后通过下面命令，能够看到对应的端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc -n kube-system</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201121091348752.png"                      alt="image-20201121091348752"                ></p><p>通过这个，我们可以看到 <code>prometheus</code> 对外暴露的端口为 30003，访问页面即可对应的图形化界面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.177.130:30003</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201121091508851.png"                      alt="image-20201121091508851"                ></p><p>在上面我们部署完prometheus后，我们还需要来部署grafana</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f grafana-deploy.yaml</span><br></pre></td></tr></table></figure><p>然后执行完后，发现下面的问题</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error: unable to recognize <span class="string">&quot;grafana-deploy.yaml&quot;</span>: no matches <span class="keyword">for</span> kind <span class="string">&quot;Deployment&quot;</span> <span class="keyword">in</span> version <span class="string">&quot;extensions/v1beta1&quot;</span></span><br></pre></td></tr></table></figure><p>我们需要修改如下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改</span></span><br><span class="line">apiVersion: apps/v1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加selector</span></span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: grafana</span><br><span class="line">      component: core</span><br></pre></td></tr></table></figure><p>修改完成后，我们继续执行上述代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建deployment</span></span><br><span class="line">kubectl create -f grafana-deploy.yaml</span><br><span class="line"><span class="comment"># 创建svc</span></span><br><span class="line">kubectl create -f grafana-svc.yaml</span><br><span class="line"><span class="comment"># 创建 ing</span></span><br><span class="line">kubectl create -f grafana-ing.yaml</span><br></pre></td></tr></table></figure><p>我们能看到，我们的grafana正在</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120110426534.png"                      alt="image-20201120110426534"                ></p><h3 id="配置数据源"><a href="#配置数据源" class="headerlink" title="配置数据源"></a>配置数据源</h3><p>下面我们需要开始打开 Grafana，然后配置数据源，导入数据显示模板</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc -n kube-system</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120111949197.png"                      alt="image-20201120111949197"                ></p><p>我们可以通过 ip + 30431 访问我们的 grafana 图形化页面</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201120112048887.png"                      alt="image-20201120112048887"                ></p><p>然后输入账号和密码：admin admin</p><p>进入后，我们就需要配置 prometheus 的数据源</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201121092012018.png"                      alt="image-20201121092012018"                ></p><p> 和 对应的IP【这里IP是我们的ClusterIP】</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201121092053215.png"                      alt="image-20201121092053215"                ></p><h3 id="设置显示数据的模板"><a href="#设置显示数据的模板" class="headerlink" title="设置显示数据的模板"></a>设置显示数据的模板</h3><p>选择Dashboard，导入我们的模板</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201121092312118.png"                      alt="image-20201121092312118"                ></p><p>然后输入 315 号模板</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201121092418180.png"                      alt="image-20201121092418180"                ></p><p>然后选择 prometheus数据源 mydb，导入即可</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201121092443266.png"                      alt="image-20201121092443266"                ></p><p>导入后的效果如下所示</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/17_Kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7/images/image-20201121092610154.png"                      alt="image-20201121092610154"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;h3 id=&quot;监控指标&quot;&gt;&lt;a href=&quot;#监控指标&quot; class=&quot;headerlink&quot; title=&quot;监控指标&quot;&gt;&lt;/a&gt;监控指标&lt;/h</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之持久化存储</title>
    <link href="http://example.com/2022/08/24/k8s%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/"/>
    <id>http://example.com/2022/08/24/k8s%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/</id>
    <published>2022-08-24T02:26:45.000Z</published>
    <updated>2022-08-24T02:28:37.579Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前我们有提到数据卷：<code>emptydir</code> ，是本地存储，pod重启，数据就不存在了，需要对数据持久化存储</p><p>对于数据持久化存储【pod重启，数据还存在】，有两种方式</p><ul><li>nfs：网络存储【通过一台服务器来存储】</li></ul><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="持久化服务器上操作"><a href="#持久化服务器上操作" class="headerlink" title="持久化服务器上操作"></a>持久化服务器上操作</h3><ul><li>找一台新的服务器nfs服务端，安装nfs</li><li>设置挂载路径</li></ul><p>使用命令安装nfs</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nfs-utils</span><br></pre></td></tr></table></figure><p>首先创建存放数据的目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /data/nfs</span><br></pre></td></tr></table></figure><p>设置挂载路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打开文件</span></span><br><span class="line">vim /etc/exports</span><br><span class="line"><span class="comment"># 添加如下内容</span></span><br><span class="line">/data/nfs *(rw,no_root_squash)</span><br></pre></td></tr></table></figure><p>执行完成后，即部署完我们的持久化服务器</p><h3 id="Node节点上操作"><a href="#Node节点上操作" class="headerlink" title="Node节点上操作"></a>Node节点上操作</h3><p>然后需要在k8s集群node节点上安装nfs，这里需要在 node1 和 node2节点上安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nfs-utils</span><br></pre></td></tr></table></figure><p>执行完成后，会自动帮我们挂载上</p><h3 id="启动nfs服务端"><a href="#启动nfs服务端" class="headerlink" title="启动nfs服务端"></a>启动nfs服务端</h3><p>下面我们回到nfs服务端，启动我们的nfs服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">systemctl start nfs</span><br><span class="line"><span class="comment"># 或者使用以下命令进行启动</span></span><br><span class="line">service nfs-server start</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/08/24/qnCwJT9V4tSFWRh.png"                      alt="image-20201119082047766"                ></p><h3 id="K8s集群部署应用"><a href="#K8s集群部署应用" class="headerlink" title="K8s集群部署应用"></a>K8s集群部署应用</h3><p>最后我们在k8s集群上部署应用，使用nfs持久化存储</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个pv文件</span></span><br><span class="line"><span class="built_in">mkdir</span> pv</span><br><span class="line"><span class="comment"># 进入</span></span><br><span class="line"><span class="built_in">cd</span> pv</span><br></pre></td></tr></table></figure><p>然后创建一个yaml文件  <code>nfs-nginx.yaml</code></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/08/24/qnCwJT9V4tSFWRh.png"                                     ></p><p>通过这个方式，就挂载到了刚刚我们的nfs数据节点下的 &#x2F;data&#x2F;nfs 目录</p><p>最后就变成了：  &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html    -&gt;  192.168.44.134&#x2F;data&#x2F;nfs   内容是对应的</p><p>我们通过这个 yaml文件，创建一个pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f nfs-nginx.yaml</span><br></pre></td></tr></table></figure><p>创建完成后，我们也可以查看日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pod nginx-dep1</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119083444454.png"                      alt="image-20201119083444454"                ></p><p>可以看到，我们的pod已经成功创建出来了，同时下图也是出于Running状态</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119083514247.png"                      alt="image-20201119083514247"                ></p><p>下面我们就可以进行测试了，比如现在nfs服务节点上添加数据，然后在看数据是否存在 pod中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入pod中查看</span></span><br><span class="line">kubectl <span class="built_in">exec</span> -it nginx-dep1 bash</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119095847548.png"                      alt="image-20201119095847548"                ></p><h2 id="PV和PVC"><a href="#PV和PVC" class="headerlink" title="PV和PVC"></a>PV和PVC</h2><p>对于上述的方式，我们都知道，我们的ip 和端口是直接放在我们的容器上的，这样管理起来可能不方便</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119082317625.png"                      alt="image-20201119082317625"                ></p><p>所以这里就需要用到 pv  和 pvc的概念了，方便我们配置和管理我们的 ip 地址等元信息</p><p>PV：持久化存储，对存储的资源进行抽象，对外提供可以调用的地方【生产者】</p><p>PVC：用于调用，不需要关心内部实现细节【消费者】</p><p>PV 和 PVC 使得 K8S 集群具备了存储的逻辑抽象能力。使得在配置Pod的逻辑里可以忽略对实际后台存储<br>技术的配置，而把这项配置的工作交给PV的配置者，即集群的管理者。存储的PV和PVC的这种关系，跟<br>计算的Node和Pod的关系是非常类似的；PV和Node是资源的提供者，根据集群的基础设施变化而变<br>化，由K8s集群管理员配置；而PVC和Pod是资源的使用者，根据业务服务的需求变化而变化，由K8s集<br>群的使用者即服务的管理员来配置。</p><h3 id="实现流程"><a href="#实现流程" class="headerlink" title="实现流程"></a>实现流程</h3><ul><li>PVC绑定PV</li><li>定义PVC</li><li>定义PV【数据卷定义，指定数据存储服务器的ip、路径、容量和匹配模式】</li></ul><h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>创建一个 pvc.yaml</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119101753419.png"                      alt="image-20201119101753419"                ></p><p>第一部分是定义一个 deployment，做一个部署</p><ul><li>副本数：3</li><li>挂载路径</li><li>调用：是通过pvc的模式</li></ul><p>然后定义pvc</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119101843498.png"                      alt="image-20201119101843498"                ></p><p>然后在创建一个 <code>pv.yaml</code></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119101957777.png"                      alt="image-20201119101957777"                ></p><p>然后就可以创建pod了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f pv.yaml</span><br></pre></td></tr></table></figure><p>然后我们就可以通过下面命令，查看我们的 pv  和 pvc之间的绑定关系</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pv, pvc</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119102332786.png"                      alt="image-20201119102332786"                ></p><p>到这里为止，我们就完成了我们 pv 和 pvc的绑定操作，通过之前的方式，进入pod中查看内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubect <span class="built_in">exec</span> -it nginx-dep1 bash</span><br></pre></td></tr></table></figure><p>然后查看  &#x2F;usr&#x2F;share&#x2F;nginx.html</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/16_Kubernetes%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/images/image-20201119102448226.png"                      alt="image-20201119102448226"                ></p><p>也同样能看到刚刚的内容，其实这种操作和之前我们的nfs是一样的，只是多了一层pvc绑定pv的操作</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;之前我们有提到数据卷：&lt;code&gt;emptydir&lt;/code&gt; ，是本地存储，pod重启，数据就不存在了，需要对数据持久化存储&lt;/p&gt;
&lt;</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之核心技术Helm</title>
    <link href="http://example.com/2022/08/24/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/"/>
    <id>http://example.com/2022/08/24/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/</id>
    <published>2022-08-24T01:36:30.000Z</published>
    <updated>2022-08-24T01:39:19.486Z</updated>
    
    <content type="html"><![CDATA[<p>Helm就是一个包管理工具【类似于npm】</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/892532-20180224212352306-705544441.png"                      alt="892532-20180224212352306-705544441"                ></p><h2 id="为什么引入Helm"><a href="#为什么引入Helm" class="headerlink" title="为什么引入Helm"></a>为什么引入Helm</h2><p>首先在原来项目中都是基于yaml文件来进行部署发布的，而目前项目大部分微服务化或者模块化，会分成很多个组件来部署，每个组件可能对应一个deployment.yaml,一个service.yaml,一个Ingress.yaml还可能存在各种依赖关系，这样一个项目如果有5个组件，很可能就有15个不同的yaml文件，这些yaml分散存放，如果某天进行项目恢复的话，很难知道部署顺序，依赖关系等，而所有这些包括</p><ul><li>基于yaml配置的集中存放</li><li>基于项目的打包</li><li>组件间的依赖</li></ul><p>但是这种方式部署，会有什么问题呢？</p><ul><li>如果使用之前部署单一应用，少数服务的应用，比较合适</li><li>但如果部署微服务项目，可能有几十个服务，每个服务都有一套yaml文件，需要维护大量的yaml文件，版本管理特别不方便</li></ul><p>Helm的引入，就是为了解决这个问题</p><ul><li>使用Helm可以把这些YAML文件作为整体管理</li><li>实现YAML文件高效复用</li><li>使用helm应用级别的版本管理</li></ul><h2 id="Helm介绍"><a href="#Helm介绍" class="headerlink" title="Helm介绍"></a>Helm介绍</h2><p>Helm是一个Kubernetes的包管理工具，就像Linux下的包管理器，如yum&#x2F;apt等，可以很方便的将之前打包好的yaml文件部署到kubernetes上。</p><p>Helm有三个重要概念</p><ul><li>helm：一个命令行客户端工具，主要用于Kubernetes应用chart的创建、打包、发布和管理</li><li>Chart：应用描述，一系列用于描述k8s资源相关文件的集合</li><li>Release：基于Chart的部署实体，一个chart被Helm运行后将会生成对应的release，将在K8S中创建出真实的运行资源对象。也就是应用级别的版本管理</li><li>Repository：用于发布和存储Chart的仓库</li></ul><h2 id="Helm组件及架构"><a href="#Helm组件及架构" class="headerlink" title="Helm组件及架构"></a>Helm组件及架构</h2><p>Helm采用客户端&#x2F;服务端架构，有如下组件组成</p><ul><li>Helm CLI是Helm客户端，可以在本地执行</li><li>Tiller是服务器端组件，在Kubernetes集群上运行，并管理Kubernetes应用程序</li><li>Repository是Chart仓库，Helm客户端通过HTTP协议来访问仓库中Chart索引文件和压缩包</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201119095458328.png"                      alt="image-20201119095458328"                ></p><h2 id="Helm-v3变化"><a href="#Helm-v3变化" class="headerlink" title="Helm v3变化"></a>Helm v3变化</h2><p>2019年11月13日，Helm团队发布了Helm v3的第一个稳定版本</p><p>该版本主要变化如下</p><ul><li><p>架构变化</p><ul><li>最明显的变化是Tiller的删除</li><li>V3版本删除Tiller</li><li>relesase可以在不同命名空间重用</li></ul></li></ul><p>V3之前</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118171523403.png"                      alt="image-20201118171523403"                ></p><p> V3版本</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118171956054.png"                      alt="image-20201118171956054"                ></p><h2 id="helm配置"><a href="#helm配置" class="headerlink" title="helm配置"></a>helm配置</h2><p>首先我们需要去 <a class="link"   href="https://helm.sh/docs/intro/quickstart/" >官网下载<i class="fas fa-external-link-alt"></i></a></p><ul><li>第一步，<a class="link"   href="https://github.com/helm/helm/releases" >下载helm<i class="fas fa-external-link-alt"></i></a>安装压缩文件，上传到linux系统中</li><li>第二步，解压helm压缩文件，把解压后的helm目录复制到 usr&#x2F;bin 目录中</li><li>使用命令：helm</li></ul><p>我们都知道yum需要配置yum源，那么helm就就要配置helm源</p><h2 id="helm仓库"><a href="#helm仓库" class="headerlink" title="helm仓库"></a>helm仓库</h2><p>添加仓库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm repo add 仓库名  仓库地址 </span><br></pre></td></tr></table></figure><p>例如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置微软源</span></span><br><span class="line">helm repo add stable http://mirror.azure.cn/kubernetes/charts</span><br><span class="line"><span class="comment"># 配置阿里源</span></span><br><span class="line">helm repo add aliyun https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span><br><span class="line"><span class="comment"># 配置google源</span></span><br><span class="line">helm repo add google https://kubernetes-charts.storage.googleapis.com/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新</span></span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure><p>然后可以查看我们添加的仓库地址</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看全部</span></span><br><span class="line">helm repo list</span><br><span class="line"><span class="comment"># 查看某个</span></span><br><span class="line">helm search repo stable</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118195732281.png"                      alt="image-20201118195732281"                ></p><p>或者可以删除我们添加的源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm repo remove stable</span><br></pre></td></tr></table></figure><h2 id="helm基本命令"><a href="#helm基本命令" class="headerlink" title="helm基本命令"></a>helm基本命令</h2><ul><li>chart install</li><li>chart upgrade</li><li>chart rollback</li></ul><h2 id="使用helm快速部署应用"><a href="#使用helm快速部署应用" class="headerlink" title="使用helm快速部署应用"></a>使用helm快速部署应用</h2><h3 id="使用命令搜索应用"><a href="#使用命令搜索应用" class="headerlink" title="使用命令搜索应用"></a>使用命令搜索应用</h3><p>首先我们使用命令，搜索我们需要安装的应用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 搜索 weave仓库</span></span><br><span class="line">helm search repo weave</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118200603643.png"                      alt="image-20201118200603643"                ></p><h3 id="根据搜索内容选择安装"><a href="#根据搜索内容选择安装" class="headerlink" title="根据搜索内容选择安装"></a>根据搜索内容选择安装</h3><p>搜索完成后，使用命令进行安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install ui aliyun/weave-scope</span><br></pre></td></tr></table></figure><p>可以通过下面命令，来下载yaml文件【如果】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f weave-scope.yaml</span><br></pre></td></tr></table></figure><p>安装完成后，通过下面命令即可查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm list</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118203727585.png"                      alt="image-20201118203727585"                ></p><p>同时可以通过下面命令，查看更新具体的信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm status ui</span><br></pre></td></tr></table></figure><p>但是我们通过查看 svc状态，发现没有对象暴露端口</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118205031343.png"                      alt="image-20201118205031343"                ></p><p>所以我们需要修改service的yaml文件，添加NodePort</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit svc ui-weave-scope</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118205129431.png"                      alt="image-20201118205129431"                ></p><p>这样就可以对外暴露端口了</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118205147631.png"                      alt="image-20201118205147631"                ></p><p>然后我们通过 ip + 32185 即可访问</p><h3 id="如果自己创建Chart"><a href="#如果自己创建Chart" class="headerlink" title="如果自己创建Chart"></a>如果自己创建Chart</h3><p>使用命令，自己创建Chart</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm create mychart</span><br></pre></td></tr></table></figure><p>创建完成后，我们就能看到在当前文件夹下，创建了一个 mychart目录</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118210755621.png"                      alt="image-20201118210755621"                ></p><h4 id="目录格式"><a href="#目录格式" class="headerlink" title="目录格式"></a>目录格式</h4><ul><li>templates：编写yaml文件存放到这个目录</li><li>values.yaml：存放的是全局的yaml文件</li><li>chart.yaml：当前chart属性配置信息</li></ul><h3 id="在templates文件夹创建两个文件"><a href="#在templates文件夹创建两个文件" class="headerlink" title="在templates文件夹创建两个文件"></a>在templates文件夹创建两个文件</h3><p>我们创建以下两个</p><ul><li>deployment.yaml</li><li>service.yaml</li></ul><p>我们可以通过下面命令创建出yaml文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导出deployment.yaml</span></span><br><span class="line">kubectl create deployment web1 --image=nginx --dry-run -o yaml &gt; deployment.yaml</span><br><span class="line"><span class="comment"># 导出service.yaml 【可能需要创建 deployment，不然会报错】</span></span><br><span class="line">kubectl expose deployment web1 --port=80 --target-port=80 --<span class="built_in">type</span>=NodePort --dry-run -o yaml &gt; service.yaml</span><br></pre></td></tr></table></figure><h3 id="安装mychart"><a href="#安装mychart" class="headerlink" title="安装mychart"></a>安装mychart</h3><p>执行命令创建</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install web1 mychart</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118213120916.png"                      alt="image-20201118213120916"                ></p><h3 id="应用升级"><a href="#应用升级" class="headerlink" title="应用升级"></a>应用升级</h3><p>当我们修改了mychart中的东西后，就可以进行升级操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm upgrade web1 mychart</span><br></pre></td></tr></table></figure><h2 id="chart模板使用"><a href="#chart模板使用" class="headerlink" title="chart模板使用"></a>chart模板使用</h2><p>通过传递参数，动态渲染模板，yaml内容动态从传入参数生成</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118213630083.png"                      alt="image-20201118213630083"                ></p><p>刚刚我们创建mychart的时候，看到有values.yaml文件，这个文件就是一些全局的变量，然后在templates中能取到变量的值，下面我们可以利用这个，来完成动态模板</p><ul><li>在values.yaml定义变量和值</li><li>具体yaml文件，获取定义变量值</li><li>yaml文件中大题有几个地方不同<ul><li>image</li><li>tag</li><li>label</li><li>port</li><li>replicas</li></ul></li></ul><h3 id="定义变量和值"><a href="#定义变量和值" class="headerlink" title="定义变量和值"></a>定义变量和值</h3><p>在values.yaml定义变量和值</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118214050899.png"                      alt="image-20201118214050899"                ></p><h3 id="获取变量和值"><a href="#获取变量和值" class="headerlink" title="获取变量和值"></a>获取变量和值</h3><p>我们通过表达式形式 使用全局变量  <code>&#123;&#123;.Values.变量名称&#125;&#125; </code></p><p>例如： <code>&#123;&#123;.Release.Name&#125;&#125;</code></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118214413203.png"                      alt="image-20201118214413203"                ></p><h3 id="安装应用"><a href="#安装应用" class="headerlink" title="安装应用"></a>安装应用</h3><p>在我们修改完上述的信息后，就可以尝试的创建应用了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install --dry-run web2 mychart</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/15_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFHelm/images/image-20201118214727058.png"                      alt="image-20201118214727058"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Helm就是一个包管理工具【类似于npm】&lt;/p&gt;
&lt;p&gt;&lt;img  
                     lazyload
                     src=&quot;/images/loading.svg&quot;
                     dat</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之使用kubeadm-ha脚本一键安装K8S</title>
    <link href="http://example.com/2022/08/24/k8s%E4%B9%8B%E4%BD%BF%E7%94%A8kubeadm-ha%E8%84%9A%E6%9C%AC%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85K8S/"/>
    <id>http://example.com/2022/08/24/k8s%E4%B9%8B%E4%BD%BF%E7%94%A8kubeadm-ha%E8%84%9A%E6%9C%AC%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85K8S/</id>
    <published>2022-08-23T21:17:21.000Z</published>
    <updated>2022-08-24T09:27:21.547Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用kubeadm-ha脚本一键安装K8S"><a href="#使用kubeadm-ha脚本一键安装K8S" class="headerlink" title="使用kubeadm-ha脚本一键安装K8S"></a>使用kubeadm-ha脚本一键安装K8S</h1><blockquote><p>Github地址：<a class="link"   href="https://github.com/TimeBye/kubeadm-ha" >https://github.com/TimeBye/kubeadm-ha<i class="fas fa-external-link-alt"></i></a></p></blockquote><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>官网的安装说明也很简单但是还有些细节还是没有提到，所以我自己照着官网的教程 补充了一些细节</p><h3 id="硬件系统要求"><a href="#硬件系统要求" class="headerlink" title="硬件系统要求"></a>硬件系统要求</h3><ul><li>Master节点：2C4G +</li><li>Worker节点：2C4G +</li></ul><p>使用centos7.7安装请按上面配置准备好3台centos,1台作为Master节点,2台Worker节点</p><p>本方式为1主2worker的配置</p><p>这是我的各个节点的配置</p><table><thead><tr><th>主机名</th><th>ip</th><th>配置</th></tr></thead><tbody><tr><td>k8s-master</td><td>192.168.177.130</td><td>2C4G</td></tr><tr><td>k8s-node1</td><td>192.168.177.131</td><td>2C2G</td></tr><tr><td>k8s-node2</td><td>192.168.177.132</td><td>2C2G</td></tr></tbody></table><h3 id="centos准备"><a href="#centos准备" class="headerlink" title="centos准备"></a>centos准备</h3><p><code>在安装之前需要准备一些基础的软件环境用于下载一键安装k8s的脚本和编辑配置</code></p><h4 id="centos网络准备"><a href="#centos网络准备" class="headerlink" title="centos网络准备"></a>centos网络准备</h4><p>安装时需要连接互联网下载各种软件 所以需要保证每个节点都可以访问外网</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping baidu.com</span><br></pre></td></tr></table></figure><p>建议关闭 <strong>CentOS</strong> 的防火墙</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld  &amp;&amp; systemctl <span class="built_in">disable</span> firewalld &amp;&amp; systemctl status firewalld </span><br></pre></td></tr></table></figure><p>同时需要保证各个节点间可以相互ping通</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping 其他节点ip</span><br></pre></td></tr></table></figure><h4 id="CentOS软件准备"><a href="#CentOS软件准备" class="headerlink" title="CentOS软件准备"></a>CentOS软件准备</h4><p>用 <strong>ssh</strong> 连接到 <strong>Master</strong> 节点上安装 Git</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install git -y</span><br></pre></td></tr></table></figure><h2 id="部署k8s前配置"><a href="#部署k8s前配置" class="headerlink" title="部署k8s前配置"></a>部署k8s前配置</h2><h4 id="下载部署脚本"><a href="#下载部署脚本" class="headerlink" title="下载部署脚本"></a>下载部署脚本</h4><p>在Master节点clone安装脚本 <a class="link"   href="https://github.com/TimeBye/kubeadm-ha" >脚本地址<i class="fas fa-external-link-alt"></i></a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --depth 1 https://github.com/TimeBye/kubeadm-ha</span><br></pre></td></tr></table></figure><p>进入到下载的部署脚本的目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd kubeadm-ha</span><br></pre></td></tr></table></figure><h4 id="安装-Ansible-运行环境"><a href="#安装-Ansible-运行环境" class="headerlink" title="安装 Ansible 运行环境"></a>安装 Ansible 运行环境</h4><p>在master节点安装Ansible环境</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ./install-ansible.sh</span><br></pre></td></tr></table></figure><h4 id="修改安装的配置文件"><a href="#修改安装的配置文件" class="headerlink" title="修改安装的配置文件"></a>修改安装的配置文件</h4><p>由于我是一个master两个node的方式构建的centos所以我们需要修改example&#x2F;hosts.s-master.ip.ini 文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi example/hosts.s-master.ip.ini </span><br></pre></td></tr></table></figure><p>具体要修改的就是 ip 和密码 其他的保持默认</p><p>我的hosts.s-master.ip.ini 文件预览</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">; 将所有节点信息在这里填写</span></span><br><span class="line"><span class="comment">;    第一个字段                  为远程服务器内网IP</span></span><br><span class="line"><span class="comment">;    第二个字段 ansible_port     为节点 sshd 监听端口</span></span><br><span class="line"><span class="comment">;    第三个字段 ansible_user     为节点远程登录用户名</span></span><br><span class="line"><span class="comment">;    第四个字段 ansible_ssh_pass 为节点远程登录用户密码</span></span><br><span class="line"><span class="section">[all]</span></span><br><span class="line">192.168.177.130 <span class="attr">ansible_port</span>=<span class="number">22</span> ansible_user=<span class="string">&quot;root&quot;</span> ansible_ssh_pass=<span class="string">&quot;moxi&quot;</span></span><br><span class="line">192.168.177.131 <span class="attr">ansible_port</span>=<span class="number">22</span> ansible_user=<span class="string">&quot;root&quot;</span> ansible_ssh_pass=<span class="string">&quot;moxi&quot;</span></span><br><span class="line">192.168.177.132 <span class="attr">ansible_port</span>=<span class="number">22</span> ansible_user=<span class="string">&quot;root&quot;</span> ansible_ssh_pass=<span class="string">&quot;moxi&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 单 master 节点不需要进行负载均衡，lb节点组留空。</span></span><br><span class="line"><span class="section">[lb]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 注意etcd集群必须是1,3,5,7...奇数个节点</span></span><br><span class="line"><span class="section">[etcd]</span></span><br><span class="line">192.168.177.130</span><br><span class="line">192.168.177.131</span><br><span class="line">192.168.177.132</span><br><span class="line"></span><br><span class="line"><span class="section">[kube-master]</span></span><br><span class="line">192.168.177.130</span><br><span class="line"></span><br><span class="line"><span class="section">[kube-worker]</span></span><br><span class="line">192.168.177.130</span><br><span class="line">192.168.177.131</span><br><span class="line">192.168.177.132</span><br><span class="line"></span><br><span class="line"><span class="comment">; 预留组，后续添加master节点使用</span></span><br><span class="line"><span class="section">[new-master]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 预留组，后续添加worker节点使用</span></span><br><span class="line"><span class="section">[new-worker]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 预留组，后续添加etcd节点使用</span></span><br><span class="line"><span class="section">[new-etcd]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 预留组，后续删除worker角色使用</span></span><br><span class="line"><span class="section">[del-worker]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 预留组，后续删除master角色使用</span></span><br><span class="line"><span class="section">[del-master]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 预留组，后续删除etcd角色使用</span></span><br><span class="line"><span class="section">[del-etcd]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 预留组，后续删除节点使用</span></span><br><span class="line"><span class="section">[del-node]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">;-------------------------------------- 以下为基础信息配置 ------------------------------------;</span></span><br><span class="line"><span class="section">[all:vars]</span></span><br><span class="line"><span class="comment">; 是否跳过节点物理资源校验，Master节点要求2c2g以上，Worker节点要求2c4g以上</span></span><br><span class="line"><span class="attr">skip_verify_node</span>=<span class="literal">true</span></span><br><span class="line"><span class="comment">; kubernetes版本</span></span><br><span class="line"><span class="attr">kube_version</span>=<span class="string">&quot;1.18.14&quot;</span></span><br><span class="line"><span class="comment">; 负载均衡器</span></span><br><span class="line"><span class="comment">;   有 nginx、openresty、haproxy、envoy  和 slb 可选，默认使用 nginx</span></span><br><span class="line"><span class="comment">;   为什么单 master 集群 apiserver 也使用了负载均衡请参与此讨论： https://github.com/TimeBye/kubeadm-ha/issues/8</span></span><br><span class="line"><span class="attr">lb_mode</span>=<span class="string">&quot;nginx&quot;</span></span><br><span class="line"><span class="comment">; 使用负载均衡后集群 apiserver ip，设置 lb_kube_apiserver_ip 变量，则启用负载均衡器 + keepalived</span></span><br><span class="line"><span class="comment">; lb_kube_apiserver_ip=&quot;192.168.56.15&quot;</span></span><br><span class="line"><span class="comment">; 使用负载均衡后集群 apiserver port</span></span><br><span class="line"><span class="attr">lb_kube_apiserver_port</span>=<span class="string">&quot;8443&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 网段选择：pod 和 service 的网段不能与服务器网段重叠，</span></span><br><span class="line"><span class="comment">; 若有重叠请配置 `kube_pod_subnet` 和 `kube_service_subnet` 变量设置 pod 和 service 的网段，示例参考：</span></span><br><span class="line"><span class="comment">;    如果服务器网段为：10.0.0.1/8</span></span><br><span class="line"><span class="comment">;       pod 网段可设置为：192.168.0.0/18</span></span><br><span class="line"><span class="comment">;       service 网段可设置为 192.168.64.0/18</span></span><br><span class="line"><span class="comment">;    如果服务器网段为：172.16.0.1/12</span></span><br><span class="line"><span class="comment">;       pod 网段可设置为：10.244.0.0/18</span></span><br><span class="line"><span class="comment">;       service 网段可设置为 10.244.64.0/18</span></span><br><span class="line"><span class="comment">;    如果服务器网段为：192.168.0.1/16</span></span><br><span class="line"><span class="comment">;       pod 网段可设置为：10.244.0.0/18</span></span><br><span class="line"><span class="comment">;       service 网段可设置为 10.244.64.0/18</span></span><br><span class="line"><span class="comment">; 集群pod ip段，默认掩码位 18 即 16384 个ip</span></span><br><span class="line"><span class="attr">kube_pod_subnet</span>=<span class="string">&quot;10.244.0.0/18&quot;</span></span><br><span class="line"><span class="comment">; 集群service ip段</span></span><br><span class="line"><span class="attr">kube_service_subnet</span>=<span class="string">&quot;10.244.64.0/18&quot;</span></span><br><span class="line"><span class="comment">; 分配给节点的 pod 子网掩码位，默认为 24 即 256 个ip，故使用这些默认值可以纳管 16384/256=64 个节点。</span></span><br><span class="line"><span class="attr">kube_network_node_prefix</span>=<span class="string">&quot;24&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; node节点最大 pod 数。数量与分配给节点的 pod 子网有关，ip 数应大于 pod 数。</span></span><br><span class="line"><span class="comment">; https://cloud.google.com/kubernetes-engine/docs/how-to/flexible-pod-cidr</span></span><br><span class="line"><span class="attr">kube_max_pods</span>=<span class="string">&quot;110&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 集群网络插件，目前支持flannel,calico</span></span><br><span class="line"><span class="attr">network_plugin</span>=<span class="string">&quot;calico&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">; 若服务器磁盘分为系统盘与数据盘，请修改以下路径至数据盘自定义的目录。</span></span><br><span class="line"><span class="comment">; Kubelet 根目录</span></span><br><span class="line"><span class="attr">kubelet_root_dir</span>=<span class="string">&quot;/var/lib/kubelet&quot;</span></span><br><span class="line"><span class="comment">; docker容器存储目录</span></span><br><span class="line"><span class="attr">docker_storage_dir</span>=<span class="string">&quot;/var/lib/docker&quot;</span></span><br><span class="line"><span class="comment">; Etcd 数据根目录</span></span><br><span class="line"><span class="attr">etcd_data_dir</span>=<span class="string">&quot;/var/lib/etcd&quot;</span></span><br></pre></td></tr></table></figure><h4 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h4><p>修改完配置文件后建议升级内核</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -i example/hosts.s-master.ip.ini 00-kernel.yml</span><br></pre></td></tr></table></figure><p>内核升级完毕后重启所有节点 在master node1 node2上执行</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><h2 id="开始部署k8s"><a href="#开始部署k8s" class="headerlink" title="开始部署k8s"></a>开始部署k8s</h2><p>等待所有的节点重启完成后进入脚本目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd kubeadm-ha</span><br></pre></td></tr></table></figure><h3 id="执行一键部署命令"><a href="#执行一键部署命令" class="headerlink" title="执行一键部署命令"></a>执行一键部署命令</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -i example/hosts.s-master.ip.ini 90-init-cluster.yml</span><br></pre></td></tr></table></figure><h3 id="查看节点运行情况"><a href="#查看节点运行情况" class="headerlink" title="查看节点运行情况"></a>查看节点运行情况</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><p>等待所有节点ready 即为创建成功</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME             STATUS   ROLES                AGE     VERSION</span><br><span class="line">192.168.28.128   Ready    etcd,worker          2m57s   v1.18.14</span><br><span class="line">192.168.28.80    Ready    etcd,master,worker   3m29s   v1.18.14</span><br><span class="line">192.168.28.89    Ready    etcd,worker          2m57s   v1.18.14</span><br></pre></td></tr></table></figure><h3 id="集群重置"><a href="#集群重置" class="headerlink" title="集群重置"></a>集群重置</h3><p>如果部署失败了，想要重置整个集群【包括数据】，执行下面脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -i example/hosts.s-master.ip.ini 99-reset-cluster.yml</span><br></pre></td></tr></table></figure><h2 id="部署kuboard"><a href="#部署kuboard" class="headerlink" title="部署kuboard"></a>部署kuboard</h2><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><p>因为我们需要拉取镜像，所以需要在服务器提前安装好Docker，首先配置一下Docker的阿里yum源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt;/etc/yum.repos.d/docker.repo&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[docker-ce-edge]</span></span><br><span class="line"><span class="string">name=Docker CE Edge - \$basearch</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/7/\$basearch/edge</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=1</span></span><br><span class="line"><span class="string">gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>然后yum方式安装docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum安装</span></span><br><span class="line">yum -y install docker-ce</span><br><span class="line"><span class="comment"># 查看docker版本</span></span><br><span class="line">docker --version  </span><br><span class="line"><span class="comment"># 开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line"><span class="comment"># 启动docker</span></span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure><p>配置docker的镜像源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/docker/daemon.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>然后重启docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h2 id="安装Kuboard【可选】"><a href="#安装Kuboard【可选】" class="headerlink" title="安装Kuboard【可选】"></a>安装Kuboard【可选】</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><strong>Kuboard</strong> 是一款免费的 <strong>Kubernetes</strong> 图形化管理工具，力图帮助用户快速在 <strong>Kubernetes</strong> 上落地微服务。</p><p>Kuboard文档：<a class="link"   href="https://kuboard.cn/" >https://kuboard.cn/<i class="fas fa-external-link-alt"></i></a></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><code>在master节点执行</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://kuboard.cn/install-script/kuboard.yaml</span><br><span class="line">kubectl apply -f https://addons.kuboard.cn/metrics-server/0.3.7/metrics-server.yaml</span><br></pre></td></tr></table></figure><p>查看 Kuboard 运行状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -l k8s.kuboard.cn/name=kuboard -n kube-system</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出结果如下所示。注意：如果是 <code>ContainerCreating</code> 那么需要等待一会</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NAME                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">kuboard-74c645f5df-cmrbc   1/1     Running   0          80s</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="访问Kuboard"><a href="#访问Kuboard" class="headerlink" title="访问Kuboard"></a>访问Kuboard</h3><p>Kuboard Service 使用了 NodePort 的方式暴露服务，NodePort 为 32567；您可以按如下方式访问 Kuboard。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 格式</span></span><br><span class="line">http://任意一个Worker节点的IP地址:32567/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 例如，我的访问地址如下所示</span></span><br><span class="line">http://192.168.177.130:32567/</span><br></pre></td></tr></table></figure><p>页面如下所示：</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/images/image-20210107211525789.png"                      alt="image-20210107211525789"                ></p><p>第一次访问需要输入token 我们获取一下 <strong>token</strong>， <code>在master节点执行</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> $(kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-user | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>) -o go-template=<span class="string">&#x27;&#123;&#123;.data.token&#125;&#125;&#x27;</span> | <span class="built_in">base64</span> -d)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>获取到的 <strong>token</strong>，然后粘贴到框中，我的 <strong>token</strong> 格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6ImY1eUZlc0RwUlZha0E3LWZhWXUzUGljNDM3SE0zU0Q4dzd5R3JTdXM2WEUifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJvYXJkLXVzZXItdG9rZW4tMmJsamsiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoia3Vib2FyZC11c2VyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiYzhlZDRmNDktNzM0Zi00MjU1LTljODUtMWI5MGI4MzU4ZWMzIiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmt1Ym9hcmQtdXNlciJ9.MujbwGnkL_qa3H14oKDT1zZ5Fzt16pWoaY52nT7fV5B2nNIRsB3Esd18S8ztHUJZLRGxAhBwu-utToi2YBb8pH9RfIeSXMezFZ6QhBbp0n5xYWeYETQYKJmes2FRcW-6jrbpvXlfUuPXqsbRX8qrnmSVEbcAms22CSSVhUbTz1kz8C7b1C4lpSGGuvdpNxgslNFZTFrcImpelpGSaIGEMUk1qdjKMROw8bV83pga4Y41Y6rJYE3hdnCkUA8w2SZOYuF2kT1DuZuKq3A53iLsvJ6Ps-gpli2HcoiB0NkeI_fJORXmYfcj5N2Csw6uGUDiBOr1T4Dto-i8SaApqmdcXg</span><br></pre></td></tr></table></figure><p>最后即可进入 <strong>kuboard</strong> 的 <strong>dashboard</strong> 界面</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/images/image-20210107211713726.png"                      alt="image-20210107211713726"                ></p><h3 id="卸载Kuboard"><a href="#卸载Kuboard" class="headerlink" title="卸载Kuboard"></a>卸载Kuboard</h3><p>当我们 <strong>kuboard</strong> 不想使用的时候，我们就可以直接卸载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f https://kuboard.cn/install-script/kuboard.yaml</span><br><span class="line">kubectl delete -f https://addons.kuboard.cn/metrics-server/0.3.7/metrics-server.yaml</span><br></pre></td></tr></table></figure><h2 id="Rancher部署【可选】"><a href="#Rancher部署【可选】" class="headerlink" title="Rancher部署【可选】"></a>Rancher部署【可选】</h2><blockquote><p>kuboard和rancher建议部署其中一个</p></blockquote><h3 id="helm安装"><a href="#helm安装" class="headerlink" title="helm安装"></a>helm安装</h3><p>使用helm部署rancher会方便很多，所以需要安装helm</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -O http://rancher-mirror.cnrancher.com/helm/v3.2.4/helm-v3.2.4-linux-amd64.tar.gz</span><br><span class="line">tar -zxvf helm-v3.2.4-linux-amd64.tar.gz</span><br><span class="line"><span class="built_in">mv</span> linux-amd64/helm /usr/local/bin</span><br></pre></td></tr></table></figure><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm version</span><br></pre></td></tr></table></figure><p>输入以下内容说明helm安装成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">version.BuildInfo&#123;Version:<span class="string">&quot;v3.2.4&quot;</span>, GitCommit:<span class="string">&quot;0ad800ef43d3b826f31a5ad8dfbb4fe05d143688&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, GoVersion:<span class="string">&quot;go1.13.12&quot;</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="添加rancher-chart仓库"><a href="#添加rancher-chart仓库" class="headerlink" title="添加rancher chart仓库"></a>添加rancher chart仓库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm repo add rancher-stable http://rancher-mirror.oss-cn-beijing.aliyuncs.com/server-charts/stable</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure><h3 id="安装rancher"><a href="#安装rancher" class="headerlink" title="安装rancher"></a>安装rancher</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">helm install rancher rancher-stable/rancher \</span><br><span class="line"> --create-namespace\</span><br><span class="line"> --namespace cattle-system \</span><br><span class="line"> --<span class="built_in">set</span> hostname=rancher.local.com</span><br></pre></td></tr></table></figure><h5 id="等待-Rancher-运行："><a href="#等待-Rancher-运行：" class="headerlink" title="等待 Rancher 运行："></a>等待 Rancher 运行：</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n cattle-system rollout status deploy/rancher</span><br></pre></td></tr></table></figure><p>输出信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Waiting <span class="keyword">for</span> deployment <span class="string">&quot;rancher&quot;</span> rollout to finish: 0 of 3 updated replicas are available...</span><br><span class="line">deployment <span class="string">&quot;rancher&quot;</span> successfully rolled out</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用kubeadm-ha脚本一键安装K8S&quot;&gt;&lt;a href=&quot;#使用kubeadm-ha脚本一键安装K8S&quot; class=&quot;headerlink&quot; title=&quot;使用kubeadm-ha脚本一键安装K8S&quot;&gt;&lt;/a&gt;使用kubeadm-ha脚本一键安装K8S&lt;/</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之核心技术Ingress</title>
    <link href="http://example.com/2022/08/23/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/"/>
    <id>http://example.com/2022/08/23/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/</id>
    <published>2022-08-23T08:30:37.000Z</published>
    <updated>2022-08-23T08:37:28.147Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>原来我们需要将端口号对外暴露，通过 ip + 端口号就可以进行访问</p><p>原来是使用Service中的NodePort来实现</p><ul><li>在每个节点上都会启动端口</li><li>在访问的时候通过任何节点，通过ip + 端口号就能实现访问</li></ul><p>但是NodePort还存在一些缺陷</p><ul><li>因为端口不能重复，所以每个端口只能使用一次，一个端口对应一个应用</li><li>实际访问中都是用域名，根据不同域名跳转到不同端口服务中</li></ul><h2 id="Ingress和Pod关系"><a href="#Ingress和Pod关系" class="headerlink" title="Ingress和Pod关系"></a>Ingress和Pod关系</h2><p>pod 和 ingress 是通过service进行关联的，而ingress作为统一入口，由service关联一组pod中</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/14_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/images/image-20201118102637839.png"                      alt="image-20201118102637839"                ></p><ul><li>首先service就是关联我们的pod</li><li>然后ingress作为入口，首先需要到service，然后发现一组pod</li><li>发现pod后，就可以做负载均衡等操作</li></ul><h2 id="Ingress工作流程"><a href="#Ingress工作流程" class="headerlink" title="Ingress工作流程"></a>Ingress工作流程</h2><p>在实际的访问中，我们都是需要维护很多域名， a.com  和  b.com</p><p>然后不同的域名对应的不同的Service，然后service管理不同的pod</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/14_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/images/image-20201118102858617.png"                      alt="image-20201118102858617"                ></p><p>需要注意，ingress不是内置的组件，需要我们单独的安装</p><h2 id="使用Ingress"><a href="#使用Ingress" class="headerlink" title="使用Ingress"></a>使用Ingress</h2><p>步骤如下所示</p><ul><li>部署ingress Controller【需要下载官方的】</li><li>创建ingress规则【对哪个Pod、名称空间配置规则】</li></ul><h3 id="创建Nginx-Pod"><a href="#创建Nginx-Pod" class="headerlink" title="创建Nginx Pod"></a>创建Nginx Pod</h3><p>创建一个nginx应用，然后对外暴露端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">kubectl create deployment web --image=nginx</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><p>对外暴露端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment web --port=80 --target-port=80 --<span class="built_in">type</span>:NodePort</span><br></pre></td></tr></table></figure><h3 id="部署-ingress-controller"><a href="#部署-ingress-controller" class="headerlink" title="部署 ingress controller"></a>部署 ingress controller</h3><p>下面我们来通过yaml的方式，部署我们的ingress，配置文件如下所示</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/14_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/images/image-20201118105427248.png"                      alt="image-20201118105427248"                ></p><p>这个文件里面，需要注意的是 hostNetwork: true，改成ture是为了让后面访问到</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f ingress-con.yaml</span><br></pre></td></tr></table></figure><p>通过这种方式，其实我们在外面就能访问，这里还需要在外面添加一层</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f ingress-con.yaml</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/14_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/images/image-20201118111256631.png"                      alt="image-20201118111256631"                ></p><p>最后通过下面命令，查看是否成功部署 ingress</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n ingress-nginx</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/14_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/images/image-20201118111424735.png"                      alt="image-20201118111424735"                ></p><h3 id="创建ingress规则文件"><a href="#创建ingress规则文件" class="headerlink" title="创建ingress规则文件"></a>创建ingress规则文件</h3><p>创建ingress规则文件，ingress-h.yaml</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/14_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/images/image-20201118111700534.png"                      alt="image-20201118111700534"                ></p><h3 id="添加域名访问规则"><a href="#添加域名访问规则" class="headerlink" title="添加域名访问规则"></a>添加域名访问规则</h3><p>在windows 的 hosts文件，添加域名访问规则【因为我们没有域名解析，所以只能这样做】</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/14_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/images/image-20201118112029820.png"                      alt="image-20201118112029820"                ></p><p>最后通过域名就能访问</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/14_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFIngress/images/image-20201118112212519.png"                      alt="image-20201118112212519"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;原来我们需要将端口号对外暴露，通过 ip + 端口号就可以进行访问&lt;/p&gt;
&lt;p&gt;原来是使用Service中的NodePort来实现&lt;/p&gt;</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之集群安全机制</title>
    <link href="http://example.com/2022/08/23/k8s%E4%B9%8B%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2022/08/23/k8s%E4%B9%8B%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/</id>
    <published>2022-08-23T07:55:34.000Z</published>
    <updated>2022-08-23T07:57:10.131Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>当我们访问K8S集群时，需要经过三个步骤完成具体操作</p><ul><li>认证</li><li>鉴权【授权】</li><li>准入控制</li></ul><p>进行访问的时候，都需要经过 apiserver， apiserver做统一协调，比如门卫</p><ul><li>访问过程中，需要证书、token、或者用户名和密码</li><li>如果访问pod需要serviceAccount</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118092356107.png"                      alt="image-20201118092356107"                ></p><h3 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h3><p>对外不暴露8080端口，只能内部访问，对外使用的端口6443</p><p>客户端身份认证常用方式</p><ul><li>https证书认证，基于ca证书</li><li>http token认证，通过token来识别用户</li><li>http基本认证，用户名 + 密码认证</li></ul><h3 id="鉴权"><a href="#鉴权" class="headerlink" title="鉴权"></a>鉴权</h3><p>基于RBAC进行鉴权操作</p><p>基于角色访问控制</p><h3 id="准入控制"><a href="#准入控制" class="headerlink" title="准入控制"></a>准入控制</h3><p>就是准入控制器的列表，如果列表有请求内容就通过，没有的话 就拒绝</p><h2 id="RBAC介绍"><a href="#RBAC介绍" class="headerlink" title="RBAC介绍"></a>RBAC介绍</h2><p>基于角色的访问控制，为某个角色设置访问内容，然后用户分配该角色后，就拥有该角色的访问权限</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118093949893.png"                      alt="image-20201118093949893"                ></p><p>k8s中有默认的几个角色</p><ul><li>role：特定命名空间访问权限</li><li>ClusterRole：所有命名空间的访问权限</li></ul><p>角色绑定</p><ul><li>roleBinding：角色绑定到主体</li><li>ClusterRoleBinding：集群角色绑定到主体</li></ul><p>主体</p><ul><li>user：用户</li><li>group：用户组</li><li>serviceAccount：服务账号</li></ul><h2 id="RBAC实现鉴权"><a href="#RBAC实现鉴权" class="headerlink" title="RBAC实现鉴权"></a>RBAC实现鉴权</h2><ul><li>创建命名空间</li></ul><h3 id="创建命名空间"><a href="#创建命名空间" class="headerlink" title="创建命名空间"></a>创建命名空间</h3><p>我们可以首先查看已经存在的命名空间</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get namespace</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118094516426.png"                      alt="image-20201118094516426"                ></p><p>然后我们创建一个自己的命名空间  roledemo</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create ns roledemo</span><br></pre></td></tr></table></figure><h3 id="命名空间创建Pod"><a href="#命名空间创建Pod" class="headerlink" title="命名空间创建Pod"></a>命名空间创建Pod</h3><p>为什么要创建命名空间？因为如果不创建命名空间的话，默认是在default下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run nginx --image=nginx -n roledemo</span><br></pre></td></tr></table></figure><h3 id="创建角色"><a href="#创建角色" class="headerlink" title="创建角色"></a>创建角色</h3><p>我们通过 rbac-role.yaml进行创建</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118094851338.png"                      alt="image-20201118094851338"                ></p><p>tip：这个角色只对pod 有 get、list权限</p><p>然后通过 yaml创建我们的role</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">kubectl apply -f rbac-role.yaml</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">kubectl get role -n roledemo</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118095141786.png"                      alt="image-20201118095141786"                ></p><h3 id="创建角色绑定"><a href="#创建角色绑定" class="headerlink" title="创建角色绑定"></a>创建角色绑定</h3><p>我们还是通过 role-rolebinding.yaml 的方式，来创建我们的角色绑定</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118095248052.png"                      alt="image-20201118095248052"                ></p><p>然后创建我们的角色绑定</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建角色绑定</span></span><br><span class="line">kubectl apply -f rbac-rolebinding.yaml</span><br><span class="line"><span class="comment"># 查看角色绑定</span></span><br><span class="line">kubectl get role, rolebinding -n roledemo</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118095357067.png"                      alt="image-20201118095357067"                ></p><h3 id="使用证书识别身份"><a href="#使用证书识别身份" class="headerlink" title="使用证书识别身份"></a>使用证书识别身份</h3><p>我们首先得有一个 rbac-user.sh 证书脚本</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118095541427.png"                      alt="image-20201118095541427"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118095627954.png"                      alt="image-20201118095627954"                ></p><p>这里包含了很多证书文件，在TSL目录下，需要复制过来</p><p>通过下面命令执行我们的脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./rbac-user.sh</span><br></pre></td></tr></table></figure><p>最后我们进行测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用get命令查看 pod 【有权限】</span></span><br><span class="line">kubectl get pods -n roledemo</span><br><span class="line"><span class="comment"># 用get命令查看svc 【没权限】</span></span><br><span class="line">kubectl get svc -n roledmeo</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/13_Kubernetes%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/images/image-20201118100051043.png"                      alt="image-20201118100051043"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;当我们访问K8S集群时，需要经过三个步骤完成具体操作&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;认证&lt;/li&gt;
&lt;li&gt;鉴权【授权】&lt;/li&gt;
&lt;li&gt;准入</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之配置管理</title>
    <link href="http://example.com/2022/08/23/k8s%E4%B9%8B%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/"/>
    <id>http://example.com/2022/08/23/k8s%E4%B9%8B%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/</id>
    <published>2022-08-23T07:08:46.000Z</published>
    <updated>2022-08-23T07:11:04.495Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h2><p>Secret的主要作用就是加密数据，然后存在etcd里面，让Pod容器以挂载Volume方式进行访问</p><p>场景：用户名 和 密码进行加密</p><p>一般场景的是对某个字符串进行base64编码 进行加密</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> -n <span class="string">&#x27;admin&#x27;</span> | <span class="built_in">base64</span></span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201117212037668.png"                      alt="image-20201117212037668"                ></p><h3 id="变量形式挂载到Pod"><a href="#变量形式挂载到Pod" class="headerlink" title="变量形式挂载到Pod"></a>变量形式挂载到Pod</h3><ul><li>创建secret加密数据的yaml文件    secret.yaml</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201117212124476.png"                      alt="image-20201117212124476"                ></p><p>然后使用下面命令创建一个pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f secret.yaml</span><br></pre></td></tr></table></figure><p>通过get命令查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118084010980.png"                      alt="image-20201118084010980"                ></p><p>然后我们通过下面的命令，进入到我们的容器内部</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it mypod bash</span><br></pre></td></tr></table></figure><p>然后我们就可以输出我们的值，这就是以变量的形式挂载到我们的容器中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出用户</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$SECRET_USERNAME</span></span><br><span class="line"><span class="comment"># 输出密码</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$SECRET_PASSWORD</span></span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118084137942.png"                      alt="image-20201118084137942"                ></p><p>最后如果我们要删除这个Pod，就可以使用这个命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f secret-val.yaml</span><br></pre></td></tr></table></figure><h3 id="数据卷形式挂载"><a href="#数据卷形式挂载" class="headerlink" title="数据卷形式挂载"></a>数据卷形式挂载</h3><p>首先我们创建一个 secret-val.yaml 文件</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118084321590.png"                      alt="image-20201118084321590"                ></p><p>然后创建我们的 Pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据配置创建容器</span></span><br><span class="line">kubectl apply -f secret-val.yaml</span><br><span class="line"><span class="comment"># 进入容器</span></span><br><span class="line">kubectl <span class="built_in">exec</span> -it mypod bash</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line"><span class="built_in">ls</span> /etc/foo</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118084707478.png"                      alt="image-20201118084707478"                ></p><h2 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h2><p>ConfigMap作用是存储不加密的数据到etcd中，让Pod以变量或数据卷Volume挂载到容器中</p><p>应用场景：配置文件</p><h3 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h3><p>首先我们需要创建一个配置文件 <code>redis.properties</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis.port=127.0.0.1</span><br><span class="line">redis.port=6379</span><br><span class="line">redis.password=123456</span><br></pre></td></tr></table></figure><h3 id="创建ConfigMap"><a href="#创建ConfigMap" class="headerlink" title="创建ConfigMap"></a>创建ConfigMap</h3><p>我们使用命令创建configmap</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create configmap redis-config --from-file=redis.properties</span><br></pre></td></tr></table></figure><p>然后查看详细信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe cm redis-config</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118085503534.png"                      alt="image-20201118085503534"                ></p><h3 id="Volume数据卷形式挂载"><a href="#Volume数据卷形式挂载" class="headerlink" title="Volume数据卷形式挂载"></a>Volume数据卷形式挂载</h3><p>首先我们需要创建一个 <code>cm.yaml</code></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118085847424.png"                      alt="image-20201118085847424"                ></p><p>然后使用该yaml创建我们的pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">kubectl apply -f cm.yaml</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118090634869.png"                      alt="image-20201118090634869"                ></p><p>最后我们通过命令就可以查看结果输出了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs mypod</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118090712780.png"                      alt="image-20201118090712780"                ></p><h3 id="以变量的形式挂载Pod"><a href="#以变量的形式挂载Pod" class="headerlink" title="以变量的形式挂载Pod"></a>以变量的形式挂载Pod</h3><p>首先我们也有一个 myconfig.yaml文件，声明变量信息，然后以configmap创建</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118090911260.png"                      alt="image-20201118090911260"                ></p><p>然后我们就可以创建我们的配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建pod</span></span><br><span class="line">kubectl apply -f myconfig.yaml</span><br><span class="line"><span class="comment"># 获取</span></span><br><span class="line">kubectl get cm</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118091042287.png"                      alt="image-20201118091042287"                ></p><p>然后我们创建完该pod后，我们就需要在创建一个  config-var.yaml 来使用我们的配置信息</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118091249520.png"                      alt="image-20201118091249520"                ></p><p>最后我们查看输出</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs mypod</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/12_Kubernetes%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86/images/image-20201118091448252.png"                      alt="image-20201118091448252"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Secret&quot;&gt;&lt;a href=&quot;#Secret&quot; class=&quot;headerlink&quot; title=&quot;Secret&quot;&gt;&lt;/a&gt;Secret&lt;/h2&gt;&lt;p&gt;Secret的主要作用就是加密数据，然后存在etcd里面，让Pod容器以挂载Volume方式进行访问&lt;/p&gt;</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之控制器Controller详解</title>
    <link href="http://example.com/2022/08/23/k8s%E4%B9%8B%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2022/08/23/k8s%E4%B9%8B%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/</id>
    <published>2022-08-23T03:23:05.000Z</published>
    <updated>2022-08-23T03:24:44.762Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Statefulset"><a href="#Statefulset" class="headerlink" title="Statefulset"></a>Statefulset</h2><p>Statefulset主要是用来部署有状态应用</p><p>对于StatefulSet中的Pod，每个Pod挂载自己独立的存储，如果一个Pod出现故障，从其他节点启动一个同样名字的Pod，要挂载上原来Pod的存储继续以它的状态提供服务。</p><h3 id="无状态应用"><a href="#无状态应用" class="headerlink" title="无状态应用"></a>无状态应用</h3><p>我们原来使用 deployment，部署的都是无状态的应用，那什么是无状态应用？</p><ul><li>认为Pod都是一样的</li><li>没有顺序要求</li><li>不考虑应用在哪个node上运行</li><li>能够进行随意伸缩和扩展</li></ul><h3 id="有状态应用"><a href="#有状态应用" class="headerlink" title="有状态应用"></a>有状态应用</h3><p>上述的因素都需要考虑到</p><ul><li>让每个Pod独立的</li><li>让每个Pod独立的，保持Pod启动顺序和唯一性</li><li>唯一的网络标识符，持久存储</li><li>有序，比如mysql中的主从</li></ul><p>适合StatefulSet的业务包括数据库服务MySQL 和 PostgreSQL，集群化管理服务Zookeeper、etcd等有状态服务</p><p>StatefulSet的另一种典型应用场景是作为一种比普通容器更稳定可靠的模拟虚拟机的机制。传统的虚拟机正是一种有状态的宠物，运维人员需要不断地维护它，容器刚开始流行时，我们用容器来模拟虚拟机使用，所有状态都保存在容器里，而这已被证明是非常不安全、不可靠的。</p><p>使用StatefulSet，Pod仍然可以通过漂移到不同节点提供高可用，而存储也可以通过外挂的存储来提供<br>高可靠性，StatefulSet做的只是将确定的Pod与确定的存储关联起来保证状态的连续性。</p><h3 id="部署有状态应用"><a href="#部署有状态应用" class="headerlink" title="部署有状态应用"></a>部署有状态应用</h3><p>无头service， ClusterIp：none</p><p>这里就需要使用 StatefulSet部署有状态应用</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117202950336.png"                      alt="image-20201117202950336"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117203130867.png"                      alt="image-20201117203130867"                ></p><p>然后通过查看pod，能否发现每个pod都有唯一的名称</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117203217016.png"                      alt="image-20201117203217016"                ></p><p>然后我们在查看service，发现是无头的service</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117203245641.png"                      alt="image-20201117203245641"                ></p><p>这里有状态的约定，肯定不是简简单单通过名称来进行约定，而是更加复杂的操作</p><ul><li>deployment：是有身份的，有唯一标识</li><li>statefulset：根据主机名 + 按照一定规则生成域名</li></ul><p>每个pod有唯一的主机名，并且有唯一的域名</p><ul><li>格式：主机名称.service名称.名称空间.svc.cluster.local</li><li>举例：nginx-statefulset-0.default.svc.cluster.local</li></ul><h2 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h2><p>DaemonSet 即后台支撑型服务，主要是用来部署守护进程</p><p>长期伺服型和批处理型的核心在业务应用，可能有些节点运行多个同类业务的Pod，有些节点上又没有这类的Pod运行；而后台支撑型服务的核心关注点在K8S集群中的节点(物理机或虚拟机)，要保证每个节点上都有一个此类Pod运行。节点可能是所有集群节点，也可能是通过 nodeSelector选定的一些特定节点。典型的后台支撑型服务包括：存储、日志和监控等。在每个节点上支撑K8S集群运行的服务。</p><p>守护进程在我们每个节点上，运行的是同一个pod，新加入的节点也同样运行在同一个pod里面</p><ul><li>例子：在每个node节点安装数据采集工具</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117204430836.png"                      alt="image-20201117204430836"                ></p><p>这里是不是一个FileBeat镜像，主要是为了做日志采集工作</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117204810350.png"                      alt="image-20201117204810350"                ></p><p>进入某个 Pod里面，进入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it ds-test-cbk6v bash</span><br></pre></td></tr></table></figure><p>通过该命令后，我们就能看到我们内部收集的日志信息了</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117204912838.png"                      alt="image-20201117204912838"                ></p><h2 id="Job和CronJob"><a href="#Job和CronJob" class="headerlink" title="Job和CronJob"></a>Job和CronJob</h2><p>一次性任务 和 定时任务</p><ul><li>一次性任务：一次性执行完就结束</li><li>定时任务：周期性执行</li></ul><p>Job是K8S中用来控制批处理型任务的API对象。批处理业务与长期伺服业务的主要区别就是批处理业务的运行有头有尾，而长期伺服业务在用户不停止的情况下永远运行。Job管理的Pod根据用户的设置把任务成功完成就自动退出了。成功完成的标志根据不同的 spec.completions 策略而不同：单Pod型任务有一个Pod成功就标志完成；定数成功行任务保证有N个任务全部成功；工作队列性任务根据应用确定的全局成功而标志成功。</p><h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><p>Job也即一次性任务</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117205635945.png"                      alt="image-20201117205635945"                ></p><p>使用下面命令，能够看到目前已经存在的Job</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get <span class="built_in">jobs</span></span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117205948374.png"                      alt="image-20201117205948374"                ></p><p>在计算完成后，通过命令查看，能够发现该任务已经完成</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117210031725.png"                      alt="image-20201117210031725"                ></p><p>我们可以通过查看日志，查看到一次性任务的结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs pi-qpqff</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117210110343.png"                      alt="image-20201117210110343"                ></p><h3 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob"></a>CronJob</h3><p>定时任务，cronjob.yaml如下所示</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117210309069.png"                      alt="image-20201117210309069"                ></p><p>这里面的命令就是每个一段时间，这里是通过 cron 表达式配置的，通过 schedule字段</p><p>然后下面命令就是每个一段时间输出 </p><p>我们首先用上述的配置文件，创建一个定时任务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f cronjob.yaml</span><br></pre></td></tr></table></figure><p>创建完成后，我们就可以通过下面命令查看定时任务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get cronjobs</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117210611783.png"                      alt="image-20201117210611783"                ></p><p>我们可以通过日志进行查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs hello-1599100140-wkn79</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117210722556.png"                      alt="image-20201117210722556"                ></p><p>然后每次执行，就会多出一个 pod</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/11_Kubernetes%E6%8E%A7%E5%88%B6%E5%99%A8Controller%E8%AF%A6%E8%A7%A3/images/image-20201117210751068.png"                      alt="image-20201117210751068"                ></p><h2 id="删除svc-和-statefulset"><a href="#删除svc-和-statefulset" class="headerlink" title="删除svc 和 statefulset"></a>删除svc 和 statefulset</h2><p>使用下面命令，可以删除我们添加的svc 和 statefulset</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete svc web</span><br><span class="line"></span><br><span class="line">kubectl delete statefulset --all</span><br></pre></td></tr></table></figure><h2 id="Replication-Controller"><a href="#Replication-Controller" class="headerlink" title="Replication Controller"></a>Replication Controller</h2><p>Replication Controller 简称 <strong>RC</strong>，是K8S中的复制控制器。RC是K8S集群中最早的保证Pod高可用的API对象。通过监控运行中的Pod来保证集群中运行指定数目的Pod副本。指定的数目可以是多个也可以是1个；少于指定数目，RC就会启动新的Pod副本；多于指定数目，RC就会杀死多余的Pod副本。</p><p>即使在指定数目为1的情况下，通过RC运行Pod也比直接运行Pod更明智，因为RC也可以发挥它高可用的能力，保证永远有一个Pod在运行。RC是K8S中较早期的技术概念，只适用于长期伺服型的业务类型，比如控制Pod提供高可用的Web服务。</p><h3 id="Replica-Set"><a href="#Replica-Set" class="headerlink" title="Replica Set"></a>Replica Set</h3><p>Replica Set 检查 RS，也就是副本集。RS是新一代的RC，提供同样高可用能力，区别主要在于RS后来居上，能够支持更多种类的匹配模式。副本集对象一般不单独使用，而是作为Deployment的理想状态参数来使用</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Statefulset&quot;&gt;&lt;a href=&quot;#Statefulset&quot; class=&quot;headerlink&quot; title=&quot;Statefulset&quot;&gt;&lt;/a&gt;Statefulset&lt;/h2&gt;&lt;p&gt;Statefulset主要是用来部署有状态应用&lt;/p&gt;
&lt;p&gt;对于S</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之核心技术Service</title>
    <link href="http://example.com/2022/08/23/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFService/"/>
    <id>http://example.com/2022/08/23/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFService/</id>
    <published>2022-08-23T01:57:16.000Z</published>
    <updated>2022-08-23T01:58:45.892Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面我们了解到 Deployment 只是保证了支撑服务的微服务Pod的数量，但是没有解决如何访问这些服务的问题。一个Pod只是一个运行服务的实例，随时可能在一个节点上停止，在另一个节点以一个新的IP启动一个新的Pod，因此不能以确定的IP和端口号提供服务。</p><p>要稳定地提供服务需要服务发现和负载均衡能力。服务发现完成的工作，是针对客户端访问的服务，找到对应的后端服务实例。在K8S集群中，客户端需要访问的服务就是Service对象。每个Service会对应一个集群内部有效的虚拟IP，集群内部通过虚拟IP访问一个服务。</p><p>在K8S集群中，微服务的负载均衡是由kube-proxy实现的。kube-proxy是k8s集群内部的负载均衡器。它是一个分布式代理服务器，在K8S的每个节点上都有一个；这一设计体现了它的伸缩性优势，需要访问服务的节点越多，提供负载均衡能力的kube-proxy就越多，高可用节点也随之增多。与之相比，我们平时在服务器端使用反向代理作负载均衡，还要进一步解决反向代理的高可用问题。</p><h2 id="Service存在的意义"><a href="#Service存在的意义" class="headerlink" title="Service存在的意义"></a>Service存在的意义</h2><h3 id="防止Pod失联【服务发现】"><a href="#防止Pod失联【服务发现】" class="headerlink" title="防止Pod失联【服务发现】"></a>防止Pod失联【服务发现】</h3><p>因为Pod每次创建都对应一个IP地址，而这个IP地址是短暂的，每次随着Pod的更新都会变化，假设当我们的前端页面有多个Pod时候，同时后端也多个Pod，这个时候，他们之间的相互访问，就需要通过注册中心，拿到Pod的IP地址，然后去访问对应的Pod</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/10_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFService/images/image-20201117093606710.png"                      alt="image-20201117093606710"                ></p><h3 id="定义Pod访问策略【负载均衡】"><a href="#定义Pod访问策略【负载均衡】" class="headerlink" title="定义Pod访问策略【负载均衡】"></a>定义Pod访问策略【负载均衡】</h3><p>页面前端的Pod访问到后端的Pod，中间会通过Service一层，而Service在这里还能做负载均衡，负载均衡的策略有很多种实现策略，例如：</p><ul><li>随机</li><li>轮询</li><li>响应比</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/10_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFService/images/image-20201117093902459.png"                      alt="image-20201117093902459"                ></p><h2 id="Pod和Service的关系"><a href="#Pod和Service的关系" class="headerlink" title="Pod和Service的关系"></a>Pod和Service的关系</h2><p>这里Pod 和 Service 之间还是根据 label 和 selector 建立关联的 【和Controller一样】</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/10_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFService/images/image-20201117094142491.png"                      alt="image-20201117094142491"                ></p><p>我们在访问service的时候，其实也是需要有一个ip地址，这个ip肯定不是pod的ip地址，而是 虚拟IP <code>vip</code> </p><h2 id="Service常用类型"><a href="#Service常用类型" class="headerlink" title="Service常用类型"></a>Service常用类型</h2><p>Service常用类型有三种</p><ul><li>ClusterIp：集群内部访问</li><li>NodePort：对外访问应用使用</li><li>LoadBalancer：对外访问应用使用，公有云</li></ul><h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>我们可以导出一个文件 包含service的配置信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment web --port=80 --target-port=80 --dry-run -o yaml &gt; service.yaml</span><br></pre></td></tr></table></figure><p>service.yaml 如下所示</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">loadBalancer:</span> &#123;&#125;</span><br></pre></td></tr></table></figure><p>如果我们没有做设置的话，默认使用的是第一种方式 ClusterIp，也就是只能在集群内部使用，我们可以添加一个type字段，用来设置我们的service类型</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">loadBalancer:</span> &#123;&#125;</span><br></pre></td></tr></table></figure><p>修改完命令后，我们使用创建一个pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f service.yaml</span><br></pre></td></tr></table></figure><p>然后能够看到，已经成功修改为 NodePort类型了，最后剩下的一种方式就是LoadBalanced：对外访问应用使用公有云</p><p>node一般是在内网进行部署，而外网一般是不能访问到的，那么如何访问的呢？</p><ul><li>找到一台可以通过外网访问机器，安装nginx，反向代理</li><li>手动把可以访问的节点添加到nginx中</li></ul><p>如果我们使用LoadBalancer，就会有负载均衡的控制器，类似于nginx的功能，就不需要自己添加到nginx上</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;前面我们了解到 Deployment 只是保证了支撑服务的微服务Pod的数量，但是没有解决如何访问这些服务的问题。一个Pod只是一个运行服务</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之核心技术Controller</title>
    <link href="http://example.com/2022/08/23/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/"/>
    <id>http://example.com/2022/08/23/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/</id>
    <published>2022-08-23T01:28:56.000Z</published>
    <updated>2022-08-23T01:32:02.815Z</updated>
    
    <content type="html"><![CDATA[<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><ul><li>什么是Controller</li><li>Pod和Controller的关系</li><li>Deployment控制器应用场景</li><li>yaml文件字段说明</li><li>Deployment控制器部署应用</li><li>升级回滚</li><li>弹性伸缩</li></ul><h2 id="什么是Controller"><a href="#什么是Controller" class="headerlink" title="什么是Controller"></a>什么是Controller</h2><p>Controller是在集群上管理和运行容器的对象，Controller是实际存在的，Pod是虚拟机的</p><h2 id="Pod和Controller的关系"><a href="#Pod和Controller的关系" class="headerlink" title="Pod和Controller的关系"></a>Pod和Controller的关系</h2><p>Pod是通过Controller实现应用的运维，比如弹性伸缩，滚动升级等</p><p>Pod 和 Controller之间是通过label标签来建立关系，同时Controller又被称为控制器工作负载</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201116092431237.png"                      alt="image-20201116092431237"                ></p><h2 id="Deployment控制器应用"><a href="#Deployment控制器应用" class="headerlink" title="Deployment控制器应用"></a>Deployment控制器应用</h2><ul><li>Deployment控制器可以部署无状态应用</li><li>管理Pod和ReplicaSet</li><li>部署，滚动升级等功能</li><li>应用场景：web服务，微服务</li></ul><p>Deployment表示用户对K8S集群的一次更新操作。Deployment是一个比RS( Replica Set, RS) 应用模型更广的 API 对象，可以是创建一个新的服务，更新一个新的服务，也可以是滚动升级一个服务。滚动升级一个服务，实际是创建一个新的RS，然后逐渐将新 RS 中副本数增加到理想状态，将旧RS中的副本数减少到0的复合操作。</p><p>这样一个复合操作用一个RS是不好描述的，所以用一个更通用的Deployment来描述。以K8S的发展方向，未来对所有长期伺服型的业务的管理，都会通过Deployment来管理。</p><h2 id="Deployment部署应用"><a href="#Deployment部署应用" class="headerlink" title="Deployment部署应用"></a>Deployment部署应用</h2><p>之前我们也使用Deployment部署过应用，如下代码所示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectrl create deployment web --image=nginx</span><br></pre></td></tr></table></figure><p>但是上述代码不是很好的进行复用，因为每次我们都需要重新输入代码，所以我们都是通过YAML进行配置</p><p>但是我们可以尝试使用上面的代码创建一个镜像【只是尝试，不会创建】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment web --image=nginx --dry-run -o yaml &gt; nginx.yaml</span><br></pre></td></tr></table></figure><p>然后输出一个yaml配置文件 <code>nginx.yml</code> ，配置文件如下所示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    app: web</span><br><span class="line">  name: web</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  strategy: &#123;&#125;</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        app: web</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">        resources: &#123;&#125;</span><br><span class="line">status: &#123;&#125;</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201116093638951.png"                      alt="image-20201116093638951"                ></p><h3 id="使用YAML创建Pod"><a href="#使用YAML创建Pod" class="headerlink" title="使用YAML创建Pod"></a>使用YAML创建Pod</h3><p>通过刚刚的代码，我们已经生成了YAML文件，下面我们就可以使用该配置文件快速创建Pod镜像了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f nginx.yaml</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201116094046007.png"                      alt="image-20201116094046007"                ></p><p>但是因为这个方式创建的，我们只能在集群内部进行访问，所以我们还需要对外暴露端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment web --port=80 --<span class="built_in">type</span>=NodePort --target-port=80 --name=web1</span><br></pre></td></tr></table></figure><p>关于上述命令，有几个参数</p><ul><li>–port：就是我们内部的端口号</li><li>–target-port：就是暴露外面访问的端口号</li><li>–name：名称</li><li>–type：类型</li></ul><p>同理，我们一样可以导出对应的配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment web --port=80 --<span class="built_in">type</span>=NodePort --target-port=80 --name=web1 -o yaml &gt; web1.yaml</span><br></pre></td></tr></table></figure><p>得到的web1.yaml如下所示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: <span class="string">&quot;2020-11-16T02:26:53Z&quot;</span></span><br><span class="line">  labels:</span><br><span class="line">    app: web</span><br><span class="line">  managedFields:</span><br><span class="line">  - apiVersion: v1</span><br><span class="line">    fieldsType: FieldsV1</span><br><span class="line">    fieldsV1:</span><br><span class="line">      f:metadata:</span><br><span class="line">        f:labels:</span><br><span class="line">          .: &#123;&#125;</span><br><span class="line">          f:app: &#123;&#125;</span><br><span class="line">      f:spec:</span><br><span class="line">        f:externalTrafficPolicy: &#123;&#125;</span><br><span class="line">        f:ports:</span><br><span class="line">          .: &#123;&#125;</span><br><span class="line">          k:&#123;<span class="string">&quot;port&quot;</span>:80,<span class="string">&quot;protocol&quot;</span>:<span class="string">&quot;TCP&quot;</span>&#125;:</span><br><span class="line">            .: &#123;&#125;</span><br><span class="line">            f:port: &#123;&#125;</span><br><span class="line">            f:protocol: &#123;&#125;</span><br><span class="line">            f:targetPort: &#123;&#125;</span><br><span class="line">        f:selector:</span><br><span class="line">          .: &#123;&#125;</span><br><span class="line">          f:app: &#123;&#125;</span><br><span class="line">        f:sessionAffinity: &#123;&#125;</span><br><span class="line">        f:<span class="built_in">type</span>: &#123;&#125;</span><br><span class="line">    manager: kubectl</span><br><span class="line">    operation: Update</span><br><span class="line">    time: <span class="string">&quot;2020-11-16T02:26:53Z&quot;</span></span><br><span class="line">  name: web2</span><br><span class="line">  namespace: default</span><br><span class="line">  resourceVersion: <span class="string">&quot;113693&quot;</span></span><br><span class="line">  selfLink: /api/v1/namespaces/default/services/web2</span><br><span class="line">  uid: d570437d-a6b4-4456-8dfb-950f09534516</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: 10.104.174.145</span><br><span class="line">  externalTrafficPolicy: Cluster</span><br><span class="line">  ports:</span><br><span class="line">  - nodePort: 32639</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">  selector:</span><br><span class="line">    app: web</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">status:</span><br><span class="line">  loadBalancer: &#123;&#125;</span><br></pre></td></tr></table></figure><p>然后我们可以通过下面的命令来查看对外暴露的服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods,svc</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201116104021357.png"                      alt="image-20201116104021357"                ></p><p>然后我们访问对应的url，即可看到 nginx了 <code>http://192.168.177.130:32639/</code></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201116104131968.png"                      alt="image-20201116104131968"                ></p><h2 id="升级回滚和弹性伸缩"><a href="#升级回滚和弹性伸缩" class="headerlink" title="升级回滚和弹性伸缩"></a>升级回滚和弹性伸缩</h2><ul><li>升级：  假设从版本为1.14 升级到 1.15 ，这就叫应用的升级【升级可以保证服务不中断】</li><li>回滚：从版本1.15 变成 1.14，这就叫应用的回滚</li><li>弹性伸缩：我们根据不同的业务场景，来改变Pod的数量对外提供服务，这就是弹性伸缩</li></ul><h3 id="应用升级和回滚"><a href="#应用升级和回滚" class="headerlink" title="应用升级和回滚"></a>应用升级和回滚</h3><p>首先我们先创建一个 1.14版本的Pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    app: web</span><br><span class="line">  name: web</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: web</span><br><span class="line">  strategy: &#123;&#125;</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      creationTimestamp: null</span><br><span class="line">      labels:</span><br><span class="line">        app: web</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx:1.14</span><br><span class="line">        name: nginx</span><br><span class="line">        resources: &#123;&#125;</span><br><span class="line">status: &#123;&#125;</span><br></pre></td></tr></table></figure><p>我们先指定版本为1.14，然后开始创建我们的Pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f nginx.yaml</span><br></pre></td></tr></table></figure><p>同时，我们使用docker images命令，就能看到我们成功拉取到了一个 1.14版本的镜像</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/08/23/IAsYKHfiPc43BD8.png"                      alt="image-20201116105710966"                ></p><p>我们使用下面的命令，可以将nginx从 1.14 升级到 1.15</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">set</span> image deployment web nginx=nginx:1.15</span><br></pre></td></tr></table></figure><p>在我们执行完命令后，能看到升级的过程</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/08/23/IAsYKHfiPc43BD8.png"                                     ></p><ul><li>首先是开始的nginx 1.14版本的Pod在运行，然后 1.15版本的在创建</li><li>然后在1.15版本创建完成后，就会暂停1.14版本</li><li>最后把1.14版本的Pod移除，完成我们的升级</li></ul><p>我们在下载 1.15版本，容器就处于ContainerCreating状态，然后下载完成后，就用 1.15版本去替换1.14版本了，这么做的好处就是：升级可以保证服务不中断</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201116111614085.png"                      alt="image-20201116111614085"                ></p><p>我们到我们的node2节点上，查看我们的 docker images;</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201116111315000.png"                      alt="image-20201116111315000"                ></p><p>能够看到，我们已经成功拉取到了 1.15版本的nginx了</p><h4 id="查看升级状态"><a href="#查看升级状态" class="headerlink" title="查看升级状态"></a>查看升级状态</h4><p>下面可以，查看升级状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout status deployment web</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/08/23/gtfxZRDHXB6vLpW.png"                      alt="image-20201116112139645"                ></p><h4 id="查看历史版本"><a href="#查看历史版本" class="headerlink" title="查看历史版本"></a>查看历史版本</h4><p>我们还可以查看历史版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout <span class="built_in">history</span> deployment web</span><br></pre></td></tr></table></figure><h4 id="应用回滚"><a href="#应用回滚" class="headerlink" title="应用回滚"></a>应用回滚</h4><p>我们可以使用下面命令，完成回滚操作，也就是回滚到上一个版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment web</span><br></pre></td></tr></table></figure><p>然后我们就可以查看状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout status deployment web</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201116112524601.png"                      alt="image-20201116112524601"                ></p><p>同时我们还可以回滚到指定版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment web --to-revision=2</span><br></pre></td></tr></table></figure><h3 id="弹性伸缩"><a href="#弹性伸缩" class="headerlink" title="弹性伸缩"></a>弹性伸缩</h3><p>弹性伸缩，也就是我们通过命令一下创建多个副本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment web --replicas=10</span><br></pre></td></tr></table></figure><p>能够清晰看到，我们一下创建了10个副本</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/9_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFController/images/image-20201117092841865.png"                      alt="image-20201117092841865"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;内容&quot;&gt;&lt;a href=&quot;#内容&quot; class=&quot;headerlink&quot; title=&quot;内容&quot;&gt;&lt;/a&gt;内容&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;什么是Controller&lt;/li&gt;
&lt;li&gt;Pod和Controller的关系&lt;/li&gt;
&lt;li&gt;Deployment控制器应</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之核心技术Pod</title>
    <link href="http://example.com/2022/08/22/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/"/>
    <id>http://example.com/2022/08/22/k8s%E4%B9%8B%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/</id>
    <published>2022-08-22T09:18:52.000Z</published>
    <updated>2022-08-22T09:23:19.578Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Pod概述"><a href="#Pod概述" class="headerlink" title="Pod概述"></a>Pod概述</h2><p>Pod是K8S系统中可以创建和管理的最小单元，是资源对象模型中由用户创建或部署的最小资源对象模型，也是在K8S上运行容器化应用的资源对象，其它的资源对象都是用来支撑或者扩展Pod对象功能的，比如控制器对象是用来管控Pod对象的，Service或者Ingress资源对象是用来暴露Pod引用对象的，PersistentVolume资源对象是用来为Pod提供存储等等，K8S不会直接处理容器，而是Pod，Pod是由一个或多个container组成。</p><p>Pod是Kubernetes的最重要概念，每一个Pod都有一个特殊的被称为 “根容器”的Pause容器。Pause容器对应的镜像属于Kubernetes平台的一部分，除了Pause容器，每个Pod还包含一个或多个紧密相关的用户业务容器。</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114185528215.png"                      alt="image-20201114185528215"                ></p><h3 id="Pod基本概念"><a href="#Pod基本概念" class="headerlink" title="Pod基本概念"></a>Pod基本概念</h3><ul><li>最小部署的单元</li><li>Pod里面是由一个或多个容器组成【一组容器的集合】</li><li>一个pod中的容器是共享网络命名空间</li><li>Pod是短暂的</li><li>每个Pod包含一个或多个紧密相关的用户业务容器</li></ul><h3 id="Pod存在的意义"><a href="#Pod存在的意义" class="headerlink" title="Pod存在的意义"></a>Pod存在的意义</h3><ul><li>创建容器使用docker，一个docker对应一个容器，一个容器运行一个应用进程</li><li>Pod是多进程设计，运用多个应用程序，也就是一个Pod里面有多个容器，而一个容器里面运行一个应用程序</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114190018948.png"                      alt="image-20201114190018948"                ></p><ul><li>Pod的存在是为了亲密性应用<ul><li>两个应用之间进行交互</li><li>网络之间的调用【通过127.0.0.1 或 socket】</li><li>两个应用之间需要频繁调用</li></ul></li></ul><p>Pod是在K8S集群中运行部署应用或服务的最小单元，它是可以支持多容器的。Pod的设计理念是支持多个容器在一个Pod中共享网络地址和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。同时Pod对多容器的支持是K8S中最基础的设计理念。在生产环境中，通常是由不同的团队各自开发构建自己的容器镜像，在部署的时候组合成一个微服务对外提供服务。</p><p>Pod是K8S集群中所有业务类型的基础，可以把Pod看作运行在K8S集群上的小机器人，不同类型的业务就需要不同类型的小机器人去执行。目前K8S的业务主要可以分为以下几种</p><ul><li>长期伺服型：long-running</li><li>批处理型：batch</li><li>节点后台支撑型：node-daemon</li><li>有状态应用型：stateful application</li></ul><p>上述的几种类型，分别对应的小机器人控制器为：Deployment、Job、DaemonSet 和 StatefulSet  (后面将介绍控制器)</p><h2 id="Pod实现机制"><a href="#Pod实现机制" class="headerlink" title="Pod实现机制"></a>Pod实现机制</h2><p>主要有以下两大机制</p><ul><li>共享网络</li><li>共享存储</li></ul><h3 id="共享网络"><a href="#共享网络" class="headerlink" title="共享网络"></a>共享网络</h3><p>容器本身之间相互隔离的，一般是通过 <strong>namespace</strong> 和 <strong>group</strong> 进行隔离，那么Pod里面的容器如何实现通信？</p><ul><li>首先需要满足前提条件，也就是容器都在同一个<strong>namespace</strong>之间</li></ul><p>关于Pod实现原理，首先会在Pod会创建一个根容器： <code>pause容器</code>，然后我们在创建业务容器 【nginx，redis 等】，在我们创建业务容器的时候，会把它添加到 <code>info容器</code> 中</p><p>而在 <code>info容器</code> 中会独立出  ip地址，mac地址，port 等信息，然后实现网络的共享</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114190913859.png"                      alt="image-20201114190913859"                ></p><p>完整步骤如下</p><ul><li>通过 Pause 容器，把其它业务容器加入到Pause容器里，让所有业务容器在同一个名称空间中，可以实现网络共享</li></ul><h3 id="共享存储"><a href="#共享存储" class="headerlink" title="共享存储"></a>共享存储</h3><p>Pod持久化数据，专门存储到某个地方中</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114193124160.png"                      alt="image-20201114193124160"                ></p><p>使用 Volumn数据卷进行共享存储，案例如下所示</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114193341993.png"                      alt="image-20201114193341993"                ></p><h2 id="Pod镜像拉取策略"><a href="#Pod镜像拉取策略" class="headerlink" title="Pod镜像拉取策略"></a>Pod镜像拉取策略</h2><p>我们以具体实例来说，拉取策略就是 <code>imagePullPolicy</code></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114193605230.png"                      alt="image-20201114193605230"                ></p><p>拉取策略主要分为了以下几种</p><ul><li>IfNotPresent：默认值，镜像在宿主机上不存在才拉取</li><li>Always：每次创建Pod都会重新拉取一次镜像</li><li>Never：Pod永远不会主动拉取这个镜像</li></ul><h2 id="Pod资源限制"><a href="#Pod资源限制" class="headerlink" title="Pod资源限制"></a>Pod资源限制</h2><p>也就是我们Pod在进行调度的时候，可以对调度的资源进行限制，例如我们限制 Pod调度是使用的资源是 2C4G，那么在调度对应的node节点时，只会占用对应的资源，对于不满足资源的节点，将不会进行调度</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114194057920.png"                      alt="image-20201114194057920"                ></p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>我们在下面的地方进行资源的限制</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114194245517.png"                      alt="image-20201114194245517"                ></p><p>这里分了两个部分</p><ul><li>request：表示调度所需的资源</li><li>limits：表示最大所占用的资源</li></ul><h2 id="Pod重启机制"><a href="#Pod重启机制" class="headerlink" title="Pod重启机制"></a>Pod重启机制</h2><p>因为Pod中包含了很多个容器，假设某个容器出现问题了，那么就会触发Pod重启机制</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114194722125.png"                      alt="image-20201114194722125"                ></p><p>重启策略主要分为以下三种</p><ul><li>Always：当容器终止退出后，总是重启容器，默认策略 【nginx等，需要不断提供服务】</li><li>OnFailure：当容器异常退出（退出状态码非0）时，才重启容器。</li><li>Never：当容器终止退出，从不重启容器 【批量任务】</li></ul><h2 id="Pod健康检查"><a href="#Pod健康检查" class="headerlink" title="Pod健康检查"></a>Pod健康检查</h2><p>通过容器检查，原来我们使用下面的命令来检查</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod</span><br></pre></td></tr></table></figure><p>但是有的时候，程序可能出现了 <strong>Java</strong> 堆内存溢出，程序还在运行，但是不能对外提供服务了，这个时候就不能通过 容器检查来判断服务是否可用了</p><p>这个时候就可以使用应用层面的检查</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 存活检查，如果检查失败，将杀死容器，根据Pod的restartPolicy【重启策略】来操作</span></span><br><span class="line">livenessProbe</span><br><span class="line"></span><br><span class="line"><span class="comment"># 就绪检查，如果检查失败，Kubernetes会把Pod从Service endpoints中剔除</span></span><br><span class="line">readinessProbe</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114195807564.png"                      alt="image-20201114195807564"                ></p><p>Probe支持以下三种检查方式</p><ul><li>http Get：发送HTTP请求，返回200 - 400 范围状态码为成功</li><li>exec：执行Shell命令返回状态码是0为成功</li><li>tcpSocket：发起TCP Socket建立成功</li></ul><h2 id="Pod调度策略"><a href="#Pod调度策略" class="headerlink" title="Pod调度策略"></a>Pod调度策略</h2><h3 id="创建Pod流程"><a href="#创建Pod流程" class="headerlink" title="创建Pod流程"></a>创建Pod流程</h3><ul><li>首先创建一个pod，然后创建一个API Server 和 Etcd【把创建出来的信息存储在etcd中】</li><li>然后创建 Scheduler，监控API Server是否有新的Pod，如果有的话，会通过调度算法，把pod调度某个node上</li><li>在node节点，会通过 <code>kubelet -- apiserver </code> 读取etcd 拿到分配在当前node节点上的pod，然后通过docker创建容器</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114201611308.png"                      alt="image-20201114201611308"                ></p><h3 id="影响Pod调度的属性"><a href="#影响Pod调度的属性" class="headerlink" title="影响Pod调度的属性"></a>影响Pod调度的属性</h3><p>Pod资源限制对Pod的调度会有影响</p><h4 id="根据request找到足够node节点进行调度"><a href="#根据request找到足够node节点进行调度" class="headerlink" title="根据request找到足够node节点进行调度"></a>根据request找到足够node节点进行调度</h4><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114194245517.png"                      alt="image-20201114194245517"                ></p><h4 id="节点选择器标签影响Pod调度"><a href="#节点选择器标签影响Pod调度" class="headerlink" title="节点选择器标签影响Pod调度"></a>节点选择器标签影响Pod调度</h4><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114202456151.png"                      alt="image-20201114202456151"                ></p><p>关于节点选择器，其实就是有两个环境，然后环境之间所用的资源配置不同</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114202643905.png"                      alt="image-20201114202643905"                ></p><p>我们可以通过以下命令，给我们的节点新增标签，然后节点选择器就会进行调度了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label node node1 env_role=prod</span><br></pre></td></tr></table></figure><h4 id="节点亲和性"><a href="#节点亲和性" class="headerlink" title="节点亲和性"></a>节点亲和性</h4><p>节点亲和性 <strong>nodeAffinity</strong> 和 之前nodeSelector 基本一样的，根据节点上标签约束来决定Pod调度到哪些节点上</p><ul><li>硬亲和性：约束条件必须满足</li><li>软亲和性：尝试满足，不保证</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114203433939.png"                      alt="image-20201114203433939"                ></p><p>支持常用操作符：in、NotIn、Exists、Gt、Lt、DoesNotExists</p><p>反亲和性：就是和亲和性刚刚相反，如 NotIn、DoesNotExists等</p><h2 id="污点和污点容忍"><a href="#污点和污点容忍" class="headerlink" title="污点和污点容忍"></a>污点和污点容忍</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>nodeSelector 和 NodeAffinity，都是Prod调度到某些节点上，属于Pod的属性，是在调度的时候实现的。</p><p>Taint 污点：节点不做普通分配调度，是节点属性</p><h3 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h3><ul><li>专用节点【限制ip】</li><li>配置特定硬件的节点【固态硬盘】</li><li>基于Taint驱逐【在node1不放，在node2放】</li></ul><h3 id="查看污点情况"><a href="#查看污点情况" class="headerlink" title="查看污点情况"></a>查看污点情况</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe node k8smaster | grep Taint</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114204124819.png"                      alt="image-20201114204124819"                ></p><p>污点值有三个</p><ul><li>NoSchedule：一定不被调度</li><li>PreferNoSchedule：尽量不被调度【也有被调度的几率】</li><li>NoExecute：不会调度，并且还会驱逐Node已有Pod</li></ul><h3 id="未节点添加污点"><a href="#未节点添加污点" class="headerlink" title="未节点添加污点"></a>未节点添加污点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node [node] key=value:污点的三个值</span><br></pre></td></tr></table></figure><p>举例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node k8snode1 env_role=<span class="built_in">yes</span>:NoSchedule</span><br></pre></td></tr></table></figure><h3 id="删除污点"><a href="#删除污点" class="headerlink" title="删除污点"></a>删除污点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node k8snode1 env_role:NoSchedule-</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114210022883.png"                      alt="image-20201114210022883"                ></p><h3 id="演示"><a href="#演示" class="headerlink" title="演示"></a>演示</h3><p>我们现在创建多个Pod，查看最后分配到Node上的情况</p><p>首先我们创建一个 nginx 的pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment web --image=nginx</span><br></pre></td></tr></table></figure><p>然后使用命令查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -o wide</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114204917548.png"                      alt="image-20201114204917548"                ></p><p>我们可以非常明显的看到，这个Pod已经被分配到 k8snode1 节点上了</p><p>下面我们把pod复制5份，在查看情况pod情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment web --replicas=5</span><br></pre></td></tr></table></figure><p>我们可以发现，因为master节点存在污点的情况，所以节点都被分配到了 node1 和 node2节点上</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114205135282.png"                      alt="image-20201114205135282"                ></p><p>我们可以使用下面命令，把刚刚我们创建的pod都删除</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete deployment web</span><br></pre></td></tr></table></figure><p>现在给了更好的演示污点的用法，我们现在给 node1节点打上污点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node k8snode1 env_role=<span class="built_in">yes</span>:NoSchedule</span><br></pre></td></tr></table></figure><p>然后我们查看污点是否成功添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe node k8snode1 | grep Taint</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114205516154.png"                      alt="image-20201114205516154"                ></p><p>然后我们在创建一个 pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建nginx pod</span></span><br><span class="line">kubectl create deployment web --image=nginx</span><br><span class="line"><span class="comment"># 复制五次</span></span><br><span class="line">kubectl scale deployment web --replicas=5</span><br></pre></td></tr></table></figure><p>然后我们在进行查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -o wide</span><br></pre></td></tr></table></figure><p>我们能够看到现在所有的pod都被分配到了 k8snode2上，因为刚刚我们给node1节点设置了污点</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114205654867.png"                      alt="image-20201114205654867"                ></p><p>最后我们可以删除刚刚添加的污点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl taint node k8snode1 env_role:NoSchedule-</span><br></pre></td></tr></table></figure><h3 id="污点容忍"><a href="#污点容忍" class="headerlink" title="污点容忍"></a>污点容忍</h3><p>污点容忍就是某个节点可能被调度，也可能不被调度</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/8_Kubernetes%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AFPod/images/image-20201114210146123.png"                      alt="image-20201114210146123"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Pod概述&quot;&gt;&lt;a href=&quot;#Pod概述&quot; class=&quot;headerlink&quot; title=&quot;Pod概述&quot;&gt;&lt;/a&gt;Pod概述&lt;/h2&gt;&lt;p&gt;Pod是K8S系统中可以创建和管理的最小单元，是资源对象模型中由用户创建或部署的最小资源对象模型，也是在K8S上运行</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之YAML文件详解</title>
    <link href="http://example.com/2022/08/22/k8s%E4%B9%8BYAML%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2022/08/22/k8s%E4%B9%8BYAML%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/</id>
    <published>2022-08-22T07:57:21.000Z</published>
    <updated>2022-08-22T07:59:47.583Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>k8s 集群中对资源管理和资源对象编排部署都可以通过声明样式（YAML）文件来解决，也就是可以把需要对资源对象操作编辑到YAML 格式文件中，我们把这种文件叫做资源清单文件，通过kubectl 命令直接使用资源清单文件就可以实现对大量的资源对象进行编排部署了。一般在我们开发的时候，都是通过配置YAML文件来部署集群的。</p><p>YAML文件：就是资源清单文件，用于资源编排</p><h2 id="YAML文件介绍"><a href="#YAML文件介绍" class="headerlink" title="YAML文件介绍"></a>YAML文件介绍</h2><h3 id="YAML概述"><a href="#YAML概述" class="headerlink" title="YAML概述"></a>YAML概述</h3><p>YAML ：仍是一种标记语言。为了强调这种语言以数据做为中心，而不是以标记语言为重点。</p><p>YAML 是一个可读性高，用来表达数据序列的格式。</p><h3 id="YAML-基本语法"><a href="#YAML-基本语法" class="headerlink" title="YAML 基本语法"></a>YAML 基本语法</h3><ul><li>使用空格做为缩进</li><li>缩进的空格数目不重要，只要相同层级的元素左侧对齐即可</li><li>低版本缩进时不允许使用Tab 键，只允许使用空格</li><li>使用#标识注释，从这个字符一直到行尾，都会被解释器忽略</li><li>使用 — 表示新的yaml文件开始</li></ul><h3 id="YAML-支持的数据结构"><a href="#YAML-支持的数据结构" class="headerlink" title="YAML 支持的数据结构"></a>YAML 支持的数据结构</h3><h4 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h4><p>键值对的集合，又称为映射(mapping) &#x2F; 哈希（hashes） &#x2F; 字典（dictionary）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对象类型：对象的一组键值对，使用冒号结构表示</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">Tom</span></span><br><span class="line"><span class="attr">age:</span> <span class="number">18</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># yaml 也允许另一种写法，将所有键值对写成一个行内对象</span></span><br><span class="line"><span class="attr">hash:</span> &#123;<span class="attr">name:</span> <span class="string">Tom</span>, <span class="attr">age:</span> <span class="number">18</span>&#125;</span><br></pre></td></tr></table></figure><h4 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数组类型：一组连词线开头的行，构成一个数组</span></span><br><span class="line">People</span><br><span class="line">- Tom</span><br><span class="line">- Jack</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数组也可以采用行内表示法</span></span><br><span class="line">People: [Tom, Jack]</span><br></pre></td></tr></table></figure><h2 id="YAML文件组成部分"><a href="#YAML文件组成部分" class="headerlink" title="YAML文件组成部分"></a>YAML文件组成部分</h2><p>主要分为了两部分，一个是控制器的定义 和 被控制的对象</p><h3 id="控制器的定义"><a href="#控制器的定义" class="headerlink" title="控制器的定义"></a>控制器的定义</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/7_Kubernetes%E9%9B%86%E7%BE%A4YAML%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/images/image-20201114110444032.png"                      alt="image-20201114110444032"                ></p><h3 id="被控制的对象"><a href="#被控制的对象" class="headerlink" title="被控制的对象"></a>被控制的对象</h3><p>包含一些 镜像，版本、端口等</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/08/22/3OTlVXjvmxgsPwz.png"                      alt="image-20201114110600165"                ></p><h3 id="属性说明"><a href="#属性说明" class="headerlink" title="属性说明"></a>属性说明</h3><p>在一个YAML文件的控制器定义中，有很多属性名称</p><table><thead><tr><th align="center">属性名称</th><th align="center">介绍</th></tr></thead><tbody><tr><td align="center">apiVersion</td><td align="center">API版本</td></tr><tr><td align="center">kind</td><td align="center">资源类型</td></tr><tr><td align="center">metadata</td><td align="center">资源元数据</td></tr><tr><td align="center">spec</td><td align="center">资源规格</td></tr><tr><td align="center">replicas</td><td align="center">副本数量</td></tr><tr><td align="center">selector</td><td align="center">标签选择器</td></tr><tr><td align="center">template</td><td align="center">Pod模板</td></tr><tr><td align="center">metadata</td><td align="center">Pod元数据</td></tr><tr><td align="center">spec</td><td align="center">Pod规格</td></tr><tr><td align="center">containers</td><td align="center">容器配置</td></tr></tbody></table><h2 id="如何快速编写YAML文件"><a href="#如何快速编写YAML文件" class="headerlink" title="如何快速编写YAML文件"></a>如何快速编写YAML文件</h2><p>一般来说，我们很少自己手写YAML文件，因为这里面涉及到了很多内容，我们一般都会借助工具来创建</p><h3 id="使用kubectl-create命令"><a href="#使用kubectl-create命令" class="headerlink" title="使用kubectl create命令"></a>使用kubectl create命令</h3><p>这种方式一般用于资源没有部署的时候，我们可以直接创建一个YAML配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 尝试运行,并不会真正的创建镜像</span></span><br><span class="line">kubectl create deployment web --image=nginx -o yaml --dry-run</span><br></pre></td></tr></table></figure><p>或者我们可以输出到一个文件中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment web --image=nginx -o yaml --dry-run &gt; hello.yaml</span><br></pre></td></tr></table></figure><p>然后我们就在文件中直接修改即可</p><h3 id="使用kubectl-get命令导出yaml文件"><a href="#使用kubectl-get命令导出yaml文件" class="headerlink" title="使用kubectl get命令导出yaml文件"></a>使用kubectl get命令导出yaml文件</h3><p>可以首先查看一个目前已经部署的镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deploy</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/7_Kubernetes%E9%9B%86%E7%BE%A4YAML%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/images/image-20201114113115649.png"                      alt="image-20201114113115649"                ></p><p>然后我们导出 nginx的配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deploy nginx -o=yaml --<span class="built_in">export</span> &gt; nginx.yaml</span><br></pre></td></tr></table></figure><p>然后会生成一个 <code>nginx.yaml</code> 的配置文件</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/7_Kubernetes%E9%9B%86%E7%BE%A4YAML%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/images/image-20201114184538797.png"                      alt="image-20201114184538797"                ></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;k8s 集群中对资源管理和资源对象编排部署都可以通过声明样式（YAML）文件来解决，也就是可以把需要对资源对象操作编辑到YAML 格式文件中</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之集群管理工具kubectl</title>
    <link href="http://example.com/2022/08/22/k8s%E4%B9%8B%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7kubectl/"/>
    <id>http://example.com/2022/08/22/k8s%E4%B9%8B%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7kubectl/</id>
    <published>2022-08-22T07:06:20.000Z</published>
    <updated>2022-08-22T07:10:24.809Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>kubectl是Kubernetes集群的命令行工具，通过kubectl能够对集群本身进行管理，并能够在集群上进行容器化应用的安装和部署</p><h2 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h2><p>命令格式如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl [<span class="built_in">command</span>] [<span class="built_in">type</span>] [name] [flags]</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>command：指定要对资源执行的操作，例如create、get、describe、delete</li><li>type：指定资源类型，资源类型是大小写敏感的，开发者能够以单数 、复数 和 缩略的形式</li></ul><p>例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod pod1</span><br><span class="line">kubectl get pods pod1</span><br><span class="line">kubectl get po pod1</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/6_Kubernetes%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7kubectl/images/image-20201114095544185.png"                      alt="image-20201114095544185"                ></p><ul><li>name：指定资源的名称，名称也是大小写敏感的，如果省略名称，则会显示所有的资源，例如</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><ul><li>flags：指定可选的参数，例如，可用 -s 或者 -server参数指定Kubernetes API server的地址和端口</li></ul><h2 id="常见命令"><a href="#常见命令" class="headerlink" title="常见命令"></a>常见命令</h2><h3 id="kubectl-help-获取更多信息"><a href="#kubectl-help-获取更多信息" class="headerlink" title="kubectl help 获取更多信息"></a>kubectl help 获取更多信息</h3><p>通过 help命令，能够获取帮助信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取kubectl的命令</span></span><br><span class="line">kubectl --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取某个命令的介绍和使用</span></span><br><span class="line">kubectl get --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><h3 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h3><p>常见的基础命令</p><table><thead><tr><th align="center">命令</th><th align="center">介绍</th></tr></thead><tbody><tr><td align="center">create</td><td align="center">通过文件名或标准输入创建资源</td></tr><tr><td align="center">expose</td><td align="center">将一个资源公开为一个新的Service</td></tr><tr><td align="center">run</td><td align="center">在集群中运行一个特定的镜像</td></tr><tr><td align="center">set</td><td align="center">在对象上设置特定的功能</td></tr><tr><td align="center">get</td><td align="center">显示一个或多个资源</td></tr><tr><td align="center">explain</td><td align="center">文档参考资料</td></tr><tr><td align="center">edit</td><td align="center">使用默认的编辑器编辑一个资源</td></tr><tr><td align="center">delete</td><td align="center">通过文件名，标准输入，资源名称或标签来删除资源</td></tr></tbody></table><h3 id="部署命令"><a href="#部署命令" class="headerlink" title="部署命令"></a>部署命令</h3><table><thead><tr><th align="center">命令</th><th align="center">介绍</th></tr></thead><tbody><tr><td align="center">rollout</td><td align="center">管理资源的发布</td></tr><tr><td align="center">rolling-update</td><td align="center">对给定的复制控制器滚动更新</td></tr><tr><td align="center">scale</td><td align="center">扩容或缩容Pod数量，Deployment、ReplicaSet、RC或Job</td></tr><tr><td align="center">autoscale</td><td align="center">创建一个自动选择扩容或缩容并设置Pod数量</td></tr></tbody></table><h3 id="集群管理命令"><a href="#集群管理命令" class="headerlink" title="集群管理命令"></a>集群管理命令</h3><table><thead><tr><th>命令</th><th>介绍</th></tr></thead><tbody><tr><td>certificate</td><td>修改证书资源</td></tr><tr><td>cluster-info</td><td>显示集群信息</td></tr><tr><td>top</td><td>显示资源(CPU&#x2F;M)</td></tr><tr><td>cordon</td><td>标记节点不可调度</td></tr><tr><td>uncordon</td><td>标记节点可被调度</td></tr><tr><td>drain</td><td>驱逐节点上的应用，准备下线维护</td></tr><tr><td>taint</td><td>修改节点taint标记</td></tr><tr><td></td><td></td></tr></tbody></table><h3 id="故障和调试命令"><a href="#故障和调试命令" class="headerlink" title="故障和调试命令"></a>故障和调试命令</h3><table><thead><tr><th align="center">命令</th><th align="center">介绍</th></tr></thead><tbody><tr><td align="center">describe</td><td align="center">显示特定资源或资源组的详细信息</td></tr><tr><td align="center">logs</td><td align="center">在一个Pod中打印一个容器日志，如果Pod只有一个容器，容器名称是可选的</td></tr><tr><td align="center">attach</td><td align="center">附加到一个运行的容器</td></tr><tr><td align="center">exec</td><td align="center">执行命令到容器</td></tr><tr><td align="center">port-forward</td><td align="center">转发一个或多个</td></tr><tr><td align="center">proxy</td><td align="center">运行一个proxy到Kubernetes API Server</td></tr><tr><td align="center">cp</td><td align="center">拷贝文件或目录到容器中</td></tr><tr><td align="center">auth</td><td align="center">检查授权</td></tr></tbody></table><h3 id="其它命令"><a href="#其它命令" class="headerlink" title="其它命令"></a>其它命令</h3><table><thead><tr><th align="center">命令</th><th align="center">介绍</th></tr></thead><tbody><tr><td align="center">apply</td><td align="center">通过文件名或标准输入对资源应用配置</td></tr><tr><td align="center">patch</td><td align="center">使用补丁修改、更新资源的字段</td></tr><tr><td align="center">replace</td><td align="center">通过文件名或标准输入替换一个资源</td></tr><tr><td align="center">convert</td><td align="center">不同的API版本之间转换配置文件</td></tr><tr><td align="center">label</td><td align="center">更新资源上的标签</td></tr><tr><td align="center">annotate</td><td align="center">更新资源上的注释</td></tr><tr><td align="center">completion</td><td align="center">用于实现kubectl工具自动补全</td></tr><tr><td align="center">api-versions</td><td align="center">打印受支持的API版本</td></tr><tr><td align="center">config</td><td align="center">修改kubeconfig文件（用于访问API，比如配置认证信息）</td></tr><tr><td align="center">help</td><td align="center">所有命令帮助</td></tr><tr><td align="center">plugin</td><td align="center">运行一个命令行插件</td></tr><tr><td align="center">version</td><td align="center">打印客户端和服务版本信息</td></tr></tbody></table><h3 id="目前使用的命令"><a href="#目前使用的命令" class="headerlink" title="目前使用的命令"></a>目前使用的命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个nginx镜像</span></span><br><span class="line">kubectl create deployment nginx --image=nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对外暴露端口</span></span><br><span class="line">kubectl expose deployment nginx --port=80 --<span class="built_in">type</span>=NodePort</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看资源</span></span><br><span class="line">kubectl get pod, svc</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;kubectl是Kubernetes集群的命令行工具，通过kubectl能够对集群本身进行管理，并能够在集群上进行容器化应用的安装和部署&lt;/</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之Kubeadm和二进制方式对比</title>
    <link href="http://example.com/2022/08/22/k8s%E4%B9%8BKubeadm%E5%92%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%AF%94/"/>
    <id>http://example.com/2022/08/22/k8s%E4%B9%8BKubeadm%E5%92%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%AF%94/</id>
    <published>2022-08-22T02:36:21.000Z</published>
    <updated>2022-08-24T09:03:36.732Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Kubeadm方式搭建K8S集群"><a href="#Kubeadm方式搭建K8S集群" class="headerlink" title="Kubeadm方式搭建K8S集群"></a>Kubeadm方式搭建K8S集群</h2><ul><li><p>安装虚拟机，在虚拟机安装Linux操作系统【3台虚拟机】</p></li><li><p>对操作系统初始化操作</p></li><li><p>所有节点安装Docker、kubeadm、kubelet、kubectl【包含master和slave节点】</p><ul><li>安装docker、使用yum，不指定版本默认安装最新的docker版本</li><li>修改docker仓库地址，yum源地址，改为阿里云地址</li><li>安装kubeadm，kubelet 和 kubectl<ul><li>k8s已经发布最新的1.19版本，可以指定版本安装，不指定安装最新版本</li><li><code>yum install -y kubelet kubeadm kubectl</code></li></ul></li></ul></li><li><p>在master节点执行初始化命令操作</p><ul><li><code>kubeadm init</code></li><li>默认拉取镜像地址 K8s.gcr.io国内地址，需要使用国内地址</li></ul></li><li><p>安装网络插件(CNI)</p><ul><li><code>kubectl apply -f kube-flannel.yml</code></li><li></li></ul></li><li><p>在所有的node节点上，使用join命令，把node添加到master节点上</p></li><li><p>测试kubernetes集群</p></li></ul><h2 id="二进制方式搭建K8S集群"><a href="#二进制方式搭建K8S集群" class="headerlink" title="二进制方式搭建K8S集群"></a>二进制方式搭建K8S集群</h2><ul><li>安装虚拟机和操作系统，对操作系统进行初始化操作</li><li>生成cfssl 自签证书<ul><li><code>ca-key.pem</code>、<code>ca.pem</code></li><li><code>server-key.pem</code>、<code>server.pem</code></li></ul></li><li>部署Etcd集群<ul><li>部署的本质，就是把etcd集群交给 systemd 管理</li><li>把生成的证书复制过来，启动，设置开机启动</li></ul></li><li>为apiserver自签证书，生成过程和etcd类似</li><li>部署master组件，主要包含以下组件<ul><li>apiserver</li><li>controller-manager</li><li>scheduler</li><li>交给systemd管理，并设置开机启动</li><li>如果要安装最新的1.19版本，下载二进制文件进行安装</li></ul></li><li>部署node组件<ul><li>docker</li><li>kubelet</li><li>kube-proxy【需要批准kubelet证书申请加入集群】</li><li>交给systemd管理组件- 组件启动，设置开机启动</li></ul></li><li>批准kubelet证书申请 并加入集群</li><li>部署CNI网络插件</li><li>测试Kubernets集群【安装nginx测试】</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Kubeadm方式搭建K8S集群&quot;&gt;&lt;a href=&quot;#Kubeadm方式搭建K8S集群&quot; class=&quot;headerlink&quot; title=&quot;Kubeadm方式搭建K8S集群&quot;&gt;&lt;/a&gt;Kubeadm方式搭建K8S集群&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;安装虚拟机</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之kubernetes 集群搭建(二进制方式)</title>
    <link href="http://example.com/2022/08/21/k8s%E4%B9%8Bkubernetes-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F/"/>
    <id>http://example.com/2022/08/21/k8s%E4%B9%8Bkubernetes-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA-%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F/</id>
    <published>2022-08-21T02:48:47.000Z</published>
    <updated>2022-08-25T01:02:57.845Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件</p><ul><li>一台或多台机器，操作系统CentOS 7.x</li><li>硬件配置：2GB ，2个CPU，硬盘30GB</li><li>集群中所有机器之间网络互通</li><li>可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像导入节点</li><li>禁止swap分区</li></ul><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ul><li>创建多台虚拟机，安装Linux系统</li><li>操作系统的初始化</li><li>为etcd 和 apiserver 自签证书</li><li>部署etcd集群</li><li>部署master组件【安装docker、kube-apiserver、kube-controller-manager、kube-scheduler、etcd】</li><li>部署node组件【安装kubelet、kube-proxy、docker、etcd】</li><li>部署集群网络</li></ul><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p>（1）软件环境：</p><table><thead><tr><th>软件</th><th>版本</th></tr></thead><tbody><tr><td>操作系统</td><td>CentOS7.8_x64 （mini）</td></tr><tr><td>Docker</td><td>19-ce</td></tr><tr><td>Kubernetes</td><td>1.19</td></tr></tbody></table><p>（2）服务器规划：</p><table><thead><tr><th>主机名</th><th>ip</th><th>组件</th></tr></thead><tbody><tr><td>k8s-master</td><td>192.168.177.140</td><td>kube-apiserver，kube-controller-manager，kube -scheduler，etcd</td></tr><tr><td>k8s-node1</td><td>192.168.177.141</td><td>kubelet，kube-proxy，docker etcd</td></tr></tbody></table><h2 id="操作系统的初始化"><a href="#操作系统的初始化" class="headerlink" title="操作系统的初始化"></a>操作系统的初始化</h2><p>然后我们需要进行一些系列的初始化操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭selinux</span></span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line">sed -i <span class="string">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config  </span><br><span class="line"><span class="comment"># 临时关闭</span></span><br><span class="line">setenforce 0  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭swap</span></span><br><span class="line"><span class="comment"># 临时</span></span><br><span class="line">swapoff -a </span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line">sed -ri <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据规划设置主机名【master节点上操作】</span></span><br><span class="line">hostnamectl set-hostname k8s-master</span><br><span class="line"><span class="comment"># 根据规划设置主机名【node1节点操作】</span></span><br><span class="line">hostnamectl set-hostname k8s-node1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在master添加hosts</span></span><br><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">192.168.177.140 k8s-master</span></span><br><span class="line"><span class="string">192.168.177.141 k8s-node1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将桥接的IPv4流量传递到iptables的链</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 生效</span></span><br><span class="line">sysctl --system  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间同步</span></span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate time.windows.com</span><br></pre></td></tr></table></figure><h2 id="部署Etcd集群"><a href="#部署Etcd集群" class="headerlink" title="部署Etcd集群"></a>部署Etcd集群</h2><p>Etcd是一个分布式键值存储系统，Kubernetes使用Etcd进行数据存储，所以先准备一个Etcd数据库，为了解决Etcd单点故障，应采用集群方式部署，这里使用3台组建集群，可容忍一台机器故障，当然也可以使用5台组件集群，可以容忍2台机器故障</p><h3 id="自签证书"><a href="#自签证书" class="headerlink" title="自签证书"></a>自签证书</h3><p>提到证书，我们想到的就是下面这个情况</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201113213116353.png"                      alt="image-20201113213116353"                ></p><p>这个https证书，其实就是服务器颁发给网站的，代表这是一个安全可信任的网站。</p><p>而在我们K8S集群的内部，其实也是有证书的，如果不带证书，那么访问就会受限</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201113213353267.png"                      alt="image-20201113213353267"                ></p><p>同时在集群内部 和外部的访问，我们也需要签发证书</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/4_%E4%BD%BF%E7%94%A8%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113213416013.png"                      alt="image-20201113213416013"                ></p><p>如果我们使用二进制的方式，那么就需要自己手动签发证书。</p><p>自签证书：我们可以想象成在一家公司上班，然后会颁发一个门禁卡，同时一般门禁卡有两种，一个是内部员工的门禁卡，和外部访客门禁卡。这两种门禁卡的权限可能不同，员工的门禁卡可以进入公司的任何地方，而访客的门禁卡是受限的，这个门禁卡其实就是自签证书</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/4_%E4%BD%BF%E7%94%A8%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113214234194.png"                      alt="image-20201113214234194"                ></p><h3 id="准备cfssl证书生成工具"><a href="#准备cfssl证书生成工具" class="headerlink" title="准备cfssl证书生成工具"></a>准备cfssl证书生成工具</h3><p>cfssl是一个开源的证书管理工具，使用json文件生成证书，相比openssl 更方便使用。找任意一台服务器操作，这里用Master节点。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span><br><span class="line"><span class="built_in">chmod</span> +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64</span><br><span class="line"><span class="built_in">mv</span> cfssl_linux-amd64 /usr/local/bin/cfssl</span><br><span class="line"><span class="built_in">mv</span> cfssljson_linux-amd64 /usr/local/bin/cfssljson</span><br><span class="line"><span class="built_in">mv</span> cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo</span><br></pre></td></tr></table></figure><h3 id="生成-Etcd-证书"><a href="#生成-Etcd-证书" class="headerlink" title="生成 Etcd 证书"></a>生成 Etcd 证书</h3><p>（1）自签证书颁发机构（CA）</p><p>创建工作目录：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p ~/TLS/&#123;etcd,k8s&#125;</span><br><span class="line"><span class="built_in">cd</span> TLS/etcd</span><br></pre></td></tr></table></figure><p>自签 CA:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; ca-config.json&lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;signing&quot;: &#123;</span></span><br><span class="line"><span class="string">            &quot;default&quot;: &#123;</span></span><br><span class="line"><span class="string">            &quot;expiry&quot;: &quot;87600h&quot;</span></span><br><span class="line"><span class="string">            &#125;,</span></span><br><span class="line"><span class="string">            &quot;profiles&quot;: &#123;</span></span><br><span class="line"><span class="string">                &quot;www&quot;: &#123;</span></span><br><span class="line"><span class="string">                    &quot;expiry&quot;: &quot;87600h&quot;,</span></span><br><span class="line"><span class="string">                    &quot;usages&quot;: [</span></span><br><span class="line"><span class="string">                        &quot;signing&quot;,</span></span><br><span class="line"><span class="string">                        &quot;key encipherment&quot;,</span></span><br><span class="line"><span class="string">                        &quot;server auth&quot;,</span></span><br><span class="line"><span class="string">                        &quot;client auth&quot;</span></span><br><span class="line"><span class="string">                    ]</span></span><br><span class="line"><span class="string">                &#125;</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; ca-csr.json&lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;etcd CA&quot;,</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;Beijing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;Beijing&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -<span class="built_in">ls</span> *pe</span><br><span class="line">ca-key.pem  ca.pem</span><br></pre></td></tr></table></figure><p>（2）使用自签 CA 签发 Etcd HTTPS 证书 </p><p>创建证书申请文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; server-csr.json&lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;etcd&quot;,</span></span><br><span class="line"><span class="string">    &quot;hosts&quot;: [</span></span><br><span class="line"><span class="string">        &quot;192.168.31.71&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.72&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.73&quot;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;BeiJing&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>注：上述文件 hosts 字段中 IP 为所有 etcd 节点的集群内部通信 IP，一个都不能少！为了 方便后期扩容可以多写几个预留的 IP。</p><p>生成证书：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server</span><br><span class="line"><span class="built_in">ls</span> server*pem</span><br><span class="line">server-key.pem   server.pem</span><br></pre></td></tr></table></figure><h3 id="从-Github-下载二进制文件"><a href="#从-Github-下载二进制文件" class="headerlink" title="从 Github 下载二进制文件"></a>从 Github 下载二进制文件</h3><p>下载地址：<a class="link"   href="https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz" >https://github.com/etcd-io/etcd/releases/download/v3.4.9/etcd-v3.4.9-linux-amd64.tar.gz<i class="fas fa-external-link-alt"></i></a></p><h2 id="部署-Etcd-集群"><a href="#部署-Etcd-集群" class="headerlink" title="部署 Etcd 集群"></a>部署 Etcd 集群</h2><p>以下在节点 1 上操作，为简化操作，待会将节点 1 生成的所有文件拷贝到节点 2 和节点 3。</p><p>（1）创建工作目录并解压二进制包</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/etcd/&#123;bin,cfg,ssl&#125; –p</span><br><span class="line">tar zxvf etcd-v3.4.9-linux-amd64.tar.gz</span><br><span class="line"><span class="built_in">mv</span> etcd-v3.4.9-linux-amd64/&#123;etcd,etcdctl&#125; /opt/etcd/bin/</span><br></pre></td></tr></table></figure><p>（2）创建 etcd 配置文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/etcd/cfg/etcd.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">#[Member]</span></span><br><span class="line"><span class="string">ETCD_NAME=&quot;etcd-1&quot;</span></span><br><span class="line"><span class="string">ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;</span></span><br><span class="line"><span class="string">ETCD_LISTEN_PEER_URLS=&quot;https://192.168.31.71:2380&quot;</span></span><br><span class="line"><span class="string">ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.31.71:2379&quot;</span></span><br><span class="line"><span class="string">#[Clustering]</span></span><br><span class="line"><span class="string">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.31.71:2380&quot;</span></span><br><span class="line"><span class="string">ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.31.71:2379&quot;</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER=&quot;etcd-1=https://192.168.31.71:2380,etcd2=https://192.168.31.72:2380,etcd-3=https://192.168.31.73:2380&quot;</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ul><li>ETCD_NAME：节点名称，集群中唯一 </li><li>ETCD_DATA_DIR：数据目录 </li><li>ETCD_LISTEN_PEER_URLS：集群通信监听地址 </li><li>ETCD_LISTEN_CLIENT_URLS：客户端访问监听地址 </li><li>ETCD_INITIAL_ADVERTISE_PEER_URLS：集群通告地址 </li><li>ETCD_ADVERTISE_CLIENT_URLS：客户端通告地址 </li><li>ETCD_INITIAL_CLUSTER：集群节点地址 </li><li>ETCD_INITIAL_CLUSTER_TOKEN：集群Token </li><li>ETCD_INITIAL_CLUSTER_STATE：加入集群的当前状态，new 是新集群，existing 表示加入 已有集群</li></ul><p>（3）systemd 管理 etcd</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/etcd.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Etcd Server</span></span><br><span class="line"><span class="string">After=network.target</span></span><br><span class="line"><span class="string">After=network-online.target</span></span><br><span class="line"><span class="string">Wants=network-online.target</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">Type=notify</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/etcd/cfg/etcd.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/etcd/bin/etcd \</span></span><br><span class="line"><span class="string">--cert-file=/opt/etcd/ssl/server.pem \</span></span><br><span class="line"><span class="string">--key-file=/opt/etcd/ssl/server-key.pem \</span></span><br><span class="line"><span class="string">--peer-cert-file=/opt/etcd/ssl/server.pem \</span></span><br><span class="line"><span class="string">--peer-key-file=/opt/etcd/ssl/server-key.pem \</span></span><br><span class="line"><span class="string">--trusted-ca-file=/opt/etcd/ssl/ca.pem </span></span><br><span class="line"><span class="string">--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem \</span></span><br><span class="line"><span class="string">--logger=zap</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">LimitNOFILE=65536</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>（4）拷贝刚才生成的证书</p><p>把刚才生成的证书拷贝到配置文件中的路径:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> ~/TLS/etcd/ca*pem ~/TLS/etcd/server*pem /opt/etcd/ssl/</span><br></pre></td></tr></table></figure><p>（5）启动并设置开机启动</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start etcd</span><br><span class="line">systemctl <span class="built_in">enable</span> etc</span><br></pre></td></tr></table></figure><p>（6）将上面节点 1 所有生成的文件拷贝到节点 2 和</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scp -r /opt/etcd/ root@192.168.31.72:/opt/</span><br><span class="line">scp /usr/lib/systemd/system/etcd.service</span><br><span class="line">  root@192.168.31.72:/usr/lib/systemd/system/</span><br><span class="line">scp -r /opt/etcd/ root@192.168.31.73:/opt/</span><br><span class="line">scp /usr/lib/systemd/system/etcd.service</span><br><span class="line">  root@192.168.31.73:/usr/lib/systemd/system/</span><br></pre></td></tr></table></figure><p>然后在节点 2 和节点 3 分别修改 etcd.conf 配置文件中的节点名称和当前服务器 IP：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vi /opt/etcd/cfg/etcd.conf</span><br><span class="line"><span class="comment">#[Member]</span></span><br><span class="line">ETCD_NAME=<span class="string">&quot;etcd-1&quot;</span> <span class="comment"># 修改此处，节点 2 改为 etcd-2，节点 3 改为 etcd-3</span></span><br><span class="line">ETCD_DATA_DIR=<span class="string">&quot;/var/lib/etcd/default.etcd&quot;</span></span><br><span class="line">ETCD_LISTEN_PEER_URLS=<span class="string">&quot;https://192.168.31.71:2380&quot;</span> <span class="comment"># 修改此处为当前服务器 IP</span></span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=<span class="string">&quot;https://192.168.31.71:2379&quot;</span> <span class="comment"># 修改此处为当前服务器 IP</span></span><br><span class="line"><span class="comment">#[Clustering]</span></span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=<span class="string">&quot;https://192.168.31.71:2380&quot;</span> <span class="comment"># 修改此处为当前</span></span><br><span class="line">服务器 IP</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=<span class="string">&quot;https://192.168.31.71:2379&quot;</span> <span class="comment"># 修改此处为当前服务器IP</span></span><br><span class="line">ETCD_INITIAL_CLUSTER=<span class="string">&quot;etcd-1=https://192.168.31.71:2380,etcd2=https://192.168.31.72:2380,etcd-3=https://192.168.31.73:2380&quot;</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN=<span class="string">&quot;etcd-cluster&quot;</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=<span class="string">&quot;new&quot;</span></span><br></pre></td></tr></table></figure><p>最后启动 etcd 并设置开机启动，同上。</p><p>（7）查看集群状态</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3 /opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --cert=/opt/etcd/ssl/server.pem --key=/opt/etcd/ssl/server-key.pem --</span><br><span class="line">endpoints=<span class="string">&quot;https://192.168.31.71:2379,https://192.168.31.72:2379,https://192.168.31.73:2379&quot;</span> endpoint health</span><br><span class="line"></span><br><span class="line">https://192.168.31.71:2379 is healthy: successfully committed proposal: took =8.154404ms</span><br><span class="line"></span><br><span class="line">https://192.168.31.73:2379 is healthy: successfully committed proposal: took =9.044117ms</span><br><span class="line"></span><br><span class="line">https://192.168.31.72:2379 is healthy: successfully committed proposal: took =10.000825ms</span><br></pre></td></tr></table></figure><p>如果输出上面信息，就说明集群部署成功。如果有问题第一步先看日志： &#x2F;var&#x2F;log&#x2F;message 或 journalctl -u etcd</p><h2 id="安装-Docker"><a href="#安装-Docker" class="headerlink" title="安装 Docker"></a>安装 Docker</h2><p>下载地址：<a class="link"   href="https://download.docker.com/linux/static/stable/x86_64/docker19.03.9.tgz" >https://download.docker.com/linux/static/stable/x86_64/docker19.03.9.tgz<i class="fas fa-external-link-alt"></i></a> </p><p>以下在所有节点操作。这里采用二进制安装，用 yum 安装也一样。</p><p>（1）解压二进制包</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf docker-19.03.9.tgz</span><br><span class="line"><span class="built_in">mv</span> docker/* /usr/bin</span><br></pre></td></tr></table></figure><p>（2） systemd 管理 dock</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/docker.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Docker Application Container Engine</span></span><br><span class="line"><span class="string">Documentation=https://docs.docker.com</span></span><br><span class="line"><span class="string">After=network-online.target firewalld.service</span></span><br><span class="line"><span class="string">Wants=network-online.target</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">Type=notify</span></span><br><span class="line"><span class="string">ExecStart=/usr/bin/dockerd</span></span><br><span class="line"><span class="string">ExecReload=/bin/kill -s HUP $MAINPID</span></span><br><span class="line"><span class="string">LimitNOFILE=infinity</span></span><br><span class="line"><span class="string">LimitNPROC=infinity</span></span><br><span class="line"><span class="string">LimitCORE=infinity</span></span><br><span class="line"><span class="string">TimeoutStartSec=0</span></span><br><span class="line"><span class="string">Delegate=yes</span></span><br><span class="line"><span class="string">KillMode=process</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">StartLimitBurst=3</span></span><br><span class="line"><span class="string">StartLimitInterval=60s</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>（3）创建配置文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /etc/docker</span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/docker/daemon.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">&quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>registry-mirrors 阿里云镜像加速器</p><p>（4）启动并设置开机启动</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl <span class="built_in">enable</span> docke</span><br></pre></td></tr></table></figure><h2 id="部署-Master-Node"><a href="#部署-Master-Node" class="headerlink" title="部署 Master Node"></a>部署 Master Node</h2><h3 id="生成-kube-apiserver-证书"><a href="#生成-kube-apiserver-证书" class="headerlink" title="生成 kube-apiserver 证书"></a>生成 kube-apiserver 证书</h3><p>（1）自签证书颁发机构（CA）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; ca-config.json&lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;signing&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;default&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;expiry&quot;: &quot;87600h&quot;</span></span><br><span class="line"><span class="string">        &#125;,</span></span><br><span class="line"><span class="string">        &quot;profiles&quot;: &#123;</span></span><br><span class="line"><span class="string">            &quot;kubernetes&quot;: &#123;</span></span><br><span class="line"><span class="string">                &quot;expiry&quot;: &quot;87600h&quot;,</span></span><br><span class="line"><span class="string">                &quot;usages&quot;: [</span></span><br><span class="line"><span class="string">                    &quot;signing&quot;,</span></span><br><span class="line"><span class="string">                    &quot;key encipherment&quot;,</span></span><br><span class="line"><span class="string">                    &quot;server auth&quot;,</span></span><br><span class="line"><span class="string">                    &quot;client auth&quot;</span></span><br><span class="line"><span class="string">                ]</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="built_in">cat</span> &gt; ca-csr.json&lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;kubernetes&quot;,</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;Beijing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;Beijing&quot;,</span></span><br><span class="line"><span class="string">            &quot;O&quot;: &quot;k8s&quot;,</span></span><br><span class="line"><span class="string">            &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>（2）生成证书:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br><span class="line"><span class="built_in">ls</span> *pem</span><br><span class="line">ca-key.pem ca.pem</span><br></pre></td></tr></table></figure><p>（3）使用自签 CA 签发 kube-apiserver HTTPS 证书 </p><p>创建证书申请文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> TLS/k8s</span><br><span class="line"><span class="built_in">cat</span> &gt; server-csr.json&lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;kubernetes&quot;,</span></span><br><span class="line"><span class="string">    &quot;hosts&quot;: [</span></span><br><span class="line"><span class="string">        &quot;10.0.0.1&quot;,</span></span><br><span class="line"><span class="string">        &quot;127.0.0.1&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.71&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.72&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.73&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.74&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.81&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.82&quot;,</span></span><br><span class="line"><span class="string">        &quot;192.168.31.88&quot;,</span></span><br><span class="line"><span class="string">        &quot;kubernetes&quot;,</span></span><br><span class="line"><span class="string">        &quot;kubernetes.default&quot;,</span></span><br><span class="line"><span class="string">        &quot;kubernetes.default.svc&quot;,</span></span><br><span class="line"><span class="string">        &quot;kubernetes.default.svc.cluster&quot;,</span></span><br><span class="line"><span class="string">        &quot;kubernetes.default.svc.cluster.local&quot;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">            &quot;O&quot;: &quot;k8s&quot;,</span></span><br><span class="line"><span class="string">            &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>生成证书：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server</span><br><span class="line"><span class="built_in">ls</span> server*pem</span><br><span class="line">server-key.pem server.pe</span><br></pre></td></tr></table></figure><h3 id="从-Github-下载二进制文"><a href="#从-Github-下载二进制文" class="headerlink" title="从 Github 下载二进制文"></a>从 Github 下载二进制文</h3><p>下载地址： <a class="link"   href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG1.18.md#v1183" >https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG1.18.md#v1183<i class="fas fa-external-link-alt"></i></a> </p><p>注：打开链接你会发现里面有很多包，下载一个 server 包就够了，包含了 Master 和 Worker </p><h3 id="解压二进制包"><a href="#解压二进制包" class="headerlink" title="解压二进制包"></a>解压二进制包</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125;</span><br><span class="line">tar zxvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line"><span class="built_in">cd</span> kubernetes/server/bin</span><br><span class="line"><span class="built_in">cp</span> kube-apiserver kube-scheduler kube-controller-manager /opt/kubernetes/bin</span><br><span class="line"><span class="built_in">cp</span> kubectl /usr/bin/</span><br></pre></td></tr></table></figure><h3 id="部署-kube-apiserver"><a href="#部署-kube-apiserver" class="headerlink" title="部署 kube-apiserver"></a>部署 kube-apiserver</h3><ol><li>创建配置文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-apiserver.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBE_APISERVER_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--etcdservers=https://192.168.31.71:2379,https://192.168.31.72:2379,https://192.168.3</span></span><br><span class="line"><span class="string">1.73:2379 \\</span></span><br><span class="line"><span class="string">--bind-address=192.168.31.71 \\</span></span><br><span class="line"><span class="string">--secure-port=6443 \\</span></span><br><span class="line"><span class="string">--advertise-address=192.168.31.71 \\</span></span><br><span class="line"><span class="string">--allow-privileged=true \\</span></span><br><span class="line"><span class="string">--service-cluster-ip-range=10.0.0.0/24 \\</span></span><br><span class="line"><span class="string">--enable-admissionplugins=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestric</span></span><br><span class="line"><span class="string">tion \\</span></span><br><span class="line"><span class="string">--authorization-mode=RBAC,Node \\</span></span><br><span class="line"><span class="string">--enable-bootstrap-token-auth=true \\</span></span><br><span class="line"><span class="string">--token-auth-file=/opt/kubernetes/cfg/token.csv \\</span></span><br><span class="line"><span class="string">--service-node-port-range=30000-32767 \\</span></span><br><span class="line"><span class="string">--kubelet-client-certificate=/opt/kubernetes/ssl/server.pem \\</span></span><br><span class="line"><span class="string">--kubelet-client-key=/opt/kubernetes/ssl/server-key.pem \\</span></span><br><span class="line"><span class="string">--tls-cert-file=/opt/kubernetes/ssl/server.pem \\</span></span><br><span class="line"><span class="string">--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\</span></span><br><span class="line"><span class="string">--client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--etcd-cafile=/opt/etcd/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--etcd-certfile=/opt/etcd/ssl/server.pem \\</span></span><br><span class="line"><span class="string">--etcd-keyfile=/opt/etcd/ssl/server-key.pem \\</span></span><br><span class="line"><span class="string">--audit-log-maxage=30 \\</span></span><br><span class="line"><span class="string">--audit-log-maxbackup=3 \\</span></span><br><span class="line"><span class="string">--audit-log-maxsize=100 \\</span></span><br><span class="line"><span class="string">--audit-log-path=/opt/kubernetes/logs/k8s-audit.log&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>注：上面两个\ \ 第一个是转义符，第二个是换行符，使用转义符是为了使用 EOF 保留换行符。 </p><ul><li>–logtostderr：启用日志 </li><li>—v：日志等级 </li><li>–log-dir：日志目录 </li><li>–etcd-servers：etcd 集群地址 </li><li>–bind-address：监听地址 </li><li>–secure-port：https 安全端口 </li><li>–advertise-address：集群通告地址 </li><li>–allow-privileged：启用授权 </li><li>–service-cluster-ip-range：Service 虚拟 IP 地址段 </li><li>–enable-admission-plugins：准入控制模块 </li><li>–authorization-mode：认证授权，启用 RBAC 授权和节点自管理 </li><li>–enable-bootstrap-token-auth：启用 TLS bootstrap 机制 </li><li>–token-auth-file：bootstrap token 文件 </li><li>–service-node-port-range：Service nodeport 类型默认分配端口范围 </li><li>–kubelet-client-xxx：apiserver 访问 kubelet 客户端证书 </li><li>–tls-xxx-file：apiserver https 证书 </li><li>–etcd-xxxfile：连接 Etcd 集群证书 </li><li>–audit-log-xxx：审计日志</li></ul><ol start="2"><li>拷贝刚才生成的证书</li></ol><p>把刚才生成的证书拷贝到配置文件中的路径：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> ~/TLS/k8s/ca*pem ~/TLS/k8s/server*pem /opt/kubernetes/ssl/</span><br></pre></td></tr></table></figure><ol start="3"><li>启用 TLS Bootstrapping 机制</li></ol><p>TLS Bootstraping：Master apiserver 启用 TLS 认证后，Node 节点 kubelet 和 kube- proxy 要与 kube-apiserver 进行通信，必须使用 CA 签发的有效证书才可以，当 Node 节点很多时，这种客户端证书颁发需要大量工作，同样也会增加集群扩展复杂度。为了简化流程，Kubernetes 引入了 TLS bootstraping 机制来自动颁发客户端证书，kubelet 会以一个低权限用户自动向 apiserver 申请证书，kubelet 的证书由 apiserver动态签署。所以强烈建议在 Node 上使用这种方式，目前主要用于 kubelet，kube-proxy 还是由我 们统一颁发一个证书。 </p><p>TLS bootstraping 工作</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../../AppData/Roaming/Typora/typora-user-images/image-20220821174158888.png"                      alt="image-20220821174158888"                ></p><p>创建上述配置文件中 token 文件:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/token.csv &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">c47ffb939f5ca36231d9e3121a252940,kubelet-bootstrap,10001,&quot;system:nodebootstrapper&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>格式：token，用户名，UID，用户组 </p><p>token 也可自行生成替换：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">head</span> -c 16 /dev/urandom | <span class="built_in">od</span> -An -t x | <span class="built_in">tr</span> -d <span class="string">&#x27; &#x27;</span></span><br></pre></td></tr></table></figure><ol start="4"><li>systemd 管理 apiserver</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-apiserver.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes API Server</span></span><br><span class="line"><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kube-apiserver.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kube-apiserver \$KUBE_APISERVER_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ol start="5"><li>启动并设置开机启动</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-apiserver</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-apiserve</span><br></pre></td></tr></table></figure><ol start="6"><li>授权 kubelet-bootstrap 用户允许请求证书</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding kubelet-bootstrap \</span><br><span class="line">--clusterrole=system:node-bootstrapper \</span><br><span class="line">--user=kubelet-bootstrap</span><br></pre></td></tr></table></figure><h3 id="部署-kube-controller-manager"><a href="#部署-kube-controller-manager" class="headerlink" title="部署 kube-controller-manager"></a>部署 kube-controller-manager</h3><ol><li>创建配置文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-controller-manager.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--leader-elect=true \\</span></span><br><span class="line"><span class="string">--master=127.0.0.1:8080 \\</span></span><br><span class="line"><span class="string">--bind-address=127.0.0.1 \\</span></span><br><span class="line"><span class="string">--allocate-node-cidrs=true \\</span></span><br><span class="line"><span class="string">--cluster-cidr=10.244.0.0/16 \\</span></span><br><span class="line"><span class="string">--service-cluster-ip-range=10.0.0.0/24 \\</span></span><br><span class="line"><span class="string">--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--root-ca-file=/opt/kubernetes/ssl/ca.pem \\</span></span><br><span class="line"><span class="string">--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span></span><br><span class="line"><span class="string">--experimental-cluster-signing-duration=87600h0m0s&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ul><li>–master：通过本地非安全本地端口 8080 连接 apiserver。</li><li>–leader-elect：当该组件启动多个时，自动选举（HA） </li><li>–cluster-signing-cert-file&#x2F;–cluster-signing-key-file：自动为 kubelet 颁发证书 的 CA，与 apiserver 保持一致</li></ul><ol start="2"><li>systemd 管理 controller-manager</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-controller-manager.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes Controller Manager</span></span><br><span class="line"><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kube-controller-manager.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kube-controller-manager</span></span><br><span class="line"><span class="string">\$KUBE_CONTROLLER_MANAGER_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ol start="3"><li>启动并设置开机启动</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-controller-manager</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-controller-manager</span><br></pre></td></tr></table></figure><h3 id="部署-kube-scheduler"><a href="#部署-kube-scheduler" class="headerlink" title="部署 kube-scheduler"></a>部署 kube-scheduler</h3><ol><li>创建配置文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-scheduler.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBE_SCHEDULER_OPTS=&quot;--logtostderr=false \</span></span><br><span class="line"><span class="string">--v=2 \</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \</span></span><br><span class="line"><span class="string">--leader-elect \</span></span><br><span class="line"><span class="string">--master=127.0.0.1:8080 \</span></span><br><span class="line"><span class="string">--bind-address=127.0.0.1&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ul><li>–master：通过本地非安全本地端口 8080 连接 apiserver。 </li><li>–leader-elect：当该组件启动多个时，自动选举（HA）</li></ul><ol start="2"><li>systemd 管理 scheduler</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-scheduler.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes Scheduler</span></span><br><span class="line"><span class="string">Documentation=https://github.com/kubernetes/kubernetes</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kube-scheduler.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kube-scheduler \$KUBE_SCHEDULER_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ol start="3"><li>启动并设置开机启动</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-scheduler</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-scheduler</span><br></pre></td></tr></table></figure><ol start="4"><li>查看集群状态</li></ol><p>所有组件都已经启动成功，通过 kubectl 工具查看当前集群组件状态：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl get cs</span><br><span class="line">NAME STATUS MESSAGE  ERROR</span><br><span class="line">scheduler       Healthy  ok</span><br><span class="line">controller-manager Healthy  ok</span><br><span class="line">etcd-2        Healthy  &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;</span><br><span class="line">etcd-1     Healthy       &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;</span><br><span class="line">etcd-0   Healthy    &#123;<span class="string">&quot;health&quot;</span>:<span class="string">&quot;true&quot;</span>&#125;</span><br></pre></td></tr></table></figure><p>如上输出说明 Master 节点组件运行正常</p><h2 id="部署-Worker-Node"><a href="#部署-Worker-Node" class="headerlink" title="部署 Worker Node"></a>部署 Worker Node</h2><p>下面还是在 Master Node 上操作，即同时作为 Worker Node</p><h3 id="创建工作目录并拷贝二进制文件"><a href="#创建工作目录并拷贝二进制文件" class="headerlink" title="创建工作目录并拷贝二进制文件"></a>创建工作目录并拷贝二进制文件</h3><p>在所有 worker node 创建工作目录</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/kubernetes/&#123;bin,cfg,ssl,logs&#125;</span><br></pre></td></tr></table></figure><p>从 master 节点拷贝:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> kubernetes/server/bin</span><br><span class="line"><span class="built_in">cp</span> kubelet kube-proxy /opt/kubernetes/bin <span class="comment"># 本地拷贝</span></span><br></pre></td></tr></table></figure><h3 id="部署-kubelet"><a href="#部署-kubelet" class="headerlink" title="部署 kubelet"></a>部署 kubelet</h3><ol><li>创建配置文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kubelet.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBELET_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--hostname-override=k8s-master \\</span></span><br><span class="line"><span class="string">--network-plugin=cni \\</span></span><br><span class="line"><span class="string">--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\</span></span><br><span class="line"><span class="string">--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\</span></span><br><span class="line"><span class="string">--config=/opt/kubernetes/cfg/kubelet-config.yml \\</span></span><br><span class="line"><span class="string">--cert-dir=/opt/kubernetes/ssl \\</span></span><br><span class="line"><span class="string">--pod-infra-container-image=lizhenliang/pause-amd64:3.0&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ul><li>–hostname-override：显示名称，集群中唯一 </li><li>–network-plugin：启用 CNI </li><li>–kubeconfig：空路径，会自动生成，后面用于连接 apiserver </li><li>–bootstrap-kubeconfig：首次启动向 apiserver 申请证书 </li><li>–config：配置参数文件 </li><li>–cert-dir：kubelet 证书生成目录 </li><li>–pod-infra-container-image：管理 Pod 网络容器的镜像</li></ul><ol start="2"><li>配置参数文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kubelet-config.yml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">kind: KubeletConfiguration</span></span><br><span class="line"><span class="string">apiVersion: kubelet.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="string">address: 0.0.0.0</span></span><br><span class="line"><span class="string">port: 10250</span></span><br><span class="line"><span class="string">readOnlyPort: 10255</span></span><br><span class="line"><span class="string">cgroupDriver: cgroupfs</span></span><br><span class="line"><span class="string">clusterDNS:</span></span><br><span class="line"><span class="string">- 10.0.0.2</span></span><br><span class="line"><span class="string">clusterDomain: cluster.local</span></span><br><span class="line"><span class="string">failSwapOn: false</span></span><br><span class="line"><span class="string">authentication:</span></span><br><span class="line"><span class="string">    anonymous:</span></span><br><span class="line"><span class="string">    enabled: false</span></span><br><span class="line"><span class="string">    webhook:</span></span><br><span class="line"><span class="string">    cacheTTL: 2m0s</span></span><br><span class="line"><span class="string">    enabled: true</span></span><br><span class="line"><span class="string">    x509:</span></span><br><span class="line"><span class="string">clientCAFile: /opt/kubernetes/ssl/ca.pem</span></span><br><span class="line"><span class="string">authorization:</span></span><br><span class="line"><span class="string">    mode: Webhook</span></span><br><span class="line"><span class="string">    webhook:</span></span><br><span class="line"><span class="string">        cacheAuthorizedTTL: 5m0s</span></span><br><span class="line"><span class="string">        cacheUnauthorizedTTL: 30s</span></span><br><span class="line"><span class="string">evictionHard:</span></span><br><span class="line"><span class="string">imagefs.available: 15%</span></span><br><span class="line"><span class="string">memory.available: 100Mi</span></span><br><span class="line"><span class="string">nodefs.available: 10%</span></span><br><span class="line"><span class="string">nodefs.inodesFree: 5%</span></span><br><span class="line"><span class="string">maxOpenFiles: 1000000</span></span><br><span class="line"><span class="string">maxPods: 110</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li>生成 bootstrap.kubeconfig 文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">KUBE_APISERVER=<span class="string">&quot;https://192.168.31.71:6443&quot;</span> <span class="comment"># apiserver IP:PORT</span></span><br><span class="line">TOKEN=<span class="string">&quot;c47ffb939f5ca36231d9e3121a252940&quot;</span> <span class="comment"># 与 token.csv 里保持一致</span></span><br><span class="line"><span class="comment"># 生成 kubelet bootstrap kubeconfig 配置文件</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">    --certificate-authority=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">    --embed-certs=<span class="literal">true</span> \</span><br><span class="line">    --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">    --kubeconfig=bootstrap.kubeconfig</span><br><span class="line">kubectl config set-credentials <span class="string">&quot;kubelet-bootstrap&quot;</span> \</span><br><span class="line">    --token=<span class="variable">$&#123;TOKEN&#125;</span> \</span><br><span class="line">    --kubeconfig=bootstrap.kubeconfig</span><br><span class="line">kubectl config set-context default \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=<span class="string">&quot;kubelet-bootstrap&quot;</span> \</span><br><span class="line">    --kubeconfig=bootstrap.kubeconfig</span><br><span class="line">kubectl config use-context default --kubeconfig=bootstrap.kubeconfig</span><br></pre></td></tr></table></figure><p>拷贝到配置文件路径：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> bootstrap.kubeconfig /opt/kubernetes/cfg</span><br></pre></td></tr></table></figure><ol start="4"><li>systemd 管理 kubelet</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kubelet.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes Kubelet</span></span><br><span class="line"><span class="string">After=docker.service</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kubelet.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kubelet \$KUBELET_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">LimitNOFILE=65536</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ol start="5"><li>启动并设置开机启动</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kubelet</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet</span><br></pre></td></tr></table></figure><h3 id="批准-kubelet-证书申请并加入集群"><a href="#批准-kubelet-证书申请并加入集群" class="headerlink" title="批准 kubelet 证书申请并加入集群"></a>批准 kubelet 证书申请并加入集群</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 kubelet 证书请求</span></span><br><span class="line">kubectl get csr</span><br><span class="line">NAME AGE SIGNERNAME</span><br><span class="line">REQUESTOR CONDITION</span><br><span class="line">node-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--K6M4G7bjhk8A 6m3s</span><br><span class="line">kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending</span><br><span class="line"><span class="comment"># 批准申请</span></span><br><span class="line">kubectl certificate approve node-csr-uCEGPOIiDdlLODKts8J658HrFq9CZ--</span><br><span class="line">K6M4G7bjhk8A</span><br><span class="line"><span class="comment"># 查看节点</span></span><br><span class="line">kubectl get node</span><br></pre></td></tr></table></figure><p>注：由于网络插件还没有部署，节点会没有准备就绪 NotReady</p><h3 id="部署-kube-proxy"><a href="#部署-kube-proxy" class="headerlink" title="部署 kube-proxy"></a>部署 kube-proxy</h3><ol><li>创建配置文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-proxy.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">KUBE_PROXY_OPTS=&quot;--logtostderr=false \\</span></span><br><span class="line"><span class="string">--v=2 \\</span></span><br><span class="line"><span class="string">--log-dir=/opt/kubernetes/logs \\</span></span><br><span class="line"><span class="string">--config=/opt/kubernetes/cfg/kube-proxy-config.yml&quot;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ol start="2"><li>配置参数文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /opt/kubernetes/cfg/kube-proxy-config.yml &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">kind: KubeProxyConfiguration</span></span><br><span class="line"><span class="string">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span></span><br><span class="line"><span class="string">bindAddress: 0.0.0.0</span></span><br><span class="line"><span class="string">metricsBindAddress: 0.0.0.0:10249</span></span><br><span class="line"><span class="string">clientConnection:</span></span><br><span class="line"><span class="string">    kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfig</span></span><br><span class="line"><span class="string">hostnameOverride: k8s-master</span></span><br><span class="line"><span class="string">clusterCIDR: 10.0.0.0/24</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ol start="3"><li>生成 kube-proxy.kubeconfig 文件</li></ol><p>生成 kube-proxy 证书:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切换工作目录</span></span><br><span class="line"><span class="built_in">cd</span> TLS/k8s</span><br><span class="line"><span class="comment"># 创建证书请求文件</span></span><br><span class="line"><span class="built_in">cat</span> &gt; kube-proxy-csr.json&lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span></span><br><span class="line"><span class="string">    &quot;hosts&quot;: [],</span></span><br><span class="line"><span class="string">    &quot;key&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;algo&quot;: &quot;rsa&quot;,</span></span><br><span class="line"><span class="string">        &quot;size&quot;: 2048</span></span><br><span class="line"><span class="string">    &#125;,</span></span><br><span class="line"><span class="string">    &quot;names&quot;: [</span></span><br><span class="line"><span class="string">        &#123;</span></span><br><span class="line"><span class="string">            &quot;C&quot;: &quot;CN&quot;,</span></span><br><span class="line"><span class="string">            &quot;L&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">            &quot;ST&quot;: &quot;BeiJing&quot;,</span></span><br><span class="line"><span class="string">            &quot;O&quot;: &quot;k8s&quot;,</span></span><br><span class="line"><span class="string">            &quot;OU&quot;: &quot;System&quot;</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 生成证书</span></span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -</span><br><span class="line">profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br><span class="line"><span class="built_in">ls</span> kube-proxy*pem</span><br><span class="line">kube-proxy-key.pem kube-proxy.pem</span><br></pre></td></tr></table></figure><p>生成 kubeconfig 文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">KUBE_APISERVER=<span class="string">&quot;https://192.168.31.71:6443&quot;</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">    --certificate-authority=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">    --embed-certs=<span class="literal">true</span> \</span><br><span class="line">    --server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">    --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">kubectl config set-credentials kube-proxy \</span><br><span class="line">    --client-certificate=./kube-proxy.pem \</span><br><span class="line">    --client-key=./kube-proxy-key.pem \</span><br><span class="line">    --embed-certs=<span class="literal">true</span> \</span><br><span class="line">    --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">kubectl config set-context default \</span><br><span class="line">    --cluster=kubernetes \</span><br><span class="line">    --user=kube-proxy \</span><br><span class="line">    --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><p>拷贝到配置文件指定路径：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> kube-proxy.kubeconfig /opt/kubernetes/cfg/</span><br></pre></td></tr></table></figure><ol start="4"><li>systemd 管理 kube-proxy</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /usr/lib/systemd/system/kube-proxy.service &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[Unit]</span></span><br><span class="line"><span class="string">Description=Kubernetes Proxy</span></span><br><span class="line"><span class="string">After=network.target</span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">EnvironmentFile=/opt/kubernetes/cfg/kube-proxy.conf</span></span><br><span class="line"><span class="string">ExecStart=/opt/kubernetes/bin/kube-proxy \$KUBE_PROXY_OPTS</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string">LimitNOFILE=65536</span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><ol start="5"><li>启动并设置开机启动</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kube-proxy</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-proxy</span><br></pre></td></tr></table></figure><h3 id="部署-CNI-网络"><a href="#部署-CNI-网络" class="headerlink" title="部署 CNI 网络"></a>部署 CNI 网络</h3><p>先准备好 CNI 二进制文件： </p><p>下载地址： <a class="link"   href="https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz" >https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz<i class="fas fa-external-link-alt"></i></a> </p><p>解压二进制包并移动到默认工作目录：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /opt/cni/bin</span><br><span class="line">tar zxvf cni-plugins-linux-amd64-v0.8.6.tgz -C</span><br></pre></td></tr></table></figure><p>部署 CNI 网络：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget</span><br><span class="line">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kubeflannel.yml</span><br><span class="line">sed -i -r <span class="string">&quot;s#quay.io/coreos/flannel:.*-amd64#lizhenliang/flannel:v0.12.0-amd64#g&quot;</span> kube-flannel.yml</span><br></pre></td></tr></table></figure><p>默认镜像地址无法访问，修改为 docker hub 镜像仓库。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kube-flannel.yml</span><br><span class="line">kubectl get pods -n kube-system</span><br><span class="line">kubectl get node</span><br></pre></td></tr></table></figure><p>部署好网络插件，Node 准备就绪。</p><h3 id="授权-apiserver-访问-kubelet"><a href="#授权-apiserver-访问-kubelet" class="headerlink" title="授权 apiserver 访问 kubelet"></a>授权 apiserver 访问 kubelet</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; apiserver-to-kubelet-rbac.yaml&lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="string">kind: ClusterRole</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">    annotations:</span></span><br><span class="line"><span class="string">        rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span></span><br><span class="line"><span class="string">    labels:</span></span><br><span class="line"><span class="string">        kubernetes.io/bootstrapping: rbac-defaults</span></span><br><span class="line"><span class="string">    name: system:kube-apiserver-to-kubelet</span></span><br><span class="line"><span class="string">rules:</span></span><br><span class="line"><span class="string">    - apiGroups:</span></span><br><span class="line"><span class="string">        - &quot;&quot;</span></span><br><span class="line"><span class="string">    resources:</span></span><br><span class="line"><span class="string">        - nodes/proxy</span></span><br><span class="line"><span class="string">        - nodes/stats</span></span><br><span class="line"><span class="string">        - nodes/log</span></span><br><span class="line"><span class="string">        - nodes/spec</span></span><br><span class="line"><span class="string">        - nodes/metrics</span></span><br><span class="line"><span class="string">        - pods/log</span></span><br><span class="line"><span class="string">    verbs:</span></span><br><span class="line"><span class="string">    - &quot;*&quot;</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="string">kind: ClusterRoleBinding</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">    name: system:kube-apiserver</span></span><br><span class="line"><span class="string">    namespace: &quot;&quot;</span></span><br><span class="line"><span class="string">roleRef:</span></span><br><span class="line"><span class="string">    apiGroup: rbac.authorization.k8s.io</span></span><br><span class="line"><span class="string">    kind: ClusterRole</span></span><br><span class="line"><span class="string">    name: system:kube-apiserver-to-kubelet</span></span><br><span class="line"><span class="string">subjects:</span></span><br><span class="line"><span class="string">    - apiGroup: rbac.authorization.k8s.io</span></span><br><span class="line"><span class="string">        kind: User</span></span><br><span class="line"><span class="string">        name: kubernetes</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">kubectl apply -f apiserver-to-kubelet-rbac.yaml</span><br></pre></td></tr></table></figure><h3 id="新增加-Worker-Node"><a href="#新增加-Worker-Node" class="headerlink" title="新增加 Worker Node"></a>新增加 Worker Node</h3><ol><li>拷贝已部署好的 Node 相关文件到新节点</li></ol><p>在 master 节点将 Worker Node 涉及文件拷贝到新节点 192.168.31.72&#x2F;73</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scp -r /opt/kubernetes root@192.168.31.72:/opt/</span><br><span class="line">scp -r /usr/lib/systemd/system/&#123;kubelet,kube-proxy&#125;.service root@192.168.31.72:/usr/lib/systemd/system</span><br><span class="line">scp -r /opt/cni/ root@192.168.31.72:/opt/</span><br><span class="line">scp /opt/kubernetes/ssl/ca.pem root@192.168.31.72:/opt/kubernetes/ssl</span><br></pre></td></tr></table></figure><ol start="2"><li>删除 kubelet 证书和 kubeconfig 文件</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> /opt/kubernetes/cfg/kubelet.kubeconfig</span><br><span class="line"><span class="built_in">rm</span> -f /opt/kubernetes/ssl/kubelet*</span><br></pre></td></tr></table></figure><p>注：这几个文件是证书申请审批后自动生成的，每个 Node 不同，必须删除重新生成。</p><ol start="3"><li>修改主机名</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /opt/kubernetes/cfg/kubelet.conf</span><br><span class="line">--hostname-override=k8s-node1</span><br><span class="line"></span><br><span class="line">vi /opt/kubernetes/cfg/kube-proxy-config.yml</span><br><span class="line">hostnameOverride: k8s-node1</span><br></pre></td></tr></table></figure><ol start="4"><li>启动并设置开机启动</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start kubelet</span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet</span><br><span class="line">systemctl start kube-proxy</span><br><span class="line">systemctl <span class="built_in">enable</span> kube-proxy</span><br></pre></td></tr></table></figure><ol start="5"><li>在 Master 上批准新 Node kubelet 证书申请</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl get csr</span><br><span class="line"></span><br><span class="line">NAME AGE SIGNERNAME</span><br><span class="line">REQUESTOR CONDITION</span><br><span class="line">node-csr-4zTjsaVSrhuyhIGqsefxzVoZDCNKei-aE2jyTP81Uro 89s</span><br><span class="line">kubernetes.io/kube-apiserver-client-kubelet kubelet-bootstrap Pending</span><br><span class="line">kubectl certificate approve node-csr-4zTjsaVSrhuyhIGqsefxzVoZDCNKeiaE2jyTP81Uro</span><br></pre></td></tr></table></figure><ol start="6"><li>查看 Node状态</li></ol><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kubectl get node</span><br></pre></td></tr></table></figure><p>Node2（192.168.31.73 ）节点同上。记得修改主机名！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h2&gt;&lt;p&gt;在开始之前，部署Kubernetes集群机器需要满足以下几个条件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一台或多台机器，操作系统Cent</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之使用kubeadm方式搭建K8S集群</title>
    <link href="http://example.com/2022/08/20/k8s%E4%B9%8B%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/"/>
    <id>http://example.com/2022/08/20/k8s%E4%B9%8B%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/</id>
    <published>2022-08-20T08:22:48.000Z</published>
    <updated>2022-08-24T09:02:22.617Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用kubeadm方式搭建K8S集群"><a href="#使用kubeadm方式搭建K8S集群" class="headerlink" title="使用kubeadm方式搭建K8S集群"></a>使用kubeadm方式搭建K8S集群</h1><p>kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。</p><p>这个工具能通过两条指令完成一个kubernetes集群的部署：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个 Master 节点</span></span><br><span class="line">kubeadm init</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将一个 Node 节点加入到当前集群中</span></span><br><span class="line">kubeadm <span class="built_in">join</span> &lt;Master节点的IP和端口 &gt;</span><br></pre></td></tr></table></figure><h2 id="Kubeadm方式搭建K8S集群"><a href="#Kubeadm方式搭建K8S集群" class="headerlink" title="Kubeadm方式搭建K8S集群"></a>Kubeadm方式搭建K8S集群</h2><p>使用kubeadm方式搭建K8s集群主要分为以下几步</p><ul><li>准备三台虚拟机，同时安装操作系统CentOS 7.x</li><li>对三个安装之后的操作系统进行初始化操作</li><li>在三个节点安装 docker kubelet kubeadm kubectl</li><li>在master节点执行kubeadm init命令初始化</li><li>在node节点上执行 kubeadm join命令，把node节点添加到当前集群</li><li>配置CNI网络插件，用于节点之间的连通【失败了可以多试几次】</li><li>通过拉取一个nginx进行测试，能否进行外网测试</li></ul><h2 id="安装要求"><a href="#安装要求" class="headerlink" title="安装要求"></a>安装要求</h2><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件：</p><ul><li>一台或多台机器，操作系统 CentOS7.x-86_x64</li><li>硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多【注意master需要两核】</li><li>可以访问外网，需要拉取镜像，如果服务器不能上网，需要提前下载镜像并导入节点</li><li>禁止swap分区</li></ul><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><table><thead><tr><th>角色</th><th>IP</th></tr></thead><tbody><tr><td>master</td><td>192.168.177.130</td></tr><tr><td>node1</td><td>192.168.177.131</td></tr><tr><td>node2</td><td>192.168.177.132</td></tr></tbody></table><p>然后开始在每台机器上执行下面的命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭防火墙</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭selinux</span></span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line">sed -i <span class="string">&#x27;s/enforcing/disabled/&#x27;</span> /etc/selinux/config  </span><br><span class="line"><span class="comment"># 临时关闭</span></span><br><span class="line">setenforce 0  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭swap</span></span><br><span class="line"><span class="comment"># 临时</span></span><br><span class="line">swapoff -a </span><br><span class="line"><span class="comment"># 永久关闭</span></span><br><span class="line">sed -ri <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据规划设置主机名【master节点上操作】</span></span><br><span class="line">hostnamectl set-hostname k8smaster</span><br><span class="line"><span class="comment"># 根据规划设置主机名【node1节点操作】</span></span><br><span class="line">hostnamectl set-hostname k8snode1</span><br><span class="line"><span class="comment"># 根据规划设置主机名【node2节点操作】</span></span><br><span class="line">hostnamectl set-hostname k8snode2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在master添加hosts</span></span><br><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/hosts &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">192.168.177.130 k8smaster</span></span><br><span class="line"><span class="string">192.168.177.131 k8snode1</span></span><br><span class="line"><span class="string">192.168.177.132 k8snode2</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将桥接的IPv4流量传递到iptables的链</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/sysctl.d/k8s.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables = 1</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 生效</span></span><br><span class="line">sysctl --system  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间同步</span></span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate time.windows.com</span><br></pre></td></tr></table></figure><h2 id="安装Docker-x2F-kubeadm-x2F-kubelet"><a href="#安装Docker-x2F-kubeadm-x2F-kubelet" class="headerlink" title="安装Docker&#x2F;kubeadm&#x2F;kubelet"></a>安装Docker&#x2F;kubeadm&#x2F;kubelet</h2><p>所有节点安装Docker&#x2F;kubeadm&#x2F;kubelet ，Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker</p><h3 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h3><p>首先配置一下Docker的阿里yum源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt;/etc/yum.repos.d/docker.repo&lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">[docker-ce-edge]</span></span><br><span class="line"><span class="string">name=Docker CE Edge - \$basearch</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/7/\$basearch/edge</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=1</span></span><br><span class="line"><span class="string">gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>然后yum方式安装docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum安装</span></span><br><span class="line">yum -y install docker-ce</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看docker版本</span></span><br><span class="line">docker --version  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动docker</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure><p>配置docker的镜像源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt;&gt; /etc/docker/daemon.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><p>然后重启docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h3 id="添加kubernetes软件源"><a href="#添加kubernetes软件源" class="headerlink" title="添加kubernetes软件源"></a>添加kubernetes软件源</h3><p>然后我们还需要配置一下yum的k8s软件源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[kubernetes]</span></span><br><span class="line"><span class="string">name=Kubernetes</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">repo_gpgcheck=0</span></span><br><span class="line"><span class="string">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><h3 id="安装kubeadm，kubelet和kubectl"><a href="#安装kubeadm，kubelet和kubectl" class="headerlink" title="安装kubeadm，kubelet和kubectl"></a>安装kubeadm，kubelet和kubectl</h3><p>由于版本更新频繁，这里指定版本号部署：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装kubelet、kubeadm、kubectl，同时指定版本</span></span><br><span class="line">yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0</span><br><span class="line"><span class="comment"># 设置开机启动</span></span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet</span><br></pre></td></tr></table></figure><h2 id="部署Kubernetes-Master【master节点】"><a href="#部署Kubernetes-Master【master节点】" class="headerlink" title="部署Kubernetes Master【master节点】"></a>部署Kubernetes Master【master节点】</h2><p>在   192.168.177.130  执行，也就是master节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --apiserver-advertise-address=192.168.177.130 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --service-cidr=10.96.0.0/12  --pod-network-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure><p>由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址，【执行上述命令会比较慢，因为后台其实已经在拉取镜像了】，我们 docker images 命令即可查看已经拉取的镜像</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20200929094302491.png"                      alt="image-20200929094302491"                ></p><p>当我们出现下面的情况时，表示kubernetes的镜像已经安装成功</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20200929094620145.png"                      alt="image-20200929094620145"                ></p><p>使用kubectl工具 【master节点操作】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>执行完成后，我们使用下面命令，查看我们正在运行的节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20200929094933142.png"                      alt="image-20200929094933142"                ></p><p>能够看到，目前有一个master节点已经运行了，但是还处于未准备状态</p><p>下面我们还需要在Node节点执行其它的命令，将node1和node2加入到我们的master节点上</p><h2 id="加入Kubernetes-Node【Slave节点】"><a href="#加入Kubernetes-Node【Slave节点】" class="headerlink" title="加入Kubernetes Node【Slave节点】"></a>加入Kubernetes Node【Slave节点】</h2><p>下面我们需要到 node1 和 node2服务器，执行下面的代码向集群添加新节点</p><p>执行在kubeadm init输出的kubeadm join命令：</p><blockquote><p>注意，以下的命令是在master初始化完成后，每个人的都不一样！！！需要复制自己生成的</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm <span class="built_in">join</span> 192.168.177.130:6443 --token 8j6ui9.gyr4i156u30y80xf \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:eda1380256a62d8733f4bddf926f148e57cf9d1a3a58fb45dd6e80768af5a500</span><br></pre></td></tr></table></figure><p>默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，操作如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure><p>当我们把两个节点都加入进来后，我们就可以去Master节点 执行下面命令查看情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node</span><br></pre></td></tr></table></figure><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113165358663.png"                      alt="image-20201113165358663"                ></p><h2 id="部署CNI网络插件"><a href="#部署CNI网络插件" class="headerlink" title="部署CNI网络插件"></a>部署CNI网络插件</h2><p>上面的状态还是NotReady，下面我们需要网络插件，来进行联网访问</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载网络插件配置</span></span><br><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><p>默认镜像地址无法访问，sed命令修改为docker hub镜像仓库。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加</span></span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line"></span><br><span class="line"><span class="comment">##①首先下载v0.13.1-rc2-amd64 镜像</span></span><br><span class="line"><span class="comment">##参考博客：https://www.cnblogs.com/pyxuexi/p/14288591.html</span></span><br><span class="line"><span class="comment">##② 导入镜像，命令，，特别提示，3个机器都需要导入，3个机器都需要导入，3个机器都需要导入，3个机器都需要导入，重要的事情说3遍。不然抱错。如果没有操作，报错后，需要删除节点，重置，在导入镜像，重新加入才行。本地就是这样操作成功的！</span></span><br><span class="line">docker load &lt; flanneld-v0.13.1-rc2-amd64.docker</span><br><span class="line"><span class="comment">#####下载本地，替换将image: quay.io/coreos/flannel:v0.13.1-rc2 替换为 image: quay.io/coreos/flannel:v0.13.1-rc2-amd64</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态 【kube-system是k8s中的最小单元】</span></span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure><p>运行后的结果</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113165929510.png"                      alt="image-20201113165929510"                ></p><p>运行完成后，我们查看状态可以发现，已经变成了Ready状态了</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113194557147.png"                      alt="image-20201113194557147"                ></p><p>如果上述操作完成后，还存在某个节点处于NotReady状态，可以在Master将该节点删除</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># master节点将该节点删除</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##20210223 yan 查阅资料添加###kubectl drain k8snode1 --delete-local-data --force --ignore-daemonsets</span></span><br><span class="line"></span><br><span class="line">kubectl delete node k8snode1</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 然后到k8snode1节点进行重置</span></span><br><span class="line"> kubeadm reset</span><br><span class="line"><span class="comment"># 重置完后在加入</span></span><br><span class="line">kubeadm <span class="built_in">join</span> 192.168.177.130:6443 --token 8j6ui9.gyr4i156u30y80xf     --discovery-token-ca-cert-hash sha256:eda1380256a62d8733f4bddf926f148e57cf9d1a3a58fb45dd6e80768af5a500</span><br></pre></td></tr></table></figure><h2 id="测试kubernetes集群"><a href="#测试kubernetes集群" class="headerlink" title="测试kubernetes集群"></a>测试kubernetes集群</h2><p>我们都知道K8S是容器化技术，它可以联网去下载镜像，用容器的方式进行启动</p><p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载nginx 【会联网拉取nginx镜像】</span></span><br><span class="line">kubectl create deployment nginx --image=nginx</span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">kubectl get pod</span><br></pre></td></tr></table></figure><p>如果我们出现Running状态的时候，表示已经成功运行了</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113203537028.png"                      alt="image-20201113203537028"                ></p><p>下面我们就需要将端口暴露出去，让其它外界能够访问</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 暴露端口</span></span><br><span class="line">kubectl expose deployment nginx --port=80 --<span class="built_in">type</span>=NodePort</span><br><span class="line"><span class="comment"># 查看一下对外的端口</span></span><br><span class="line">kubectl get pod,svc</span><br></pre></td></tr></table></figure><p>能够看到，我们已经成功暴露了 80端口  到 30529上</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113203840915.png"                      alt="image-20201113203840915"                ></p><p>我们到我们的宿主机浏览器上，访问如下地址</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.177.130:30529/</span><br></pre></td></tr></table></figure><p>发现我们的nginx已经成功启动了</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113204056851.png"                      alt="image-20201113204056851"                ></p><p>到这里为止，我们就搭建了一个单master的k8s集群</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="/../../../../../%E6%96%B0%E7%9F%A5%E8%AF%86/LearningNotes-master/K8S/3_%E4%BD%BF%E7%94%A8kubeadm%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4/images/image-20201113204158884.png"                      alt="image-20201113204158884"                ></p><h2 id="错误汇总"><a href="#错误汇总" class="headerlink" title="错误汇总"></a>错误汇总</h2><h3 id="错误一"><a href="#错误一" class="headerlink" title="错误一"></a>错误一</h3><p>在执行Kubernetes  init方法的时候，出现这个问题</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class="line">[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2</span><br></pre></td></tr></table></figure><p>是因为VMware设置的核数为1，而K8S需要的最低核数应该是2，调整核数重启系统即可</p><h3 id="错误二"><a href="#错误二" class="headerlink" title="错误二"></a>错误二</h3><p>我们在给node1节点使用 kubernetes join命令的时候，出现以下错误</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class="line">[ERROR Swap]: running with swap on is not supported. Please <span class="built_in">disable</span> swap</span><br></pre></td></tr></table></figure><p>错误原因是我们需要关闭swap</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭swap</span></span><br><span class="line"><span class="comment"># 临时</span></span><br><span class="line">swapoff -a </span><br><span class="line"><span class="comment"># 临时</span></span><br><span class="line">sed -ri <span class="string">&#x27;s/.*swap.*/#&amp;/&#x27;</span> /etc/fstab</span><br></pre></td></tr></table></figure><h3 id="错误三"><a href="#错误三" class="headerlink" title="错误三"></a>错误三</h3><p>在给node1节点使用 kubernetes join命令的时候，出现以下错误</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The HTTP call equal to <span class="string">&#x27;curl -sSL http://localhost:10248/healthz&#x27;</span> failed with error: Get http://localhost:10248/healthz: dial tcp [::1]:10248: connect: connection refused</span><br></pre></td></tr></table></figure><p>解决方法，首先需要到 master 节点，创建一个文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建文件夹</span></span><br><span class="line"><span class="built_in">mkdir</span> /etc/systemd/system/kubelet.service.d</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建文件</span></span><br><span class="line">vim /etc/systemd/system/kubelet.service.d/10-kubeadm.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加如下内容</span></span><br><span class="line">Environment=<span class="string">&quot;KUBELET_SYSTEM_PODS_ARGS=--pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true --fail-swap-on=false&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重置</span></span><br><span class="line">kubeadm reset</span><br></pre></td></tr></table></figure><p>然后删除刚刚创建的配置目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf <span class="variable">$HOME</span>/.kube</span><br></pre></td></tr></table></figure><p>然后 在master重新初始化</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --apiserver-advertise-address=202.193.57.11 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --service-cidr=10.96.0.0/12  --pod-network-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure><p>初始完成后，我们再到 node1节点，执行 kubeadm join命令，加入到master</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm <span class="built_in">join</span> 202.193.57.11:6443 --token c7a7ou.z00fzlb01d76r37s \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:9c3f3cc3f726c6ff8bdff14e46b1a856e3b8a4cbbe30cab185f6c5ee453aeea5</span><br></pre></td></tr></table></figure><p>添加完成后，我们使用下面命令，查看节点是否成功添加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><h3 id="错误四"><a href="#错误四" class="headerlink" title="错误四"></a>错误四</h3><p>我们再执行查看节点的时候，  kubectl get nodes 会出现问题</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of <span class="string">&quot;crypto/rsa: verification error&quot;</span> <span class="keyword">while</span> trying to verify candidate authority certificate <span class="string">&quot;kubernetes&quot;</span>)</span><br></pre></td></tr></table></figure><p>这是因为我们之前创建的配置文件还存在，也就是这些配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>我们需要做的就是把配置文件删除，然后重新执行一下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf <span class="variable">$HOME</span>/.kube</span><br></pre></td></tr></table></figure><p>然后再次创建一下即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo <span class="built_in">cp</span> -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo <span class="built_in">chown</span> $(<span class="built_in">id</span> -u):$(<span class="built_in">id</span> -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>这个问题主要是因为我们在执行 kubeadm reset 的时候，没有把 $HOME&#x2F;.kube 给移除掉，再次创建时就会出现问题了</p><h3 id="错误五"><a href="#错误五" class="headerlink" title="错误五"></a>错误五</h3><p>安装的时候，出现以下错误</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Another app is currently holding the yum lock; waiting <span class="keyword">for</span> it to <span class="built_in">exit</span>...</span><br></pre></td></tr></table></figure><p>是因为yum上锁占用，解决方法</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install docker-ce</span><br></pre></td></tr></table></figure><h3 id="错误六"><a href="#错误六" class="headerlink" title="错误六"></a>错误六</h3><p>在使用下面命令，添加node节点到集群上的时候</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm <span class="built_in">join</span> 192.168.177.130:6443 --token jkcz0t.3c40t0bqqz5g8wsb  --discovery-token-ca-cert-hash sha256:bc494eeab6b7bac64c0861da16084504626e5a95ba7ede7b9c2dc7571ca4c9e5</span><br></pre></td></tr></table></figure><p>然后出现了这个错误</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8smaster ~]<span class="comment"># kubeadm join 192.168.177.130:6443 --token jkcz0t.3c40t0bqqz5g8wsb     --discovery-token-ca-cert-hash sha256:bc494eeab6b7bac64c0861da16084504626e5a95ba7ede7b9c2dc7571ca4c9e5</span></span><br><span class="line">W1117 06:55:11.220907   11230 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not <span class="built_in">set</span>.</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[WARNING IsDockerSystemdCheck]: detected <span class="string">&quot;cgroupfs&quot;</span> as the Docker cgroup driver. The recommended driver is <span class="string">&quot;systemd&quot;</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class="line">[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not <span class="built_in">set</span> to 1</span><br><span class="line">[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`</span><br><span class="line">To see the stack trace of this error execute with --v=5 or higher</span><br></pre></td></tr></table></figure><p>出于安全考虑，Linux系统<strong>默认是禁止数据包转发</strong>的。所谓<strong>转发即当主机拥有多于一块的网卡时，其中一块收到数据包，根据数据包的目的ip地址将包发往本机另一网卡，该网卡根据路由表继续发送数据包</strong>。这通常就是路由器所要实现的功能。也就是说  <strong>&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;ip_forward</strong> 文件的值不支持转发</p><ul><li>0：禁止</li><li>1：转发</li></ul><p>所以我们需要将值修改成1即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> “1” &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><p>修改完成后，重新执行命令即可</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用kubeadm方式搭建K8S集群&quot;&gt;&lt;a href=&quot;#使用kubeadm方式搭建K8S集群&quot; class=&quot;headerlink&quot; title=&quot;使用kubeadm方式搭建K8S集群&quot;&gt;&lt;/a&gt;使用kubeadm方式搭建K8S集群&lt;/h1&gt;&lt;p&gt;kubead</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之搭建K8S集群前置知识</title>
    <link href="http://example.com/2022/08/20/k8s%E4%B9%8B%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/"/>
    <id>http://example.com/2022/08/20/k8s%E4%B9%8B%E6%90%AD%E5%BB%BAK8S%E9%9B%86%E7%BE%A4%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/</id>
    <published>2022-08-20T07:58:53.000Z</published>
    <updated>2022-08-25T01:00:19.142Z</updated>
    
    <content type="html"><![CDATA[<h2 id="搭建k8s环境平台规划"><a href="#搭建k8s环境平台规划" class="headerlink" title="搭建k8s环境平台规划"></a>搭建k8s环境平台规划</h2><h3 id="单master集群"><a href="#单master集群" class="headerlink" title="单master集群"></a>单master集群</h3><p>单个master节点，然后管理多个node节点</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20200928110456495.png"                      alt="image-20200928110456495"                ></p><h3 id="多master集群"><a href="#多master集群" class="headerlink" title="多master集群"></a>多master集群</h3><p>多个master节点，管理多个node节点，同时中间多了一个负载均衡的过程</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20200928110543829.png"                      alt="image-20200928110543829"                ></p><h2 id="服务器硬件配置要求"><a href="#服务器硬件配置要求" class="headerlink" title="服务器硬件配置要求"></a>服务器硬件配置要求</h2><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>master：2核  4G  20G</p><p>node：   4核  8G  40G</p><h3 id="生产环境"><a href="#生产环境" class="headerlink" title="生产环境"></a>生产环境</h3><p>master：8核  16G  100G</p><p>node：   16核  64G  200G</p><p>目前生产部署Kubernetes集群主要有两种方式</p><h3 id="kubeadm"><a href="#kubeadm" class="headerlink" title="kubeadm"></a>kubeadm</h3><p>kubeadm是一个K8S部署工具，提供kubeadm init 和 kubeadm join，用于快速部署Kubernetes集群</p><p>官网地址：<a class="link"   href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/" >点我传送<i class="fas fa-external-link-alt"></i></a></p><h3 id="二进制包"><a href="#二进制包" class="headerlink" title="二进制包"></a>二进制包</h3><p>从github下载发行版的二进制包，手动部署每个组件，组成Kubernetes集群。</p><p>Kubeadm降低部署门槛，但屏蔽了很多细节，遇到问题很难排查。如果想更容易可控，推荐使用二进制包部署Kubernetes集群，虽然手动部署麻烦点，期间可以学习很多工作原理，也利于后期维护。</p><h2 id="Kubeadm部署集群"><a href="#Kubeadm部署集群" class="headerlink" title="Kubeadm部署集群"></a>Kubeadm部署集群</h2><p>kubeadm 是官方社区推出的一个用于快速部署kubernetes 集群的工具，这个工具能通过两条指令完成一个kubernetes 集群的部署：</p><ul><li>创建一个Master 节点kubeadm init</li><li>将Node 节点加入到当前集群中$ kubeadm join &lt;Master 节点的IP 和端口&gt;</li></ul><h2 id="安装要求"><a href="#安装要求" class="headerlink" title="安装要求"></a>安装要求</h2><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件</p><ul><li>一台或多台机器，操作系统为Centos7.X</li><li>硬件配置：2GB或更多GAM，2个CPU或更多CPU，硬盘30G</li><li>集群中所有机器之间网络互通</li><li>可以访问外网，需要拉取镜像</li><li>禁止swap分区</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;搭建k8s环境平台规划&quot;&gt;&lt;a href=&quot;#搭建k8s环境平台规划&quot; class=&quot;headerlink&quot; title=&quot;搭建k8s环境平台规划&quot;&gt;&lt;/a&gt;搭建k8s环境平台规划&lt;/h2&gt;&lt;h3 id=&quot;单master集群&quot;&gt;&lt;a href=&quot;#单master集</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s之kubernetes概述</title>
    <link href="http://example.com/2022/08/20/k8s%E4%B9%8Bkubernetes%E6%A6%82%E8%BF%B0/"/>
    <id>http://example.com/2022/08/20/k8s%E4%B9%8Bkubernetes%E6%A6%82%E8%BF%B0/</id>
    <published>2022-08-20T03:14:25.000Z</published>
    <updated>2022-08-25T00:55:14.749Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>K8S主要讲的就是Kubernetes，首先Kubernetes首字母为K，末尾为s，中间一共有8个字母，所以简称K8s</p><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><ul><li>Linux操作系统</li><li>Docker</li></ul><h2 id="课程简介"><a href="#课程简介" class="headerlink" title="课程简介"></a>课程简介</h2><ul><li><p>K8s概念和架构</p></li><li><p>从零搭建K8s集群</p><ul><li>基于客户端工具kubeadm搭建（简单，最多半小时）</li><li>基于二进制包方式（能看到内部的架构）</li></ul></li><li><p>K8s核心概念</p><ul><li>Pod：K8s管理的最小单位级，是所有业务类型的基础</li><li>Controller：控制器，有状态，无状态，一次任务，定时任务，守护进程</li><li>Service Ingress：对外暴露端口</li><li>RBAC：安全机制，权限模型</li><li>Helm：下载机制</li><li>持久化存储</li></ul></li><li><p>搭建集群监控平台系统</p></li><li><p>从零搭建高可用K8s集群</p></li><li><p>在集群环境部署项目</p></li></ul><h2 id="K8S概念和特性"><a href="#K8S概念和特性" class="headerlink" title="K8S概念和特性"></a>K8S概念和特性</h2><h3 id="部署发展历程"><a href="#部署发展历程" class="headerlink" title="部署发展历程"></a>部署发展历程</h3><p>我们的项目部署也在经历下面的这样一个历程</p><blockquote><p>传统部署 -&gt; 虚拟化部署时代 -&gt; 容器部署时代</p></blockquote><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://s2.loli.net/2022/08/21/x8mpD6GzLdgwATQ.png"                      alt="image-20201122104102715"                ></p><ul><li><strong>传统部署时代</strong>：早期，组织在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。例如，如果在物理服务器上运行多个应用程序，则可能会出现-一个应用程序占用大部分资源的情况，结果可能导致其他应用程序的性能下降。–种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展，并且组织维护许多物理服务器的成本很高。</li><li><strong>虚拟化部署时代</strong>：作为解决方案，引入了虚拟化功能，它允许您在单个物理服务器的CPU.上运行多个虚拟机（VM）。虚拟化功能允许应用程序在VM之间隔离，并提供安全级别，因为一一个应用程序的信息不能被另一应用程序自由地访问。因为虚拟化可以轻松地添加或更新应用程序、降低硬件成本等等，所以虚拟化可以更好地利用物理服务器中的资源，并可以实现更好的可伸缩性。每个VM是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。</li><li><strong>容器部署时代</strong>：容器类似于VM，但是它们具有轻量级的隔离属性，可以在应用程序之间共享操作系统<br>（OS），因此，容器被认为是轻量级的。容器与VM类似，具有自己的文件系统、CPU、内存、进程空间等。由于它们与基础架构分离，因此可以跨云和OS分发进行移植。</li></ul><p>容器因具有许多优势而变得流行起来。下面列出了容器的一些好处：</p><ul><li>敏捷应用程序的创建和部署：与使用VM镜像相比，提高了容器镜像创建的简便性和效率。</li><li>持续开发、集成和部署：通过简单的回滚（由于镜像不可变性），提供可靠且频繁的容器镜像构建和部署。</li><li>关注开发与运维的分离：在构建&#x2F;时而不是在部署时创建应用程序容器镜像，将应用程序与基础架构分离。</li><li>可观察性：不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。</li><li>跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。</li><li>云和操作系统分发的可移植性：可在Ubuntu、RHEL、RHEL、CoreOS、本地、Google Kubernetes Engine和其它任何其它地方运行。</li><li>以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行OS到使用逻辑资源在OS上运行应用程序。</li><li>松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分，并且可以动态部署和管理-而不是在一台大型单机上器体运行。</li><li>资源隔离：可预测的应用程序性能。</li></ul><h3 id="K8S概述"><a href="#K8S概述" class="headerlink" title="K8S概述"></a>K8S概述</h3><p>kubernetes，简称K8s，是用8 代替8 个字符“ubernete”而成的缩写。是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes 提供了应用部署，规划，更新，维护的一种机制。</p><p>传统的应用部署方式是通过插件或脚本来安装应用。这样做的缺点是应用的运行、配置、管理、所有生存周期将与当前操作系统绑定，这样做并不利于应用的升级更新&#x2F;回滚等操作，当然也可以通过创建虚拟机的方式来实现某些功能，但是虚拟机非常重，并不利于可移植性。</p><p>新的方式是通过部署容器方式实现，每个容器之间互相隔离，每个容器有自己的文件系统，容器之间进程不会相互影响，能区分计算资源。相对于虚拟机，容器能快速部署，由于容器与底层设施、机器文件系统解耦的。</p><blockquote><p>总结：</p><ul><li>K8s是谷歌在2014年发布的容器化集群管理系统</li><li>使用k8s进行容器化应用部署</li><li>使用k8s利于应用扩展</li><li>k8s目标实施让部署容器化应用更加简洁和高效</li></ul></blockquote><h3 id="K8S概述-1"><a href="#K8S概述-1" class="headerlink" title="K8S概述"></a>K8S概述</h3><p>Kubernetes 是一个轻便的和可扩展的开源平台，用于管理容器化应用和服务。通过Kubernetes 能够进行应用的自动化部署和扩缩容。在Kubernetes 中，会将组成应用的容器组合成一个逻辑单元以更易管理和发现。</p><p>Kubernetes 积累了作为Google 生产环境运行工作负载15 年的经验，并吸收了来自于社区的最佳想法和实践。</p><h3 id="K8S功能"><a href="#K8S功能" class="headerlink" title="K8S功能"></a>K8S功能</h3><h4 id="自动装箱"><a href="#自动装箱" class="headerlink" title="自动装箱"></a>自动装箱</h4><p>基于容器对应用运行环境的资源配置要求自动部署应用容器</p><h4 id="自我修复-自愈能力"><a href="#自我修复-自愈能力" class="headerlink" title="自我修复(自愈能力)"></a>自我修复(自愈能力)</h4><p>当容器失败时，会对容器进行重启</p><p>当所部署的Node节点有问题时，会对容器进行重新部署和重新调度</p><p>当容器未通过监控检查时，会关闭此容器直到容器正常运行时，才会对外提供服务</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20220824215044545.png"                      alt="image-20220824215044545"                ></p><p>如果某个服务器上的应用不响应了，Kubernetes会自动在其它的地方创建一个</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122112241092.png"                      alt="image-20201122112241092"                ></p><h4 id="水平扩展"><a href="#水平扩展" class="headerlink" title="水平扩展"></a>水平扩展</h4><p>通过简单的命令、用户UI 界面或基于CPU 等资源使用情况，对应用容器进行规模扩大或规模剪裁</p><blockquote><p>当我们有大量的请求来临时，我们可以增加副本数量，从而达到水平扩展的效果</p></blockquote><p>当黄色应用过度忙碌，会来扩展一个应用</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122112301750.png"                      alt="image-20201122112301750"                ></p><h4 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h4><p>用户不需使用额外的服务发现机制，就能够基于Kubernetes 自身能力实现服务发现和负载均衡</p><blockquote><p>对外提供统一的入口，让它来做节点的调度和负载均衡， 相当于微服务里面的网关？</p></blockquote><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20200928101711968.png"                      alt="image-20200928101711968"                ></p><h4 id="滚动更新"><a href="#滚动更新" class="headerlink" title="滚动更新"></a>滚动更新</h4><p>可以根据应用的变化，对应用容器运行的应用，进行一次性或批量式更新</p><blockquote><p>添加应用的时候，不是加进去就马上可以进行使用，而是需要判断这个添加进去的应用是否能够正常使用</p></blockquote><h4 id="版本回退"><a href="#版本回退" class="headerlink" title="版本回退"></a>版本回退</h4><p>可以根据应用部署情况，对应用容器运行的应用，进行历史版本即时回退</p><blockquote><p>类似于Git中的回滚</p></blockquote><h4 id="密钥和配置管理"><a href="#密钥和配置管理" class="headerlink" title="密钥和配置管理"></a>密钥和配置管理</h4><p>在不需要重新构建镜像的情况下，可以部署和更新密钥和应用配置，类似热部署。</p><h4 id="存储编排"><a href="#存储编排" class="headerlink" title="存储编排"></a>存储编排</h4><p>自动实现存储系统挂载及应用，特别对有状态应用实现数据持久化非常重要</p><p>存储系统可以来自于本地目录、网络存储(NFS、Gluster、Ceph 等)、公共云存储服务</p><h4 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h4><p>提供一次性任务，定时任务；满足批量数据处理和分析的场景</p><h2 id="K8S架构组件"><a href="#K8S架构组件" class="headerlink" title="K8S架构组件"></a>K8S架构组件</h2><h3 id="完整架构图"><a href="#完整架构图" class="headerlink" title="完整架构图"></a>完整架构图</h3><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20200928103059652.png"                      alt="image-20200928103059652"                ></p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20200928110124821.png"                      alt="image-20200928110124821"                ></p><h3 id="架构细节"><a href="#架构细节" class="headerlink" title="架构细节"></a>架构细节</h3><p>K8S架构主要包含两部分：Master（主控节点）和 node（工作节点）</p><p>master节点架构图</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122113057343.png"                      alt="image-20201122113057343"                ></p><p>Node节点架构图</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122155629990.png"                      alt="image-20201122155629990"                ></p><p>k8s 集群控制节点，对集群进行调度管理，接受集群外用户去集群操作请求；</p><ul><li><p><strong>master</strong>：主控节点</p><ul><li>API Server：集群统一入口，以restful风格进行操作，同时交给etcd存储<ul><li>提供认证、授权、访问控制、API注册和发现等机制</li></ul></li><li>scheduler：节点的调度，选择node节点应用部署</li><li>controller-manager：处理集群中常规后台任务，一个资源对应一个控制器</li><li>etcd：存储系统，用于保存集群中的相关数据</li></ul></li><li><p><strong>Work node</strong>：工作节点</p><ul><li>Kubelet：master派到node节点代表，管理本机容器<ul><li>一个集群中每个节点上运行的代理，它保证容器都运行在Pod中</li><li>负责维护容器的生命周期，同时也负责Volume(CSI) 和 网络(CNI)的管理</li></ul></li><li>kube-proxy：提供网络代理，负载均衡等操作</li></ul></li><li><p>容器运行环境【<strong>Container Runtime</strong>】</p><ul><li>容器运行环境是负责运行容器的软件</li><li>Kubernetes支持多个容器运行环境：Docker、containerd、cri-o、rktlet以及任何实现Kubernetes CRI (容器运行环境接口) 的软件。</li></ul></li><li><p>fluentd：是一个守护进程，它有助于提升 集群层面日志</p></li></ul><h2 id="K8S核心概念"><a href="#K8S核心概念" class="headerlink" title="K8S核心概念"></a>K8S核心概念</h2><h3 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h3><ul><li>Pod是K8s中最小的单元</li><li>一组容器的集合</li><li>共享网络【一个Pod中的所有容器共享同一网络】</li><li>生命周期是短暂的（服务器重启后，就找不到了）</li></ul><h3 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h3><ul><li>声明在Pod容器中可访问的文件目录</li><li>可以被挂载到Pod中一个或多个容器指定路径下</li><li>支持多种后端存储抽象【本地存储、分布式存储、云存储】</li></ul><h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><ul><li>确保预期的pod副本数量【ReplicaSet】</li><li>无状态应用部署【Deployment】<ul><li>无状态就是指，不需要依赖于网络或者ip</li></ul></li><li>有状态应用部署【StatefulSet】<ul><li>有状态需要特定的条件</li></ul></li><li>确保所有的node运行同一个pod 【DaemonSet】</li><li>一次性任务和定时任务【Job和CronJob】</li></ul><h3 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h3><ul><li>定义一组Pod副本数目，版本等</li><li>通过控制器【Controller】维持Pod数目【自动回复失败的Pod】</li><li>通过控制器以指定的策略控制版本【滚动升级、回滚等】</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122161601349.png"                      alt="image-20201122161601349"                ></p><h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><ul><li>定义一组pod的访问规则</li><li>Pod的负载均衡，提供一个或多个Pod的稳定访问地址</li><li>支持多种方式【ClusterIP、NodePort、LoadBalancer】</li></ul><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122161132055.png"                      alt="image-20201122161132055"                ></p><p>可以用来组合pod，同时对外提供服务</p><h3 id="Label"><a href="#Label" class="headerlink" title="Label"></a>Label</h3><p>label：标签，用于对象资源查询，筛选</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122161713638.png"                      alt="image-20201122161713638"                ></p><h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><p>命名空间，逻辑隔离</p><ul><li>一个集群内部的逻辑隔离机制【鉴权、资源】</li><li>每个资源都属于一个namespace</li><li>同一个namespace所有资源不能重复</li><li>不同namespace可以资源名重复</li></ul><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>我们通过Kubernetes的API来操作整个集群</p><p>同时我们可以通过 kubectl 、ui、curl 最终发送 http + json&#x2F;yaml 方式的请求给API Server，然后控制整个K8S集群，K8S中所有的资源对象都可以采用 yaml 或 json 格式的文件定义或描述</p><p>如下：使用yaml部署一个nginx的pod</p><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122162612448.png"                      alt="image-20201122162612448"                ></p><h2 id="完整流程"><a href="#完整流程" class="headerlink" title="完整流程"></a>完整流程</h2><p><img                       lazyload                     src="/images/loading.svg"                     data-src="https://raw.githubusercontent.com/ainianxu/image/master/image-20201122163512535.png"                      alt="image-20201122163512535"                ></p><ul><li>通过Kubectl提交一个创建RC（Replication Controller）的请求，该请求通过APlserver写入etcd</li><li>此时Controller Manager通过API Server的监听资源变化的接口监听到此RC事件</li><li>分析之后，发现当前集群中还没有它所对应的Pod实例</li><li>于是根据RC里的Pod模板定义一个生成Pod对象，通过APIServer写入etcd</li><li>此事件被Scheduler发现，它立即执行执行一个复杂的调度流程，为这个新的Pod选定一个落户的Node，然后通过API Server讲这一结果写入etcd中</li><li>目标Node上运行的Kubelet进程通过APiserver监测到这个”新生的Pod.并按照它的定义，启动该Pod并任劳任怨地负责它的下半生，直到Pod的生命结束</li><li>随后，我们通过Kubectl提交一个新的映射到该Pod的Service的创建请求</li><li>ControllerManager通过Label标签查询到关联的Pod实例，然后生成Service的Endpoints信息，并通过APIServer写入到etod中，</li><li>接下来，所有Node上运行的Proxy进程通过APIServer查询并监听Service对象与其对应的Endponts信息，建立一个软件方式的负载均衡器来实现Service访问到后端Pod的流量转发功能</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;K8S主要讲的就是Kubernetes，首先Kubernetes首字母为K，末尾为s，中间一共有8个字母，所以简称K8s&lt;/p&gt;
&lt;h2 i</summary>
      
    
    
    
    
    <category term="k8s" scheme="http://example.com/tags/k8s/"/>
    
  </entry>
  
</feed>
