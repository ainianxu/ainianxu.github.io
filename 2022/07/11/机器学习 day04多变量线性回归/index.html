<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <title>
        Hexo
    </title>
    
<link rel="stylesheet" href="/libs/highlight/styles/monokai-sublime.css">

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 6.1.0"></head>

<body id="bodyx">
    <div class="hd posts">
    <a href="/index.html"><i class="fa fa-reply replay-btn" aria-hidden="true"></i></a>
    <div class="post-title">
        <p>
            机器学习 day04多变量线性回归
        </p>
        <hr>
    </div>
    <div class="post-content">
        <h1 id="01-多元线性回归–多特征向量情况下的假设形式"><a href="#01-多元线性回归–多特征向量情况下的假设形式" class="headerlink" title="01 多元线性回归–多特征向量情况下的假设形式"></a>01 多元线性回归–多特征向量情况下的假设形式</h1><ul>
<li>一些符号表示：</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/mwgvfjZVI48nydk.png" alt="image-20210711083812186"></p>
<ul>
<li>简化下面等式的表达方法：向量内积转化</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/Z39eqvxKXyL7Ylw.png" alt="image-20210711084514568"></p>
<h1 id="02-多元梯度下降算法"><a href="#02-多元梯度下降算法" class="headerlink" title="02 多元梯度下降算法"></a>02 多元梯度下降算法</h1><ul>
<li>多元线性回归方程+代价函数+梯度下降函数</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/L3nA5bza9WXBYjc.png" alt="image-20210711085058562"></p>
<ul>
<li>单元及多元线性回归的梯度下降法对比</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/twckGH1bURSZfYJ.png" alt="image-20210711085457222"></p>
<h1 id="03-多元梯度下降法–特征缩放"><a href="#03-多元梯度下降法–特征缩放" class="headerlink" title="03 多元梯度下降法–特征缩放"></a>03 多元梯度下降法–特征缩放</h1><ul>
<li>特征缩放的目的只是为了运行更快。使特征值比较接近，使图像变得比较圆。以至于梯度下降的速度更快，收敛所需要的迭代次数更少，收敛更快。缩放前后对比图如下：</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/nZ6opKb5t4mzuwQ.png" alt="image-20210711090921347"></p>
<ul>
<li>特征值的取值别太大也别太小，与下面这个范围足够接近最好。</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/qxjhR1LdObvCNzX.png" alt="image-20210711091300248"></p>
<ul>
<li>均值归一化的工作：X &#x3D;（当前值-平均值）&#x2F;【（最大值-最小值）只要是这个范围左右就可以】</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/NhwYrqOenRAW4XC.png" alt="image-20210711091817337"></p>
<h1 id="04-多元梯度下降法–学习率"><a href="#04-多元梯度下降法–学习率" class="headerlink" title="04 多元梯度下降法–学习率"></a>04 多元梯度下降法–学习率</h1><ul>
<li>梯度算法正常工作图如下：代价函数随迭代次数的变化，最终收敛。</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/ikP2GewhfKAmru9.png" alt="image-20210711100438986"></p>
<ul>
<li>如果所得图像不是一直减小的，那么需要减小学习率，当然学习率也不能过小，否则梯度下降将会十分缓慢，迭代次数无限增加。</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/XkpshNyLCE4YMAe.png" alt="image-20210711100941585"></p>
<ul>
<li>得到一个不错的学习率：按照三的倍数来取值，尝试一系列的学习率，找到个太小的值，再找到另一个太大的值，然后取太大的值，或者比太大的值略小的比较合理的值</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/vjaw7KDY4b61iHs.png" alt="image-20210711101508027"></p>
<h1 id="05-特征和多项式回归"><a href="#05-特征和多项式回归" class="headerlink" title="05 特征和多项式回归"></a>05 特征和多项式回归</h1><ul>
<li>特征可以根据自己的需求选择合适的特征，例如将两个不同的特征相乘得到一个新的特征</li>
<li>如果只用多次函数，适当使用特征缩放将起到很好的效果：</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/Mh9rqHp56124ILU.png" alt="image-20210711102443558"></p>
<ul>
<li>可以有多种合理的选择，比如也可以是平方根。</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/f6WlTvNMjU4im3w.png" alt="image-20210711102612626"></p>
<h1 id="06-正规方程–区别于迭代方法的直接解法"><a href="#06-正规方程–区别于迭代方法的直接解法" class="headerlink" title="06 正规方程–区别于迭代方法的直接解法"></a>06 正规方程–区别于迭代方法的直接解法</h1><ul>
<li>正规方程：对代价函数求偏导数，并将其置0，就可以得到使代价函数最小的值。</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/BCZlKrVpeswyimf.png" alt="image-20210711103640016"></p>
<ul>
<li>方程的形式及例子：</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/JibTXo3pWMePV2A.png" alt="image-20210711104001835"></p>
<ul>
<li><p>使用正规方程就不用对特征进行缩放了。</p>
</li>
<li><p>选择合适的算法（梯度下降还是正规方程）一般特征&lt;10000时选用正规方程直接求解，他们二者的优缺点：</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/n6pISkePvHGDqYU.png" alt="image-20210711104943918"></p>
<h1 id="07-正规方程在矩阵不可逆情况下的解决方法"><a href="#07-正规方程在矩阵不可逆情况下的解决方法" class="headerlink" title="07 正规方程在矩阵不可逆情况下的解决方法"></a>07 正规方程在矩阵不可逆情况下的解决方法</h1><ul>
<li><p>在Octave中pinv（伪逆）与inv（逆）是求逆矩阵的，就算矩阵没有逆，pinv也会求出它的逆。</p>
</li>
<li><p>首先看是否有多余的特征（两个特征线性相关），选择进行删除，直到没有多余的为止；再观察是否特征过多，选择没有影响的特征进行删除。</p>
</li>
</ul>
<p><img src="https://s2.loli.net/2022/04/11/Yc7FAiOmUk63vdz.png" alt="image-20210711110234591"></p>

    </div>

    
</div>
    <div class="footer" id="footer">
    <p>Copyright © 2020 <a class="flink" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>-<a class="flink" target="_blank" rel="noopener" href="https://github.com/ainianxu">Fang</a>.
        <label class="el-switch el-switch-green el-switch-sm" style="vertical-align: sub;">
            <input type="checkbox" name="switch" id="update_style">
            <span class="el-switch-style"></span>
        </label>
<!--         <script type="text/javascript">
        var cnzz_protocol = (("https:" == document.location.protocol) ? "https://" : "http://");
        document.write(unescape("%3Cspan id='cnzz_stat_icon_1278548644'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "v1.cnzz.com/stat.php%3Fid%3D1278548644%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
        </script> -->
    </p>
</div>
<input type="hidden" id="web_style" value="black">
<input type="hidden" id="valine_appid" value="CmCti21ooOOIzFOhEyFkFvR0-gzGzoHsz">
<input type="hidden" id="valine_appKey" value="FqiyUqbg7McKN2eG0MCewupf">

<script src="/libs/jquery.min.js"></script>


<script src="/libs/highlight/highlight.pack.js"></script>

<script src='//cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>

<script src="/js/js.js"></script>

<style type="text/css">
.v * {
    color: #698fca;
}

.v .vlist .vcard .vhead .vsys {
    color: #3a3e4a;
}

.v .vlist .vcard .vh .vmeta .vat {
    color: #638fd5;
}

.v .vlist .vcard .vhead .vnick {
    color: #6ba1ff;
}

.v a {
    color: #8696b1;
}

.v .vlist .vcard .vhead .vnick:hover {
    color: #669bfc;
}
</style>
</body>

</html>