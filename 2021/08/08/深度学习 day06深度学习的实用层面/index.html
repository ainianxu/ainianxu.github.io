<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Fang">
    
    <title>
        
            深度学习 day06 深度学习的实用层面 |
        
        念~旭
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/favicon.ico">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":false},"style":{"primary_color":"#0066CC","avatar":"/images/favicon.ico","favicon":"/images/favicon.ico","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"你舍得放弃么？你愿意放弃么？你能......放弃么？"},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"3.4.4"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                念~旭
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">深度学习 day06 深度学习的实用层面</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/favicon.ico">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Fang</span>
                        
                            <span class="author-label">Lv4</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2021-08-08 22:07:11</span>
        <span class="mobile">2021-08-08 22:07</span>
    </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>3.7k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>12 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h1 id="01-训练-x2F-开发-x2F-测试集"><a href="#01-训练-x2F-开发-x2F-测试集" class="headerlink" title="01 训练 &#x2F; 开发 &#x2F; 测试集"></a>01 训练 &#x2F; 开发 &#x2F; 测试集</h1><ul>
<li>应用型机器学习是一个高度迭代的过程（想法-&gt;代码-&gt;实现），循环该过程的效率是决定项目进展速度的一个关键因素，创建高质量的训练集、验证集、测试集也有助于提高循环效率。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/DSxRVLuKpOgJNyd.png"
                      alt="image-20210806161754138"
                ></p>
<ul>
<li>随着数据量的不断增加（从1000个样本到1000000个样本），那么验证集和测试集占数据总量的比例会趋向于变得更小。如果数据有一百万，那么就可以选择一万条作验证集，一万条作测试集。因为验证集的目的就是验证不同的算法，检验哪种算法最有效，同样的根据最终选择的分类器，测试集的主要目的是正确评估分类器的性能，选择这么多数据就足够了。（训练集98%，验证集1%，测试集1%）</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/vtEC2qVdHk17o5Y.png"
                      alt="image-20210806162107456"
                ></p>
<ul>
<li>总结：现代深度学习的一个趋势：在训练和测试集分布不匹配的情况下进行训练（比如说训练集数据是从网上整下来的，验证集和测试集是用户上传的），针对于这种情况要确保验证集和测试集的数据来自同一分布。最后一点就是没有测试集也没关系（如果不需要无偏估计），如果只有验证集没有测试集，就应该在训练集上训练尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出合适的模型 。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/7fnzWmodxagwCYr.png"
                      alt="image-20210806162137497"
                ></p>
<h1 id="02-偏差-x2F-方差"><a href="#02-偏差-x2F-方差" class="headerlink" title="02 偏差 &#x2F; 方差"></a>02 偏差 &#x2F; 方差</h1><p>关于深度学习的误差问题就是要对偏差、方差的权衡。</p>
<hr>
<ul>
<li>分为欠拟合（高偏差） | 适度拟合 | 过度拟合（高方差）</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/EgIKkZJf4nYHLhO.png"
                      alt="image-20210807102539471"
                ></p>
<ul>
<li>理解偏差和方差的两个关键数据是训练集误差和验证集误差。下面分别是基于人眼误差为0的情况下，高方差 | 高偏差 | 高偏差+高方差 | 低偏差+低方差。（以上分析的前提都是假设基本误差很小，训练集和验证集来自相同分布）如果最优误差（贝叶斯误差）为15%，那么第二组数据就是低偏差+低方差。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/fjcuJr2yKGWPdTM.png"
                      alt="image-20210807102555855"
                ></p>
<ul>
<li>下面用紫色线画出的分类器具有高偏差和高方差，高偏差是因为它几乎是一条线性分类器，并未拟合数据，高方差是因为采用曲线函数或二次函数，灵活性太高以致拟合了这两个错误样本。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/u2ZcwayY7RUOT4P.png"
                      alt="image-20210807102611204"
                ></p>
<ul>
<li>总结：通过分析训练集和验证集验证算法产生的误差来诊断算法是否存在高偏差或者高方差，以此来决定接下来你要做什么</li>
</ul>
<h1 id="03-机器学习基础"><a href="#03-机器学习基础" class="headerlink" title="03 机器学习基础"></a>03 机器学习基础</h1><ul>
<li>首先检查偏差，如果偏差过高，甚至无法拟合训练集，那么就需要选择一个新网络（含有更多的隐层或者隐藏单元）；或者花费更多的时间来训练网络（花费更多的时间训练算法或者尝试更先进的优化算法）；或者从多种神经网络架构中选择一种，通常采用规模更大的网络都会有所帮助。不断地重复这些步骤，直到偏差降低到可接受范围。</li>
<li>一旦偏差降低到可接受的范围，检查下方差有没有问题（评估方差要查看验证集性能），如果方差过高，需要采用更多的数据也许会有帮助；或者通过正则化来减少过拟合；找到更合适的网络架构。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/ZOU1cMAfbrJiduz.png"
                      alt="image-20210807154603673"
                ></p>
<h1 id="04-正则化"><a href="#04-正则化" class="headerlink" title="04 正则化"></a>04 正则化</h1><ul>
<li>逻辑回归函数中的正则化：L2正则化是最常见的，还有L1正则化，如果使用L1正则化，w最终会是稀疏的（w向量中有很多0）。在python中我们使用lambd来代替lambda正则化参数。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/iTkZuKNzQcO5GfL.png"
                      alt="image-20210808091957852"
                ></p>
<ul>
<li>神经网络实现L2正则化：字母L代表神经网络的层数</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/8UyILZGqO6CvQwJ.png"
                      alt="image-20210808092010146"
                ></p>
<h1 id="05-为什么正则化可以减少过拟合？"><a href="#05-为什么正则化可以减少过拟合？" class="headerlink" title="05 为什么正则化可以减少过拟合？"></a>05 为什么正则化可以减少过拟合？</h1><ul>
<li>直观的理解就是lambda增加到足够大，w会接近于0，在这个过程中她会出现拟合正合适的情况，逐渐的会变成高偏差。直觉上我们会认为大量的隐藏单元被完全消除了，实际上依然存在，只是他们的影响变得更小了。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/zJQFSw4CqxYGt8B.png"
                      alt="image-20210808095419078"
                ></p>
<ul>
<li>假设我们用的是tanh()函数，z在很小的范围内，图像是呈线性的，如果z变得更大或者更小，图像将呈非线性。如果神经网络每层都是线性的，那么整个网络就是线性网络，最终我们只能计算线性函数，因此它不适合非常复杂的决策。总结：如果正则化参数变得很大，参数w很小，z也会相对变小，整个神经网络会计算离线性函数近的值，这个线性函数非常简单不会发生过拟合。</li>
<li>还有一点值得注意：为了调试梯度下降，一定要使用新定义的J函数，它包含了第二个正则化项，否则函数J可能不会在所有调幅范围内都单调递减。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/JKZaoeAkL5mnhfs.png"
                      alt="image-20210808095442984"
                ></p>
<h1 id="06-Dropout正则化"><a href="#06-Dropout正则化" class="headerlink" title="06 Dropout正则化"></a>06 Dropout正则化</h1><ul>
<li>Dropout（随机失活）工作流程：假设左图存在过拟合，dropout会遍历网络的每一层，并设置消除神经网络中节点的概率（每一个节点都以抛硬币的方式设置概率即每个节点得以保留和消除的概率都是0.5），我们在消除一些节点的同时也会删除该节点进出的连线，最后得到一个节点更少、规模更小的网络。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/Jrx6TVuDgXnk4S3.png"
                      alt="image-20210808121838170"
                ></p>
<ul>
<li>如何实施dropout：inverted dropout（反向随机失活）-&gt;首先定义一个向量d，d^ 3表示一个三层的dropout向量；然后看它是否小于某个数（keep-prob），keep-prob表示保留某个隐藏单元的概率，它的作用就是生成随机矩阵，这个d3就是个布尔类型的数组，值为1或者0；接下来是从第三层中获取激活函数（a3），a3等于上面的a3与d3元素相乘，它的作用就是过滤d3中所有等于0的元素，而各个元素等于0的概率只有20%；最后向外扩展a3，通过除以keep-prob来确保a3的期望值不变，假设预期a^ [3]预期减少20%，为了不影响z^ [4]的期望值，就需要用w^ [4]*a^ [3]除以0.8，它将会修正我们所需的那20%。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/CXtxvLIMOARTkQb.png"
                      alt="image-20210808121710187"
                ></p>
<ul>
<li>我们在测试阶段不使用dropout，因为在测试阶段我们不期望输出的结果是随机的。测试阶段不同于训练阶段，即使在测试阶段不执行dropout来调整数值范围，激活函数的预期结果也不会发生变化。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/2Bnb1patl4kzhcM.png"
                      alt="image-20210808121649464"
                ></p>
<h1 id="07-理解Dropout"><a href="#07-理解Dropout" class="headerlink" title="07 理解Dropout"></a>07 理解Dropout</h1><ul>
<li>左图中用紫色圈起来的单元，它不能依靠任何特征，因为特征（该单元的输入）都有可能被随机清除。通过为单元的四个输入增加一点权重，Dropout将产生收缩权重的平方范数的效果。实施Dropout的结果是会压缩权重并完成一些预防过拟合的外层正则化。Dropout的功能类似于L2正则化，与L2正则化不同的是：被应用的方式不同，Dropout也会有所不同，甚至更适用于不同的输入范围。为了预防矩阵的过拟合，对权重最大的矩阵（例如右图的w^ [2]&#x3D;7×7）的那一层，keep-prob值应该相对较低，而且每一层的keep-prob值都有可能不同，如果某一层keep-prob为1，那么就不对这层使用Dropout。</li>
<li>在计算机视觉领域由于通常没有足够的数据，所以一直存在过拟合，所以Dropout在这是很热门的。Dropout的一个大缺点就是代价函数J不被明确定义，为了绘制学习曲线确保每次迭代都是呈下降趋势，通常会关闭Dropout函数，然后运行代码确保J函数单调递减，最后在打开Dropout。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/jFPkWd2q4YLTwEH.png"
                      alt="image-20210808153353102"
                ></p>
<ul>
<li>总结：如果你担心某些层比其他层更加容易过拟合，那么就将某些层的keep-prob值设置相对较低，缺点是为了使用交叉验证，需要搜索更多的超级参数。另一种方案是一些层用Dropout，一些层不用，应用的层只含有一个超级参数就是keep-prob</li>
</ul>
<h1 id="08-其他正则化方法"><a href="#08-其他正则化方法" class="headerlink" title="08 其他正则化方法"></a>08 其他正则化方法</h1><ul>
<li>数据扩增可以作为正则化方法使用：对图片进行水平翻转，扩大裁剪，对数字进行扭曲等操作。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/5elauZS8y9sb7fT.png"
                      alt="image-20210808162621924"
                ></p>
<ul>
<li>early stopping代表提前停止训练神经网络。我们在绘制验证集误差时会发现。验证集误差通常会呈下降趋势，然后在某一节点开始上升，因此在迭代的过程中选择中间w的值（就是那个拐点），early stopping的优点是只运行一次坡度下降，就可以找到w的较小值、中间值和较大值，而无需尝试L2正则化超级参数lambda的很多值。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/kBOTQGpcFNbvr6g.png"
                      alt="image-20210808162639281"
                ></p>
<h1 id="09-正则化输入"><a href="#09-正则化输入" class="headerlink" title="09 正则化输入"></a>09 正则化输入</h1><p>训练神经网络，其中一个加速训练的方法就是归一化输入：归一化的目的就是让特征值保持在相似的范围内</p>
<hr>
<ul>
<li>归一化输入有两个步骤：第一步是零均值化（左下公式）变为第二个图，第二步是归一化方差（右下公式）变为第三个图，第二个图的x_1的方差明显比x_2的方差要大-&gt;第三个图x_1的方差和x_2的方差一样大。我们希望不论是训练数据还是测试数据都是通过相同的u和sita^ 2定义的相同数据转换，其中u和sita^ 2是由训练集数据计算得出的。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/RLjO2othmpvKud7.png"
                      alt="image-20210808181124568"
                ></p>
<ul>
<li>如果使用非归一化特征（特征值不在一个相似的范围内），会得到一个非常细长狭窄的代价函数（左图）并且需要的学习率也要小，如果归一化特征后（特征值处于相似范围内），代价函数看起来更加的对称（右图）而且设置的学习率可以较大。如果特征的范围都很相似，那么将对优化算法很有利（下方x的取值），否则不利（上方x的取值）。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/ZJQnVwRkijFsEYy.png"
                      alt="image-20210808181137915"
                ></p>
<ul>
<li>总结：如果特征值不在一个相似的范围内，那么归一化将会显得格外重要，如果特征值处于相似范围内，那么归一化就不是很重要了。</li>
</ul>
<h1 id="10-梯度消失与梯度爆炸"><a href="#10-梯度消失与梯度爆炸" class="headerlink" title="10 梯度消失与梯度爆炸"></a>10 梯度消失与梯度爆炸</h1><p>当你训练神经网络时，导数或者坡度有时会变得非常大或者非常小，甚至以指数方式变小，这加大了训练难度。我们应更加明智的选择随机初始化权重，从而避免这个问题。</p>
<hr>
<ul>
<li>该例子中g（z）&#x3D;z，b^ [l]&#x3D;0。当权重w只比1略大一点或者说比单位矩阵大一点，深度神经网络的激活函数将爆炸式增长，如果w比1略小一点，在神经网络中激活函数将以指数级递减。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/h6X38FCtTJ4VUzK.png"
                      alt="image-20210808203127077"
                ></p>
<h1 id="11-神经网络的权重初始化"><a href="#11-神经网络的权重初始化" class="headerlink" title="11 神经网络的权重初始化"></a>11 神经网络的权重初始化</h1><ul>
<li>神经单元权重初始化：为了防止z值过大或过小，当n越大你希望w_i越小，最合理的方法就是设置w_i&#x3D;1&#x2F;n，其中这里的n代表神经元的输入特征数量，实际上就是设置某层权重矩阵w。如果用的是Relu激活函数而不是1&#x2F;n，方差设置为2&#x2F;n更好。这里用n^ [l-1]是因为一般情况下l层的每个神经元都有n^ [l-1]个输入。</li>
<li>其他变体函数的公式：Tanh激活函数为右边第一个式子；Relu激活函数是左边画框的；有时也用右边第二个</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/AgKEYzaNMTPk3LB.png"
                      alt="image-20210808205829700"
                ></p>
<h1 id="12-梯度的数值逼近"><a href="#12-梯度的数值逼近" class="headerlink" title="12 梯度的数值逼近"></a>12 梯度的数值逼近</h1><p>梯度检验的作用是确保backprop正确实施</p>
<hr>
<ul>
<li>单边计算：</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/alpyERwhz4Z18LG.png"
                      alt="image-20210808210925721"
                ></p>
<ul>
<li>使用双边误差的方法更逼近导数，双边计算出来是3.0001，而单边计算出来是3.0301，可以看出双边更加接近3。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/M2UcAmtYkE8ZOKR.png"
                      alt="image-20210808210940411"
                ></p>
<h1 id="13-梯度检验"><a href="#13-梯度检验" class="headerlink" title="13 梯度检验"></a>13 梯度检验</h1><ul>
<li>首先做些处理：</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/QeZG3sbtj7Toyi5.png"
                      alt="image-20210808213755158"
                ></p>
<ul>
<li>为了实施梯度检验，要做的就是循环执行。先将J展开，然后进行循环，我们要验证的就是dsita_approx与dsita这两个向量是否真的接近，一般做下列运算：计算这两个向量的距离（dsita_approx-dsita的欧几里得范数，注意没有平方，它是误差平方之和，然后求平方根得到欧式距离），然后用向量长度做归一化，结果为||dsita_approx-dsita||&#x2F;||dsita_approx||+||dsita||。分母只是用来预防这些向量太小或太大，分母使这个方程式变成比率。如果计算方程式得到的值为10的-7次方甚至更小，这就很好；如果在10的-5次方就要小心了，检查这个向量所有的项确保没有一项误差过大；如果是10的-3那么就要担心是否存在bug了，看看是否有个具体的i值使得dsita_approx与dsita大不相同。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/nvMwEskfLJ9lxDm.png"
                      alt="image-20210808213819586"
                ></p>
<h1 id="14-关于梯度检验实现的注记"><a href="#14-关于梯度检验实现的注记" class="headerlink" title="14 关于梯度检验实现的注记"></a>14 关于梯度检验实现的注记</h1><p>如何在神经网络实现梯度检验的适用技巧和注意事项</p>
<hr>
<ul>
<li>不要在训练中适用梯度检验，它只用于调试</li>
<li>如果算法的梯度检验失败，要检查所有项，并试图找出bug：如果两个向量的值相差很大 ，我们要查找不同的i值，看看是哪个导致的。</li>
<li>在实施梯度检验时，如果使用正则化，请注意正则项</li>
<li>梯度检验不能与dropout同时使用：因为每次迭代过程中dropout会随机消除隐层单元的不同子集，难以计算dropout在梯度下降上的代价函数J</li>
<li>在随机初始化过程中，当w和b接近0时，梯度下降&#x2F;backprop的实施是正确的；但在运行梯度下降时w和b变得更大，也就越来越不准确。这时要做的就是在随机初始化过程中运行梯度检验，然后训练网络，w和b会有一段时间远离0，如果随机初始化值比较小，反复训练网络之后再重新运行梯度检验。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/OG8TsrDMlcpiyKz.png"
                      alt="image-20210808214519694"
                ></p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：深度学习 day06 深度学习的实用层面</li>
        <li>Post author：Fang</li>
        <li>Create time：2021-08-08 22:07:11</li>
        <li>
            Post link：https://ainianxu.github.io/2021/08/08/深度学习 day06深度学习的实用层面/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>&nbsp;
                    </li>
                
            </ul>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2021/08/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day07%2008%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">深度学习 day07 08 优化算法</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2021/08/06/1%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%EF%BC%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">1编程作业：线性回归</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'loa9BVbgmyFLwBMHhg1Cycx1-gzGzoHsz',
                    appKey: '47pIz6ewIXRi5251WyfUpQOB',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情吐槽吧~',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Fang';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2021</span>
              -
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Fang</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.4</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#01-%E8%AE%AD%E7%BB%83-x2F-%E5%BC%80%E5%8F%91-x2F-%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="nav-number">1.</span> <span class="nav-text">01 训练 &#x2F; 开发 &#x2F; 测试集</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#02-%E5%81%8F%E5%B7%AE-x2F-%E6%96%B9%E5%B7%AE"><span class="nav-number">2.</span> <span class="nav-text">02 偏差 &#x2F; 方差</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80"><span class="nav-number">3.</span> <span class="nav-text">03 机器学习基础</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#04-%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">4.</span> <span class="nav-text">04 正则化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#05-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AD%A3%E5%88%99%E5%8C%96%E5%8F%AF%E4%BB%A5%E5%87%8F%E5%B0%91%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%9F"><span class="nav-number">5.</span> <span class="nav-text">05 为什么正则化可以减少过拟合？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#06-Dropout%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">6.</span> <span class="nav-text">06 Dropout正则化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#07-%E7%90%86%E8%A7%A3Dropout"><span class="nav-number">7.</span> <span class="nav-text">07 理解Dropout</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#08-%E5%85%B6%E4%BB%96%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95"><span class="nav-number">8.</span> <span class="nav-text">08 其他正则化方法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#09-%E6%AD%A3%E5%88%99%E5%8C%96%E8%BE%93%E5%85%A5"><span class="nav-number">9.</span> <span class="nav-text">09 正则化输入</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#10-%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E4%B8%8E%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8"><span class="nav-number">10.</span> <span class="nav-text">10 梯度消失与梯度爆炸</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#11-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-number">11.</span> <span class="nav-text">11 神经网络的权重初始化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#12-%E6%A2%AF%E5%BA%A6%E7%9A%84%E6%95%B0%E5%80%BC%E9%80%BC%E8%BF%91"><span class="nav-number">12.</span> <span class="nav-text">12 梯度的数值逼近</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#13-%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C"><span class="nav-number">13.</span> <span class="nav-text">13 梯度检验</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14-%E5%85%B3%E4%BA%8E%E6%A2%AF%E5%BA%A6%E6%A3%80%E9%AA%8C%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%B3%A8%E8%AE%B0"><span class="nav-number">14.</span> <span class="nav-text">14 关于梯度检验实现的注记</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/code-copy.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/lazyload.js"></script>


<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
