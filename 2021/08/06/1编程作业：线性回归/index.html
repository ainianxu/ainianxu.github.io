<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Fang">
    
    <title>
        
            1编程作业：线性回归 |
        
        念~旭
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/favicon.ico">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":false},"style":{"primary_color":"#0066CC","avatar":"/images/favicon.ico","favicon":"/images/favicon.ico","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"进来就别走了！"},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"3.4.4"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                念~旭
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/links"
                            >
                                LINKS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/links">LINKS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">1编程作业：线性回归</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/favicon.ico">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Fang</span>
                        
                            <span class="author-label">Lv7</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2021-08-06 11:59:57</span>
        <span class="mobile">2021-08-06 11:59</span>
    </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>2.4k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>11 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p>原任务是在Octave&#x2F;MATLAB实现，本次编程作业全部以python完成。</p>
<hr>
<h1 id="01-简单的练习"><a href="#01-简单的练习" class="headerlink" title="01 简单的练习"></a>01 简单的练习</h1><p>总结下题目：输出一个5*5的单位矩阵</p>
<hr>
<ul>
<li>在此我们用np.eye(<em>N</em>,<em>M&#x3D;None</em>, <em>k&#x3D;0</em>, <em>dtype&#x3D;&lt;type ‘float’&gt;</em>)，首先N代表的是输出方阵的维度，第二个参数不用设置默认M&#x3D;N，主要看第三个参数，默认是对角线为1，其余全为0；如果k为正数，则对角线往上第k个全为1，其余全为0；如果k为负数，则对角线往下第k个全为1，其余全为0。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.eye(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(A)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[[1. 0. 0. 0. 0.]</span></span><br><span class="line"><span class="string"> [0. 1. 0. 0. 0.]</span></span><br><span class="line"><span class="string"> [0. 0. 1. 0. 0.]</span></span><br><span class="line"><span class="string"> [0. 0. 0. 1. 0.]</span></span><br><span class="line"><span class="string"> [0. 0. 0. 0. 1.]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h1 id="02-单变量线性回归"><a href="#02-单变量线性回归" class="headerlink" title="02 单变量线性回归"></a>02 单变量线性回归</h1><p>根据这座城市的人口数量及该城市小吃店的利润，来预测开小吃店的利润。</p>
<hr>
<h2 id="2-1-绘制数据"><a href="#2-1-绘制数据" class="headerlink" title="2.1 绘制数据"></a>2.1 绘制数据</h2><ul>
<li>读入数据：在此我们引入pandas库，该库可以帮助我们从诸如 csv 类型的文件导入数据，并且可以用它快速的对数据进行转换和过滤的操作。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">path = <span class="string">&quot;machine-learning-ex1\machine-learning-ex1\ex1\ex1data1.txt&quot;</span></span><br><span class="line">data = pd.read_csv(path,header=<span class="literal">None</span>,names=[<span class="string">&#x27;Population&#x27;</span>,<span class="string">&#x27;Profit&#x27;</span>])<span class="comment">#header决定要不要原始的表头，name给出自定义的表头。</span></span><br><span class="line"><span class="built_in">print</span>(data.head())<span class="comment">#从头查询数据</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   population   profit</span></span><br><span class="line"><span class="string">0      6.1101  17.5920</span></span><br><span class="line"><span class="string">1      5.5277   9.1302</span></span><br><span class="line"><span class="string">2      8.5186  13.6620</span></span><br><span class="line"><span class="string">3      7.0032  11.8540</span></span><br><span class="line"><span class="string">4      5.8598   6.8233</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>数据可视化：在此我们引入matplotlib.pyplot库，使用plot函数画图。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">data.plot(kind=<span class="string">&#x27;scatter&#x27;</span>, x=<span class="string">&#x27;Population&#x27;</span>, y=<span class="string">&#x27;Profit&#x27;</span>, figsize=(<span class="number">12</span>,<span class="number">8</span>))<span class="comment">#生成图形，kind‘指定所画图的类型，figsize 指定图片大小。</span></span><br><span class="line">plt.show()<span class="comment">#显示图形</span></span><br></pre></td></tr></table></figure>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/TExH9s13tMWIioB.png"
                      alt="image-20210805080023050"
                ></p>
<h2 id="2-2-梯度下降"><a href="#2-2-梯度下降" class="headerlink" title="2.2 梯度下降"></a>2.2 梯度下降</h2><p>这部分需要使用梯度下降将线性回归参数 θ 拟合到数据集上。</p>
<h3 id="2-21-公式"><a href="#2-21-公式" class="headerlink" title="2.21 公式"></a>2.21 公式</h3><ul>
<li>代价函数</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/3lprR9vik6M2dOG.png"
                      alt="image-20210805112600247"
                ></p>
<ul>
<li>假设函数</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/xYra86AfkZ14HcR.png"
                      alt="image-20210805112723564"
                ></p>
<ul>
<li>参数更新</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/vSkcFgEYuK1do4I.png"
                      alt="image-20210805115411195"
                ></p>
<ul>
<li>随着梯度下降不断地更新参数，参数也就越接近使代价函数最小的最优值</li>
</ul>
<h3 id="2-22-实现"><a href="#2-22-实现" class="headerlink" title="2.22 实现"></a>2.22 实现</h3><ul>
<li>我们要为我们之前读取的数据添加一列x，用来更新θ_0。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data.insert(<span class="number">0</span>, <span class="string">&#x27;Ones&#x27;</span>, <span class="number">1</span>) <span class="comment">#相当于在第0列，添加一个表头名为Ones，并且该列均为1</span></span><br><span class="line"><span class="built_in">print</span>(data.head())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   Ones  Population   Profit</span></span><br><span class="line"><span class="string">0     1      6.1101  17.5920</span></span><br><span class="line"><span class="string">1     1      5.5277   9.1302</span></span><br><span class="line"><span class="string">2     1      8.5186  13.6620</span></span><br><span class="line"><span class="string">3     1      7.0032  11.8540</span></span><br><span class="line"><span class="string">4     1      5.8598   6.8233</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>分割X和y。使用pandas的iloc来进行选择训练集X和目标y</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分割X和y</span></span><br><span class="line">lists = data.shape[<span class="number">1</span>]<span class="comment">#输出列数</span></span><br><span class="line">X = data.iloc[:,:-<span class="number">1</span>]<span class="comment">#X是第一列到最后一列，但不包括最后一列，因为 python的范围/切片不包括终点</span></span><br><span class="line">y = data.iloc[:,lists-<span class="number">1</span>:lists]<span class="comment">#最后一列</span></span><br><span class="line"><span class="comment">#y = data.iloc[:,-1]#也是最后一列</span></span><br><span class="line"><span class="built_in">print</span>(X.head())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   Ones  Population</span></span><br><span class="line"><span class="string">0     1      6.1101</span></span><br><span class="line"><span class="string">1     1      5.5277</span></span><br><span class="line"><span class="string">2     1      8.5186</span></span><br><span class="line"><span class="string">3     1      7.0032</span></span><br><span class="line"><span class="string">4     1      5.8598</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(y.head())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Profit</span></span><br><span class="line"><span class="string">0  17.5920</span></span><br><span class="line"><span class="string">1   9.1302</span></span><br><span class="line"><span class="string">2  13.6620</span></span><br><span class="line"><span class="string">3  11.8540</span></span><br><span class="line"><span class="string">4   6.8233</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>我们还要将θ初始化为0，并将θ、X、y全部转化为矩阵</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = np.matrix(X.values)</span><br><span class="line">y = np.matrix(y.values)</span><br><span class="line">theta = np.matrix(np.array([<span class="number">0</span>,<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(X.shape)<span class="comment">#(97, 2)</span></span><br><span class="line"><span class="built_in">print</span>(y.shape)<span class="comment">#(97, 1)</span></span><br><span class="line"><span class="built_in">print</span>(theta.shape)<span class="comment">#(1, 2)</span></span><br></pre></td></tr></table></figure>

<h3 id="2-23-计算J-θ"><a href="#2-23-计算J-θ" class="headerlink" title="2.23 计算J(θ)"></a>2.23 计算J(θ)</h3><ul>
<li>计算代价函数来检测代价函数的收敛性。根据上面的公式我们写出代价函数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">computeCost</span>(<span class="params">X, y, theta</span>):</span><br><span class="line">    inner = np.power((X * theta.T)-y,<span class="number">2</span>)<span class="comment">#数组元素求n次方</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(inner) / (<span class="number">2</span> * <span class="built_in">len</span>(X))</span><br><span class="line"><span class="built_in">print</span>(computeCost(X, y, theta)) <span class="comment">#32.072733877455676</span></span><br></pre></td></tr></table></figure>

<h3 id="2-24-梯度下降"><a href="#2-24-梯度下降" class="headerlink" title="2.24 梯度下降"></a>2.24 梯度下降</h3><p>代价函数J(θ)的参数是由向量θ表示，假设你已经实现了梯度下降，如果计算正确，J(θ)的值不应该增加，而应该减小然后在算法结束时收敛到一个稳定值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradientDescent</span>(<span class="params">X, y, theta, alpha, iters</span>):</span><br><span class="line">    temp = np.matrix(np.zeros(theta.shape))<span class="comment">#创建0矩阵[[0. 0.]]</span></span><br><span class="line">    parameters = <span class="built_in">int</span>(theta.ravel().shape[<span class="number">1</span>]) <span class="comment">#ravel()将多维数组转换为一维数组,.shape[1]是看列数为多少-2</span></span><br><span class="line">    cost = np.zeros(iters)<span class="comment">#初始化代价函数数组</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iters):</span><br><span class="line">        error = (X * theta.T) - y</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(parameters):</span><br><span class="line">            term = np.multiply(error, X[:, j])</span><br><span class="line">            temp[<span class="number">0</span>, j] = theta[<span class="number">0</span>, j] - ((alpha / <span class="built_in">len</span>(X)) * np.<span class="built_in">sum</span>(term))<span class="comment">#更新参数</span></span><br><span class="line"></span><br><span class="line">        theta = temp</span><br><span class="line">        cost[i] = computeCost(X, y, theta)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta, cost</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">iters = <span class="number">1500</span></span><br><span class="line">g, cost = gradientDescent(X, y, theta, alpha, iters)</span><br><span class="line"><span class="built_in">print</span>(g)<span class="comment">#[[-3.63029144  1.16636235]]</span></span><br><span class="line">predict1 = [<span class="number">1</span>,<span class="number">3.5</span>]*g.T</span><br><span class="line"><span class="built_in">print</span>(predict1)<span class="comment">#[[0.45197679]]</span></span><br><span class="line">predict2 = [<span class="number">1</span>,<span class="number">7</span>]*g.T</span><br><span class="line"><span class="built_in">print</span>(predict2)<span class="comment">#[[4.53424501]]</span></span><br></pre></td></tr></table></figure>

<h3 id="2-3-调试"><a href="#2-3-调试" class="headerlink" title="2.3 调试"></a>2.3 调试</h3><ul>
<li>python可视化：原始数据以及拟合的直线</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在指定的间隔内返回均匀间隔的数字：从data.Population的最小值到最大的范围内，等间距的返回100个样本</span></span><br><span class="line">x = np.linspace(data.Population.<span class="built_in">min</span>(), data.Population.<span class="built_in">max</span>(), <span class="number">100</span>)</span><br><span class="line">f = g[<span class="number">0</span>, <span class="number">0</span>] + (g[<span class="number">0</span>, <span class="number">1</span>] * x)<span class="comment">#参数为最优值的直线</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">8</span>))<span class="comment">#创建一个12*8的图即多维窗口</span></span><br><span class="line">ax.plot(x, f, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;Prediction&#x27;</span>) <span class="comment">#定义x, y, 颜色，图例上显示的东西</span></span><br><span class="line">ax.scatter(data.Population, data.Profit, label=<span class="string">&#x27;Traning Data&#x27;</span>)</span><br><span class="line">ax.legend(loc=<span class="number">2</span>)<span class="comment">#指定图例的位置</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Population&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Profit&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Predicted Profit vs. Population Size&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/v5wimh6HzINd8lE.png"
                      alt="image-20210805233002972"
                ></p>
<h1 id="03-多变量线性回归"><a href="#03-多变量线性回归" class="headerlink" title="03 多变量线性回归"></a>03 多变量线性回归</h1><p>根据ex1data2.txt里的数据建立模型，预测房屋的价格，其中第一列是房屋大小，第二列是卧室数量，第三列是房屋售价</p>
<hr>
<ul>
<li>第一步依旧是读入数据：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">path = <span class="string">&#x27;machine-learning-ex1\machine-learning-ex1\ex1\ex1data2.txt&#x27;</span></span><br><span class="line">data2 = pd.read_csv(path,header = <span class="literal">None</span>,names=[<span class="string">&#x27;Size&#x27;</span>, <span class="string">&#x27;Bedrooms&#x27;</span>, <span class="string">&#x27;Price&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(data2.head())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"> Size  Bedrooms   Price</span></span><br><span class="line"><span class="string">0  2104         3  399900</span></span><br><span class="line"><span class="string">1  1600         3  329900</span></span><br><span class="line"><span class="string">2  2400         3  369000</span></span><br><span class="line"><span class="string">3  1416         2  232000</span></span><br><span class="line"><span class="string">4  3000         4  539900</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="3-1-特征归一化"><a href="#3-1-特征归一化" class="headerlink" title="3.1 特征归一化"></a>3.1 特征归一化</h2><p>特征缩放的目的只是为了运行更快。使特征值比较接近，使图像变得比较圆。以至于梯度下降的速度更快，收敛所需要的迭代次数更少，收敛更快。</p>
<hr>
<ul>
<li>mean()函数功能：求取均值，std()函数是用来求标准差的（std &#x3D; sqrt(mean(abs(x - x.mean())**2))）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data2 = (data2 - data2.mean()) / data2.std()</span><br><span class="line"><span class="built_in">print</span>(data2.head())</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">      Size  Bedrooms     Price</span></span><br><span class="line"><span class="string">0  0.130010 -0.223675  0.475747</span></span><br><span class="line"><span class="string">1 -0.504190 -0.223675 -0.084074</span></span><br><span class="line"><span class="string">2  0.502476 -0.223675  0.228626</span></span><br><span class="line"><span class="string">3 -0.735723 -1.537767 -0.867025</span></span><br><span class="line"><span class="string">4  1.257476  1.090417  1.595389</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="3-2-梯度下降"><a href="#3-2-梯度下降" class="headerlink" title="3.2 梯度下降"></a>3.2 梯度下降</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">data2.insert(<span class="number">0</span>, <span class="string">&#x27;Ones&#x27;</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">cols = data2.shape[<span class="number">1</span>]</span><br><span class="line">X2 = data2.iloc[:,<span class="number">0</span>:cols-<span class="number">1</span>]</span><br><span class="line">y2 = data2.iloc[:,cols-<span class="number">1</span>:cols]</span><br><span class="line"></span><br><span class="line">X2 = np.matrix(X2.values)</span><br><span class="line">y2 = np.matrix(y2.values)</span><br><span class="line">theta2 = np.matrix(np.array([<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">g2, cost2 = gradientDescent(X2, y2, theta2, alpha, iters)</span><br><span class="line"><span class="built_in">print</span>(g2)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[-1.10898288e-16  8.84042349e-01 -5.24551809e-02]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="3-3-正规方程"><a href="#3-3-正规方程" class="headerlink" title="3.3 正规方程"></a>3.3 正规方程</h2><p>训练集特征矩阵为 X（包含了x_0&#x3D;1）训练集结果为向量 y，则利用正规方程解出向量:其中np.linalg.inv()：矩阵求逆。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://s2.loli.net/2022/04/13/cAfMsjPdLED5gJB.png"
                      alt="image-20210806114131781"
                ></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">normalEqn</span>(<span class="params">X, y</span>):</span><br><span class="line">    theta = ((np.linalg.inv(X.T.dot(X))).dot(X.T)).dot(y)</span><br><span class="line">    <span class="comment"># theta = np.linalg.inv(X.T@X)@X.T@y</span></span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line">theta2=normalEqn(X2, y2)</span><br><span class="line"><span class="built_in">print</span>(theta2)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[-7.11223170e-17]</span></span><br><span class="line"><span class="string"> [ 8.84765988e-01]</span></span><br><span class="line"><span class="string"> [-5.31788197e-02]]</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h1 id="04-代码总结"><a href="#04-代码总结" class="headerlink" title="04 代码总结"></a>04 代码总结</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">path = <span class="string">&quot;machine-learning-ex1\machine-learning-ex1\ex1\ex1data1.txt&quot;</span></span><br><span class="line">data = pd.read_csv(path,header=<span class="literal">None</span>,names=[<span class="string">&#x27;Population&#x27;</span>,<span class="string">&#x27;Profit&#x27;</span>])<span class="comment">#header决定要不要原始的表头，name给出自定义的表头。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#data.plot(kind=&#x27;scatter&#x27;, x=&#x27;Population&#x27;, y=&#x27;Profit&#x27;, figsize=(12,8))#生成图形，kind‘指定所画图的类型，figsize 指定图片大小。</span></span><br><span class="line"><span class="comment"># plt.show()#显示图形</span></span><br><span class="line"><span class="comment">#==============================================================================</span></span><br><span class="line">data.insert(<span class="number">0</span>, <span class="string">&#x27;Ones&#x27;</span>, <span class="number">1</span>) <span class="comment">#相当于在第0列，添加一个表头名为Ones，并且该列均为1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分割X和y</span></span><br><span class="line">lists = data.shape[<span class="number">1</span>]<span class="comment">#输出列数</span></span><br><span class="line">X = data.iloc[:,:-<span class="number">1</span>]<span class="comment">#X是第一列到最后一列，但不包括最后一列，因为 python的范围/切片不包括终点</span></span><br><span class="line">y = data.iloc[:,lists-<span class="number">1</span>:lists]<span class="comment">#最后一列</span></span><br><span class="line"><span class="comment">#y = data.iloc[:,-1]#也是最后一列</span></span><br><span class="line"></span><br><span class="line">X = np.matrix(X.values)</span><br><span class="line">y = np.matrix(y.values)</span><br><span class="line">theta = np.matrix(np.array([<span class="number">0</span>,<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">computeCost</span>(<span class="params">X, y, theta</span>):</span><br><span class="line">    inner = np.power((X * theta.T)-y,<span class="number">2</span>)<span class="comment">#数组元素求n次方</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(inner) / (<span class="number">2</span> * <span class="built_in">len</span>(X))</span><br><span class="line"><span class="comment"># print(computeCost(X, y, theta)) #32.072733877455676</span></span><br><span class="line"><span class="comment">#梯度下降算法如下：</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradientDescent</span>(<span class="params">X, y, theta, alpha, iters</span>):</span><br><span class="line">    temp = np.matrix(np.zeros(theta.shape))<span class="comment">#创建0矩阵[[0. 0.]]</span></span><br><span class="line">    parameters = <span class="built_in">int</span>(theta.ravel().shape[<span class="number">1</span>]) <span class="comment">#ravel()将多维数组转换为一维数组,.shape[1]是看列数为多少</span></span><br><span class="line">    cost = np.zeros(iters)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iters):</span><br><span class="line">        error = (X * theta.T) - y</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(parameters):</span><br><span class="line">            term = np.multiply(error, X[:, j])</span><br><span class="line">            temp[<span class="number">0</span>, j] = theta[<span class="number">0</span>, j] - ((alpha / <span class="built_in">len</span>(X)) * np.<span class="built_in">sum</span>(term))</span><br><span class="line"></span><br><span class="line">        theta = temp</span><br><span class="line">        cost[i] = computeCost(X, y, theta)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> theta, cost</span><br><span class="line"></span><br><span class="line">alpha = <span class="number">0.01</span></span><br><span class="line">iters = <span class="number">1500</span></span><br><span class="line">g, cost = gradientDescent(X, y, theta, alpha, iters)</span><br><span class="line"><span class="comment">#print(g)#[[-3.63029144  1.16636235]]</span></span><br><span class="line">predict1 = [<span class="number">1</span>,<span class="number">3.5</span>]*g.T</span><br><span class="line"><span class="comment">#print(predict1)#[[0.45197679]]</span></span><br><span class="line">predict2 = [<span class="number">1</span>,<span class="number">7</span>]*g.T</span><br><span class="line"><span class="comment">#print(predict2)#[[4.53424501]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在指定的间隔内返回均匀间隔的数字：从data.Population的最小值到最大的范围内，等间距的返回100个样本</span></span><br><span class="line">x = np.linspace(data.Population.<span class="built_in">min</span>(), data.Population.<span class="built_in">max</span>(), <span class="number">100</span>)</span><br><span class="line">f = g[<span class="number">0</span>, <span class="number">0</span>] + (g[<span class="number">0</span>, <span class="number">1</span>] * x)<span class="comment">#参数为最优值的直线</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>,<span class="number">8</span>))<span class="comment">#创建一个12*8的图即多维窗口</span></span><br><span class="line">ax.plot(x, f, <span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;Prediction&#x27;</span>) <span class="comment">#定义x, y, 颜色，图例上显示的东西</span></span><br><span class="line">ax.scatter(data.Population, data.Profit, label=<span class="string">&#x27;Traning Data&#x27;</span>)</span><br><span class="line">ax.legend(loc=<span class="number">2</span>)<span class="comment">#指定图例的位置</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Population&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Profit&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Predicted Profit vs. Population Size&#x27;</span>)</span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line"><span class="comment">#===========================================================================</span></span><br><span class="line">path = <span class="string">&#x27;machine-learning-ex1\machine-learning-ex1\ex1\ex1data2.txt&#x27;</span></span><br><span class="line">data2 = pd.read_csv(path,header = <span class="literal">None</span>,names=[<span class="string">&#x27;Size&#x27;</span>, <span class="string">&#x27;Bedrooms&#x27;</span>, <span class="string">&#x27;Price&#x27;</span>])</span><br><span class="line">data2 = (data2 - data2.mean()) / data2.std()</span><br><span class="line"></span><br><span class="line">data2.insert(<span class="number">0</span>, <span class="string">&#x27;Ones&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">cols = data2.shape[<span class="number">1</span>]</span><br><span class="line">X2 = data2.iloc[:,<span class="number">0</span>:cols-<span class="number">1</span>]</span><br><span class="line">y2 = data2.iloc[:,cols-<span class="number">1</span>:cols]</span><br><span class="line"></span><br><span class="line">X2 = np.matrix(X2.values)</span><br><span class="line">y2 = np.matrix(y2.values)</span><br><span class="line">theta2 = np.matrix(np.array([<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">g2, cost2 = gradientDescent(X2, y2, theta2, alpha, iters)</span><br><span class="line"><span class="built_in">print</span>(g2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalEqn</span>(<span class="params">X, y</span>):</span><br><span class="line">    theta = ((np.linalg.inv(X.T.dot(X))).dot(X.T)).dot(y)</span><br><span class="line">    <span class="comment"># theta = np.linalg.inv(X.T@X)@X.T@y</span></span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line">theta2=normalEqn(X2, y2)</span><br><span class="line"><span class="built_in">print</span>(theta2)</span><br></pre></td></tr></table></figure>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：1编程作业：线性回归</li>
        <li>Post author：Fang</li>
        <li>Create time：2021-08-06 11:59:57</li>
        <li>
            Post link：https://ainianxu.github.io/2021/08/06/1编程作业：线性回归/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a>&nbsp;
                    </li>
                
            </ul>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2021/08/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20day06%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">深度学习 day06 深度学习的实用层面</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2021/08/03/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%AC%E5%9B%9B%E5%91%A8%E6%A3%80%E6%B5%8B/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">神经网络和深度学习第四周检测</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
            <div class="comment-container">
                <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fas fa-comments">&nbsp;Comments</i>
    </div>
    

        
            
    <div class="valine-container">
        <script data-pjax
                src="//cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script>
        <div id="vcomments"></div>
        <script data-pjax>
            function loadValine() {
                new Valine({
                    el: '#vcomments',
                    appId: 'loa9BVbgmyFLwBMHhg1Cycx1-gzGzoHsz',
                    appKey: '47pIz6ewIXRi5251WyfUpQOB',
                    meta: ['nick', 'mail', 'link'],
                    avatar: 'wavatar',
                    enableQQ: true,
                    placeholder: '😜 尽情吐槽吧~',
                    lang: 'en'.toLowerCase()
                });

                function getAuthor(language) {
                    switch (language) {
                        case 'en':
                            return 'Author';
                        case 'zh-CN':
                            return '博主';
                        default:
                            return 'Master';
                    }
                }

                // Add "Author" identify
                const getValineDomTimer = setInterval(() => {
                    const vcards = document.querySelectorAll('#vcomments .vcards .vcard');
                    if (vcards.length > 0) {
                        let author = 'Fang';

                        if (author) {
                            for (let vcard of vcards) {
                                const vnick_dom = vcard.querySelector('.vhead .vnick');
                                const vnick = vnick_dom.innerHTML;
                                if (vnick === author) {
                                    vnick_dom.innerHTML = `${vnick} <span class="author">${getAuthor(KEEP.hexo_config.language)}</span>`
                                }
                            }
                        }
                        clearInterval(getValineDomTimer);
                    } else {
                        clearInterval(getValineDomTimer);
                    }
                }, 2000);
            }

            if ('true') {
                const loadValineTimeout = setTimeout(() => {
                    loadValine();
                    clearTimeout(loadValineTimeout);
                }, 1000);
            } else {
                window.addEventListener('DOMContentLoaded', loadValine);
            }
        </script>
    </div>



        
    
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2021</span>
              -
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Fang</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.4</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fas fa-comment"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#01-%E7%AE%80%E5%8D%95%E7%9A%84%E7%BB%83%E4%B9%A0"><span class="nav-number">1.</span> <span class="nav-text">01 简单的练习</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#02-%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">2.</span> <span class="nav-text">02 单变量线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E7%BB%98%E5%88%B6%E6%95%B0%E6%8D%AE"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 绘制数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 梯度下降</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-21-%E5%85%AC%E5%BC%8F"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.21 公式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-22-%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.22 实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-23-%E8%AE%A1%E7%AE%97J-%CE%B8"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.23 计算J(θ)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-24-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.2.4.</span> <span class="nav-text">2.24 梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-%E8%B0%83%E8%AF%95"><span class="nav-number">2.2.5.</span> <span class="nav-text">2.3 调试</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#03-%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">3.</span> <span class="nav-text">03 多变量线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-%E7%89%B9%E5%BE%81%E5%BD%92%E4%B8%80%E5%8C%96"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 特征归一化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 正规方程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#04-%E4%BB%A3%E7%A0%81%E6%80%BB%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">04 代码总结</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/code-copy.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/lazyload.js"></script>


<div class="post-scripts pjax">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/toc.js"></script>
    
</div>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.4/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
